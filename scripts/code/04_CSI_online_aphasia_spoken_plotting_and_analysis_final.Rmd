---
title: '04 CSI online spoken: Spoken - Plotting and analysis - final data'
author: "Kirsten Stark"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load packages
```{r load_packages}
#library(dplyr)
library(tidyr)
library(lme4)
library(lmerTest)
library(Rmisc)
library(Cairo)
#library(strengejacke)
library(ggplot2)
library(sjPlot)
library(dplyr)

options(scipen=999)

rm(list = ls())
options( "encoding" = "UTF-8" )
set.seed(99)
```


## Load and preprocess data

```{r load_data}
# input 
input = "aphasia_final.csv"

# load data
df <- read.csv2(here::here("data","transient_data_files", input), sep=",") #%>% select(-"X")
```

Check amount of participants and trials

```{r checks}
# no. of participants: 
length(unique(df$subject))

# no. of trials is 160 per participant? 
nrow(df) == 3*160 * length(unique(df$subject))

table(df$subject, df$session)

# how many non-responses
df %>% filter(VOT==0) %>% dplyr::group_by(type, subject,session) %>% 
  dplyr::summarise(length(VOT))
# table(df$VOT==0, df$subject, df$session)
```

## Drop filler trials

```{r}
df <- df %>% filter(category!="Filler") %>% droplevels()
```

## Add ordinal position

```{r warning=FALSE}
      # add position number
df <- df %>% group_by(subject, session, category) %>% 
      add_count() %>% 
      dplyr::mutate(PosOr = seq(1:n)) %>% dplyr::select(-n)
table(df$PosOr)
#table(df$PosOr,df$session, df$subject)
```

## Factorize columns

```{r transform_variables}
# factorize columns
df$VOT <- as.numeric(as.character(df$VOT))
is.numeric(df$VOT)
df$PosOr <- as.factor(df$PosOr)
df$group <- as.factor(df$type)
df$subject <- as.factor(df$subject)
df$session <- as.factor(df$session)

# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df$session)<-my.simple
levels(df$session)

## Define contrast of group
contrasts(df$group) <- MASS::contr.sdif(2)
levels(df$group)

## Define Ordinal position as continuous predictor variable
df$PosOr_cont <- as.numeric(scale(as.numeric(as.character(df$PosOr)),
                                        center = T, scale = F))
```

## Classified errors and correct responses
Correct responses start with 1.

1 - correct
1.1 - correct with alternative response
1.2 - correct with phonematic paraphasia (<=25% of the word)
1.3 - correct with correct article [*]

1.4 - correct, but VOT invalid

0 - wrong
0.1 - wrong with phonematic paraphrasia (> 25 % of the word)
0.2 - wrong: semantic paraphrasia (word in the experiment)
0.3 - wrong: semantic paraphrasia (word not in the experiment)
0.4 - wrong: null reaction
0.5 - wrong: replacement without connection to the word (word in the experiment) 
0.6 - wrong: replacement without connection to the word (word not in the experiment)
0.7 - superordinate word
0.8 - neologism
0.9 - etc.

0.99 - TECHNICAL ERROR


[*] Bei 1.3 wollten wir schauen wie oft die Artikel mitgenannt wurden, aber das können wir ja erstmal vernachlässigen. Für die exakten Ergebnisse wollten wir dann ja nochmal besprechen, weil die Bestimmung der VOT nicht 100% möglich ist mit Artikel.

```{r fix_correctness}
## Add technical errors in the missing trials
sum(is.na(df$VOT)) # NA VOT so far are technical errors
df$error[is.na(df$VOT)] <- "99"
df$correct[is.na(df$VOT)] <- "0"

## Two trials were forgotten to be classified, but AR == 99 --> technical error?
#sum(is.na(df$correct))
#df %>% filter(is.na(correct))
df$error[is.na(df$correct) & df$AR == "99"] <- "99"
df$correct[is.na(df$correct) & df$AR == "99"] <- "0"
sum(is.na(df$correct))

## NR and 0.4 are the same -> replace this
df$error[df$error=="NR"] <- "4"

## Rename broken names
unique(df$error)
df$error <- stringr::str_replace(df$error, ";;;;;;", "")
df$error <- stringr::str_replace(df$error, "ok", "") # subject 113, session 2, trial 121 (Couch)
df$error <- gsub("?",NA,df$error, fixed = TRUE)
unique(df$error)

unique(df$correct)
df$correct <- stringr::str_replace(df$correct, ";;;;;;", "")
unique(df$correct)
```

```{r table_correctness}
## Overall amount of correct answers
sum(df$correct != 0)
sum(is.na(df$correct)) # these are the technical errors were no audio file was recorded

## Overview of correct responses
table(df$correct)
df$VOT[df$correct==1.4] 

# Overview of incorrect responses
sum(df$correct==0, na.rm=T)

sum(df$correct == 0 & !is.na(df$error)) # here the error classification was missing
df[df$correct == 0 & is.na(df$error),]
df$error[df$correct == 0 & is.na(df$error)] <- 1 # phonet. paraphrasia > 25 % 
```

Overview of correctness classifications by group

```{r}
df %>% group_by(type) %>% dplyr::count(correct)
```

Errors 

```{r}
table(df$error)
```

Show amount of incorrect trials per ordinal position (excluding fillers):

```{r}
## How many incorrect (correct) non-filler trials per ordinal position?
table(df$PosOr[df$category != "Filler" & df$correct == 0],
      df$correct[df$category != "Filler" & df$correct == 0])
table(df$PosOr[df$category != "Filler" & startsWith("1", df$correct)],
      df$correct[df$category != "Filler" & startsWith("1", df$correct)])

## How many incorrrct trials that were not technical errors per ordinal position? 
table(df$PosOr[df$category != "Filler" & df$correct == 0 & 
                 df$error != 99])
```

Show amount of incorrect trials per subject

```{r}
df %>% filter(category != "Filler") %>% 
  group_by(subject, session) %>%
  dplyr::count(correct) %>%  
  mutate(prop=round(n/160*100,2)) %>% #round(prop.table(n), 4)) %>% 
  filter(correct == "0") %>%
  dplyr::select(-c(correct, n))
```

Total percentage of errors

```{r}
sum(df$correct[df$category != "Filler"]=="0", na.rm=T)/nrow(df%>%filter(category != "Filler"))
```

## Summarise erroneous and correct responses

```{r}
classification_summary <- df %>% group_by(group, session) %>% count(correct) %>%
  mutate(correct = case_when(correct == "0" ~ "wrong sum",
                             correct == "1" ~ "correct",
                             correct == "1.1" ~ 
                               "correct with alternative response",
                             correct == "1.2" ~ 
                               "correct with phonematic paraphasia (<=25% of the word)",
                             correct == "1.3" ~ "correct with correct article",
                             correct == "1.4" ~ "correct, but VOT invalid")) %>%
  rename(classification=correct)

x <- df %>% group_by(group, session) %>% count(error) %>%
  mutate(error=as.character(error)) %>% 
  mutate(error=case_when(error == "1" ~ 
                               "wrong with phonematic paraphrasia (> 25 % of the word)",
                             error == "2" ~ 
                               "wrong: semantic paraphrasia (word in the experiment)",
                             error == "3" ~ 
                               "wrong: semantic paraphrasia (word not in the experiment)",
                             error == "4" ~ 
                               "wrong: null reaction",
                             error == "5" ~ 
                               "wrong: replacement without connection to the word (word in the experiment) ",
                             error == "6" ~ 
                               "wrong: replacement without connection to the word (word not in the experiment)",
                             error == "7" ~ "wrong: superordinate word",
                             error == "8" ~ "wrong: neologism",
                             error == "9" ~ "wrong: etc.",
                             error == "99" ~ "TECHNICAL ERROR",
                             is.na(error) ~ "sum correct")) %>%
  rename(classification = error)
(classification_summary <- rbind(classification_summary, x) %>% 
  arrange(group, session))

# Export as word file
library(flextable)
huxt_word <- huxtable::huxtable(classification_summary)
huxt_word <- huxtable::set_number_format(huxt_word, round(2))
huxtable::quick_docx(huxt_word, 
                     file = here::here("results", "tables",
                                       "CSI_online_aphasia_classification_summary.docx"), 
                                       open = FALSE)
```


## Subset data for reaction time and error analyses and delete fillers
As correct reaction times will be considered:
1 - correct
1.1 - correct with alternative response
1.2 - correct with phonematic paraphasia (<=25% of the word)
1.3 - correct with correct article [*]

```{r}
df %>% mutate(correct_class = case_when(
  correct == 1 | correct ==1.1 | correct == 1.2 |correct == 1.3 ~ 1, 
  correct == 1.4 | correct == 0 ~ 0)) -> df
# Fillers included
df %>% group_by(group, session) %>% dplyr::count(correct_class) 
table(df$correct_class)
# Fillers excluded
df %>% filter(category != "Filler") %>% 
  group_by(group, session) %>% dplyr::count(correct_class) 
table(df$correct_class[df$category != "Filler"])
df_RTs <- df %>% filter(correct_class == 1 & category != "Filler")
# table(df_RTs$correct_class, df_RTs$correct)
# sum(df_RTs$VOT == 0); sum(is.na(df_RTs$VOT))

df_RTs %>% group_by(group, session) %>% count()
df_RTs %>% group_by(group, session) %>% count(correct)
```

As errors on the participant side will be considered: 
1 - wrong with phonematic paraphrasia (> 25 % of the word)
2 - wrong: semantic paraphrasia (word in the experiment)
3 - wrong: semantic paraphrasia (word not in the experiment)
4 - wrong: null reaction
5 - wrong: replacement without connection to the word (word in the experiment) 
6 - wrong: replacement without connection to the word (word not in the experiment)
7 - superordinate word
8 - neologism
9 - etc.

```{r}
df %>% mutate(error_class = case_when(
  error ==1 | error == 2 |error == 3 |
    error==4 | error==5 | error == 6 | error == 7 |
    error == 8 | error == 9 ~ 1, 
  error == 99 | is.na(error) ~ 0)) -> df
# Overview including Fillers
df %>% group_by(group, session) %>% count(error_class)
table(df$error_class)
# Overview excluding Fillers
df %>% filter(category != "Filler") %>% 
  group_by(group, session) %>% count(error_class)
table(df$error_class[df$category != "Filler"])

df_errors <- df %>% filter(category != "Filler" & (error != "99" | is.na(error)))
```

# --------
# REACTION TIMES

```{r}
sum(!is.na(df_RTs$error))
```


### Descriptives

```{r descriptives}
(means_final<- df_RTs %>% 
   filter(category != "Filler") %>% 
   Rmisc::summarySEwithin(.,"VOT",idvar = "subject",
                          withinvars = c("session", "PosOr"), 
                          betweenvars = "group", na.rm = T))
(means_final_cat<- df_RTs %>% 
   filter(category != "Filler") %>% 
   Rmisc::summarySEwithin(.,"VOT",idvar = "category",
                          withinvars = c("session", "PosOr"), 
                          betweenvars = "group",na.rm = T))
(means_final_wo_session <- df_RTs %>% 
   filter(category != "Filler") %>% 
   Rmisc::summarySEwithin(.,"VOT",idvar = "subject",
                          withinvars = c("PosOr"), 
                          betweenvars = "group",na.rm = T))
# Export as word file
library(flextable)
huxt_word <- huxtable::huxtable(means_final)
huxt_word <- huxtable::set_number_format(huxt_word, round(2))
huxtable::quick_docx(huxt_word, 
                     file = here::here("results", "tables",
                                       "CSI_online_aphasia_subject_RT_by_session.docx"), 
                                       open = FALSE)

```

Calculate increase mean by ordinal position, separately for each session (not controlled for random variances, weighted only per session):

```{r}
means_final$increase <- NA
for(k in 1:length(unique(means_final$group))){
  for(i in 1:length(unique(means_final$session))){
    for(j in 2:length(unique(means_final$PosOr))) {
      means_final$increase[means_final$session==unique(means_final$session)[i] &
                             means_final$PosOr==unique(means_final$PosOr)[j] & 
                             means_final$group == unique(means_final$group)[k]] <- 
       means_final$VOT[means_final$session==unique(means_final$session)[i] &
                             means_final$PosOr==unique(means_final$PosOr)[j] & 
                             means_final$group == unique(means_final$group)[k]] - 
        means_final$VOT[means_final$session==unique(means_final$session)[i] &
                             means_final$PosOr==unique(means_final$PosOr)[j-1] & 
                             means_final$group == unique(means_final$group)[k]]
    }
}}
# means_final

## Calculate overall mean increase per session (weighted)
## PWA
mean(means_final$increase[means_final$session==1 & means_final$group == "PWA"], na.rm=T)
## control
mean(means_final$increase[means_final$session==1 & means_final$group == "control"], na.rm=T)

means_final$PosOr_effect <- NA
means_final$PosOr_effect[means_final$PosOr==1] <- 1
for(k in 1:length(unique(means_final$group))){
for(i in 1:length(unique(means_final$session))){
  for(j in 2:length(unique(means_final$PosOr))) {
    means_final$PosOr_effect[
      means_final$session==unique(means_final$session)[i] & 
        means_final$PosOr==unique(means_final$PosOr)[1] & 
        means_final$group == unique(means_final$group)[k]] <-
      means_final$PosOr_effect[
      means_final$session==unique(means_final$session)[i] & 
        means_final$PosOr==unique(means_final$PosOr)[1] & 
        means_final$group == unique(means_final$group)[k]] + 
      means_final$increase[means_final$session==unique(means_final$session)[i] &
                             means_final$PosOr==unique(means_final$PosOr)[j]& 
                             means_final$group == unique(means_final$group)[k]]*
      (means_final$N[means_final$session==unique(means_final$session)[i] &
                          means_final$PosOr==unique(means_final$PosOr)[j]& 
                             means_final$group == unique(means_final$group)[k]]+
        means_final$N[means_final$session==unique(means_final$session)[i] &
                          means_final$PosOr==unique(means_final$PosOr)[j-1]& 
                             means_final$group == unique(means_final$group)[k]])
  }
  means_final$PosOr_effect[means_final$session==unique(means_final$session)[i] &
                             means_final$PosOr==unique(means_final$PosOr)[1]& 
                             means_final$group == unique(means_final$group)[k]] <-
    means_final$PosOr_effect[means_final$session==unique(means_final$session)[i] &
                               means_final$PosOr==unique(means_final$PosOr)[1]& 
                             means_final$group == unique(means_final$group)[k]]/
    (sum(means_final$N[means_final$session==unique(means_final$session)[i]& 
                             means_final$group == unique(means_final$group)[k]])+
       sum(means_final$N[means_final$session==unique(means_final$session)[i] &
                           (means_final$PosOr=="2" |
                              means_final$PosOr=="3" |
                              means_final$PosOr=="4")& 
                             means_final$group == unique(means_final$group)[k]]))
}}
means_final
```

### Types of correctness classification 

```{r}
df %>% group_by(group) %>% count(correct)
df %>% group_by(group,session) %>% count(correct)
```

### Plotting
Make plots suitable for APA format, font sizes can be adjusted

```{r apatheme}
apatheme <- theme_bw()+
  theme(plot.title=element_text(size=22,hjust = .5),# (family="Arial",size=22,hjust = .5),
        panel.grid.major=element_blank(), panel.grid.minor=element_blank(),
        panel.border=element_blank(),axis.line=element_line(),
        text=element_text(size=16))# text=element_text(family="Arial",size=16))

control_color <- "#DDAA33"
PWA_color <- "#004488"
```

#### RTs across session, by ordinal position and group
Line graph (only correct trials, without fillers). Across sessions

```{r plot_rt}
(plot_vot <- means_final_wo_session %>% 
    ggplot(., aes(x=PosOr, y=VOT,color=group, group=group)) +
    geom_point(aes(shape=group), size=3)+
    scale_shape_manual(values=c(16,17))+
    stat_summary(aes(linetype=group),fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("dotted", "longdash"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, color=group), width =.1) +
    scale_color_manual(values=c(control_color, PWA_color))+
    apatheme+
    scale_y_continuous(limits = c(1120, 1450), breaks =seq(1150,1450, by = 50)) +
    labs(x="Ordinal position",y ="VOT in ms", colour="Group", linetype="Group",
         shape="Group") +
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm")))
```

```{r}
filename <- "CSI_online_aphasia_spoken_plot_rt_across_sessions.pdf"
ggsave(plot_vot, filename =
         here::here("results", "figures", filename),
       width = 18, height = 13, units = "cm",
       dpi = 300, device = cairo_pdf)
```

#### RTs by Group, session, and ordinal position

```{r }
override.linetype<-c("solid", "dashed", "dotted")
(plot_rt_repetition_PWA <- means_final %>% filter(group=="PWA") %>% 
    ggplot(., aes(x=PosOr, y=VOT, group=session, color = session)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=session),fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("solid", "dashed", "dotted"))+
    scale_color_manual(values=c("#0072B2", "#E69F00", "#000000"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, group = session), width =.1) +
    apatheme+
    scale_y_continuous(limits = c(1120, 1450), breaks =seq(1150,1450, by = 50)) +
    labs(x="Ordinal Position ",y ="RT (ms)", colour="Session", linetype="Session",
         title = "Patients with Aphasia") + #+
  # annotate(geom="text", x=1.5, y=1330, label="n = 30", 
  #         color="black", size = 8))
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))

(plot_rt_repetition_control <- means_final %>% filter(group=="control") %>% 
    ggplot(., aes(x=PosOr, y=VOT, group=session, color = session)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=session),fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("solid", "dashed", "dotted"))+
    scale_color_manual(values=c("#0072B2", "#E69F00", "#000000"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, group = session), width =.1) +
    apatheme+
    scale_y_continuous(limits = c(1120, 1450), breaks =seq(1150,1450, by = 50)) +
    #breaks = c(1100, 1150, 1200, 1250, 1300, 1350)) +
    labs(x="Ordinal Position ",y ="RT (ms)", colour="Session", linetype="Session",
         title = "Control Group") + #+
  # annotate(geom="text", x=1.5, y=1330, label="n = 30", 
  #         color="black", size = 8))
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"))+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))

plots <- cowplot::plot_grid(plot_rt_repetition_PWA,plot_rt_repetition_control,
          nrow = 1, ncol=2,  rel_widths = c(0.81,1), #rel_height = c(1,1),
          margin(1,1,1,1),
          labels = c("A", "B"),label_size = 34,
                    label_fontfamily = "Helvetica", label_y = 1.01, label_x=-0.03)
filename <- "CSI_online_aphasia_spoken_plot_rt_by_repetition.pdf"
ggsave(plots, filename = 
         here::here("results", "figures", filename),
       width = 25, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))

```


#### Normalized boxplot 

```{r boxplot_rt}
means_subject <- df_RTs %>% 
   filter(category != "Filler") %>% 
   summarySEwithin(.,"VOT",withinvars = c("subject","session", "PosOr"),
                   betweenvars="group")
(means_subject <- means_subject %>%
  group_by(subject) %>%
  dplyr::mutate(VOT_norm = VOT - first(VOT)))

(boxplot <- 
  ggplot() + 
  ## boxplot
  geom_boxplot(data=means_subject, aes(x = PosOr,y =VOT_norm, color=group),
               #colour = "grey",
               width = 0.3,fatten = 1)+
  # ### individual means
  geom_jitter(data=means_subject, aes(x = PosOr,y =VOT_norm, color=group),
              position = position_dodge(0.6),
              shape=19,
              #color = "dark grey",
              size=2)+
  ### group means
  stat_summary(data=means_subject, aes(x = PosOr,y =VOT_norm, color=group),
               fun=mean, geom="point",
               #colour = "black",
               shape=18, size=5)+
  ### line
  stat_summary(data=means_subject, aes(x = PosOr,y =VOT_norm, color=group, group=group),
               fun=mean, geom="line",
               #colour = "black",
               linetype = "longdash")+
  
  ## other stuff
  #scale_y_continuous(breaks = seq(600, 1300, by = 50))+
  labs(x="Ordinal Position",y ="Normalized RTs (ms)")+
  apatheme +
  theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0))) +
  coord_equal(ratio = 1/100))

filename <- "CSI_online_aphasia_spoken_boxplot.pdf"
ggsave(boxplot, filename = 
         here::here("results", "figures", filename),
       width = 18, height = 18, units = "cm", 
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))

```

Export plot grid

```{r plot_grid}
# cowplot::plot_grid(plot_rt, boxplot,
#           nrow = 1, labels = c("A", "B"), label_fontfamily = "Arial") %>%
#   ggsave(filename = here::here("results", "figures",
#                                "CSI_online_aphasia_typing_RTs_and_normalized_RTs"),
#          width = 18, height = 13, units = "cm", dpi = 300, 
#          device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", "CSI_online_typing_RTs_and_normalized_RTs"))

```

#### ... with fillers for control

```{r plot_rt_fillers}
# (plot_rt_fillers <- df %>% 
#     mutate(kind = case_when(category == "Filler" ~"Filler",
#                           category != "Filler" ~"Experimental")) %>%
#     ggplot(., aes(x=PosOr, y=timing.01, group=kind, color=kind)) +
#     stat_summary(fun=mean,  geom="point", size = 2)+
#     stat_summary(fun=mean,  geom="line", size = 1) +
#     apatheme+
#     labs(x="Ordinal Position ",y ="RT (ms)", color = "Trial type")+
#   annotate(geom="text", x=1.5, y=1350, label="n = 30", 
#            color="black", size = 8))
# 
# filename <- "CSI_online_typing_plot_rt_with_fillers.pdf"
# ggsave(plot_rt_fillers, filename = 
#          here::here("results", "figures", filename),
#        width = 18, height = 13, units = "cm", 
#        dpi = 300, device = cairo_pdf)
# embedFonts(file = here::here("results", "figures", filename))
```

#### Control: Plot RTs accross the experiment
All correct trials (Excluding filler)

```{r plot_RTs_all}
(plot_RTs_all <- ggplot(data=df_RTs, aes(x=trial, y=VOT, linetype=session,shape=session, color=group)) +
  stat_summary(aes(color=group, shape=session),fun=mean,  geom="point", size = 2)+
  stat_summary(aes(color=group, linetype=session),fun=mean,  geom="line", size = 1) +
  apatheme+
  labs(x="Trial ",y ="VOT (ms)")+
  scale_color_manual(values=c(control_color, PWA_color)))#+
  # annotate(geom="text", x=20, y=1800, label="n = 19", 
  #          color="black", size = 8))

filename <- "CSI_online_aphasia__spoken_plot_rts_across_experiment.pdf"
ggsave(plot_RTs_all, filename = 
         here::here("results", "figures", filename),
       width = 18, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))
```


### Inferential statistics: GLMM (Gamma distribution) with ordinal position as a continuous predictor
#### Contrast coding
*Center predictor variable* 
Across both groups

```{r}
df_RTs$PosOr.cont <- scale(as.numeric(as.character(df_RTs$PosOr)),
                                        center = T, scale = F)
table(df_RTs$PosOr.cont)
mean(df_RTs$PosOr.cont); sd(df_RTs$PosOr.cont)
```

For PWA only

```{r}
df_RTs_PWA <- df_RTs %>% filter(group=="PWA") %>% droplevels()
df_RTs_PWA$PosOr.cont <- scale(as.numeric(as.character(df_RTs_PWA$PosOr)),
                                        center = T, scale = F)
table(df_RTs_PWA$PosOr.cont)
mean(df_RTs_PWA$PosOr.cont); sd(df_RTs_PWA$PosOr.cont)
```

*Compute further contrasts*

```{r}
# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_RTs$session)<-my.simple
levels(df_RTs$session)
contrasts(df_RTs_PWA$session)<-my.simple
levels(df_RTs_PWA$session)

## Define contrast of group
contrasts(df_RTs$group) <- MASS::contr.sdif(2)
levels(df_RTs$group)
levels(df_RTs_PWA$group)
```

#### Check distribution of data
Are the data normally distributed or does a gamma distribution fit the data better?  

*Histogram of the reaction time data*

```{r RT_hist}
hist(df_RTs$VOT)
hist(df_RTs_PWA$VOT)
```

*Exclude unrealistically short reaction times < 200 ms*

```{r}
sum(df_RTs$VOT < 200)
df_RTs <- df_RTs %>% filter(VOT >=200)

sum(df_RTs_PWA$VOT < 200)
df_RTs_PWA <- df_RTs_PWA %>% filter(VOT >=200)
```

*Check fit of normal vs gamma distribution in histograms, q-q-plots and using objective criteria:*  
1) Fit normal and gamma distributions to the reaction time data

```{r load_fitdistrplus}
library(fitdistrplus)
```

```{r fit.normal}
fit.normal<- fitdist(df_RTs$VOT, distr = "norm", method = "mle")
summary(fit.normal)
#plot(fit.normal)

fit.normal_PWA<- fitdist(df_RTs_PWA$VOT, distr = "norm", method = "mle")
summary(fit.normal_PWA)
#plot(fit.normal_PWA)
```

```{r fit.gamma}
fit.gamma <- fitdist(df_RTs$VOT, distr = "gamma", method = "mle")
summary(fit.gamma)
#plot(fit.gamma)

fit.gamma_PWA <- fitdist(df_RTs_PWA$VOT, distr = "gamma", method = "mle")
summary(fit.gamma_PWA)
#plot(fit.gamma_PWA)
```

```{r fit.invgamma}
# library(actuar)
# fit.invgamma <- fitdist(df_RTs$VOT, distr = "invgamma",  method = "mle")
# summary(fit.invgauss)
# #plot(fit.invgauss)
# 
# fit.invgamma_PWA <- fitdist(df_RTs_PWA$VOT, distr = "invgamma", method = "mle")
# summary(fit.invgamma_PWA)
# #plot(fit.invgauss_PWA)
```


```{r fit.invgauss}
library(actuar)
fit.invgauss <- fitdist(df_RTs$VOT, distr = "invgauss", start = list(mean = 5, shape = 1), method = "mle")
summary(fit.invgauss)
#plot(fit.invgauss)

fit.invgauss_PWA <- fitdist(df_RTs_PWA$VOT, distr = "invgauss", start = list(mean = 5, shape = 1), method = "mle")
summary(fit.invgauss_PWA)
#plot(fit.invgauss_PWA)
```


2) Compare the fit of the two distributions  
Visually compare fit of both distributions in histogram

```{r density-comparison}
denscomp(list(fit.gamma, fit.invgauss,fit.normal))

denscomp(list(fit.gamma_PWA, fit.invgauss_PWA, fit.normal_PWA))
```

Visually compare fit of both distributions in Q-Q-plots

```{r q-q-comparison}
qqcomp(list(fit.gamma, fit.invgauss, fit.normal))
qqcomp(list(fit.gamma_PWA, fit.invgauss_PWA, fit.normal_PWA))
```

Compare information criteria

```{r fit_criteria-comparison}
gofstat(list(fit.gamma, fit.invgauss, fit.normal),
        fitnames = c("Gamma", "Inverse Gaussian", "Normal"))

gofstat(list(fit.gamma_PWA, fit.invgauss_PWA, fit.normal_PWA),
        fitnames = c("Gamma", "Inverse Gaussian", "Normal" ))
```

**Conclusion:** .
Overall, (inverse) gamma fits the data better than a normal model with uncontrolled data and an inverse Gaussian distribution for both the entire data set and the PWA group only. The inverse Gamma is not yet implemented in glmer. Therefor we will use the Gamma distribution.

*didLMERconverge function*

```{r}
## This function provides a better convergence check for lme4 v>1.0 models, which have a nasty habit of throwing up false nonconvergence warnings.  It implements Ben Bolker's suggestion here (https://github.com/lme4/lme4/issues/120), referred to again here (http://stats.stackexchange.com/questions/97929/lmer-model-fails-to-converge).
didLmerConverge = function(lmerModel){
  relativeMaxGradient=signif(max(abs(with(
    lmerModel@optinfo$derivs,solve(Hessian,gradient)))),3)
  if (relativeMaxGradient < 0.001) {
    cat(sprintf("\tThe relative maximum gradient of %s is less than our 0.001 criterion.\n\tYou can safely ignore any warnings about a claimed convergence failure.\n\n", relativeMaxGradient))
  }
  else {
    cat(sprintf("The relative maximum gradient of %s exceeds our 0.001 criterion.\nThis looks like a real convergence failure; maybe try simplifying your model?\n\n", relativeMaxGradient))
  }
}

#didLmerConverge(m1)
```

#### Main 1: PWA only - Ordinal position x session 

```{r GLMM_cont}
# m1 <- glmer(VOT ~ PosOr.cont*session +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session|category),
#              data = df_RTs_PWA,
#             family =Gamma(link ="identity"),
#             control=glmerControl(optimizer = "bobyqa"))
```

Model fails to converge --> reduce

```{r}
# 1) Increase optimizer iterations
# m1 <- glmer(VOT ~ PosOr.cont*session +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session|category),
#              data = df_RTs_PWA,
#             family =Gamma(link ="identity"),
#             control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# 2) Set correlation parameters to zero
m1 <- afex::lmer_alt(VOT ~ PosOr.cont*session + 
               (PosOr.cont*session||subject) +
              (PosOr.cont*session||category),
             data = df_RTs_PWA, 
            family =Gamma(link ="identity"), 
            control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1)
## The warnings can be safely ignored

# inspect model
summary(m1)
anova(m1)

# save model output
saveRDS(m1, file = here::here("results", "tables",
                          "CSI_online_aphasia_PWA_glmm_cont.RDS"))
tab_model(m1,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Gamma distribution) of VOTs Predicted by Ordinal Position and Session, PWA only",
          pred.labels = c("(Intercept)", "Ordinal Position", 
                          "Session 2 vs 1",
                          "Session 3 vs 1", "Ord.Pos. x Session2-1",
                          "Ord.Pos. x Session3-1"),
          dv.labels = "Vocal Onset Time",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_cont.html"))
```

#### Secondary analysis with factor group

Make sure contrasts are correctly defined

```{r}
contrasts(df_RTs$session)
levels(df_RTs$session)

## Define contrast of group
contrasts(df_RTs$group)
levels(df_RTs$group)
```

Compute model

```{r}
# m2 <- glmer(VOT ~ PosOr.cont*session*group +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session*group|category),
#              data = df_RTs,
#             family =Gamma(link ="identity"),
#             control=glmerControl(optimizer = "bobyqa"))
```

Model fails to converge --> reduce

```{r}
# 1) Increase optimizer iterations
# m2 <- glmer(VOT ~ PosOr.cont*session*group +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session*group|category),
#              data = df_RTs,
#             family =Gamma(link ="identity"),
#             control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# 2) Set correlation parameters to zero
m2 <- afex::lmer_alt(VOT ~ PosOr.cont*session*group + 
               (PosOr.cont*session||subject) +
              (PosOr.cont*session*group||category),
             data = df_RTs, 
            family =Gamma(link ="identity"), 
            control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m2)
## The warnings can be safely ignored

# inspect model
summary(m2)
anova(m2)

# save model output
saveRDS(m2, file = here::here("results", "tables",
                          "CSI_online_aphasia_SessionxGroup_glmm_cont.RDS"))
tab_model(m2,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Gamma distribution) of VOTs Predicted by Ordinal Position, Session and Group",
          pred.labels = c("(Intercept)", "Ordinal Position",
                          "Session 2 vs 1",
                          "Session 3 vs 1", 
                          "Group (PWA-Control)",
                          "Ord.Pos. x Session2-1",
                          "Ord.Pos. x Session3-1",
                          "Ord.Pos. x Group", 
                          "Session 2-1 x Group",
                          "Session 3-1 x Group",
                          "Ord.Pos. x Session 2-1 x Group",
                          "Ord.Pos. x Session 3-1 x Group"),
          dv.labels = "Vocal Onset Time",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_glmm_cont.html"))
```

##### Follow-up: Nested model

```{r warning=FALSE}
m2_nested1 <- afex::lmer_alt(VOT ~ group/(PosOr.cont*session) + 
               (PosOr.cont*session||subject) +
              (PosOr.cont*session*group||category),
             data = df_RTs, 
            family =Gamma(link ="identity"), 
            control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m2_nested1)
summary(m2_nested1)
saveRDS(m2_nested1, file = here::here("results", "tables",
                          "CSI_online_aphasia_Group_nest_PosOrxSession_glmm_cont.RDS"))
tab_model(m2_nested1,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Gamma distribution) of VOTs with Ordinal Position and Session nested into Group",
          # pred.labels = c("(Intercept)", "Ordinal Position", 
          #                 "Session 2 vs 1",
          #                 "Session 3 vs 1", "Ord.Pos. x Session2-1",
          #                 "Ord.Pos. x Session3-1"),
          dv.labels = "Vocal Onset Time",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here("results", "tables","CSI_online_aphasia_Group_nest_PosOrxSession_glmm_cont.html"))
```

```{r warning=FALSE}
m2_nested1.2 <- afex::lmer_alt(VOT ~ session/(PosOr.cont*group) + 
               (PosOr.cont*session||subject) +
              (PosOr.cont*session*group||category),
             data = df_RTs, 
            family =Gamma(link ="identity"), 
            control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m2_nested1.2)
summary(m2_nested1.2)
saveRDS(m2_nested1.2, file = here::here("results", "tables",
                          "CSI_online_aphasia_Session_nest_PosOrxGroup_glmm_cont.RDS"))
tab_model(m2_nested1.2,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Gamma distribution) of VOTs with Ordinal Position and Group nested into Session",
          # pred.labels = c("(Intercept)", "Ordinal Position", 
          #                 "Session 2 vs 1",
          #                 "Session 3 vs 1", "Ord.Pos. x Session2-1",
          #                 "Ord.Pos. x Session3-1"),
          dv.labels = "Vocal Onset Time",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here("results", "tables","CSI_online_aphasia_Session_nest_PosOrxGroup_glmm_cont.html"))
```

```{r warning=FALSE}
# m2_nested2 <- afex::lmer_alt(VOT ~ group/session/PosOr.cont + 
#                (PosOr.cont*session||subject) +
#               (PosOr.cont*session*group||category),
#              data = df_RTs, 
#             family =Gamma(link ="identity"), 
#             control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
m2_nested2 <- afex::lmer_alt(VOT ~ group/session/PosOr.cont + 
               (PosOr.cont*session||subject) +
              (PosOr.cont*session*group-PosOr.cont||category),
             data = df_RTs, 
            family =Gamma(link ="identity"), 
            control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m2_nested2)
summary(m2_nested2)
saveRDS(m2_nested2, file = here::here("results", "tables",
                          "CSI_online_aphasia_Group_nest_Session_nest_PosOr_glmm_cont.RDS"))
tab_model(m2_nested2,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Gamma distribution) of VOTs with Ordinal Position nested into Session nested into Group",
          # pred.labels = c("(Intercept)", "Ordinal Position", 
          #                 "Session 2 vs 1",
          #                 "Session 3 vs 1", "Ord.Pos. x Session2-1",
          #                 "Ord.Pos. x Session3-1"),
          dv.labels = "Vocal Onset Time",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here("results", "tables","CSI_online_aphasia_Group_nest_Session_nest_PosOr_glmm_cont.html"))
```

### Control: Comparison with transformed RTs

*Box-cox test*  
(common transformations: -2 -> 1/(Y^2), -1 -> 1/y, -0.5 -> 1/(sqrt(y))), 
0 -> log(y), 0.5 -> sqrt(y), *1 -> y*, 2 -> y^2, 3 -> y^3)  

#### PWA only

```{r}
boxcox(df_RTs_PWA$VOT ~ df_RTs_PWA$PosOr*df_RTs_PWA$session)

## Box-Cox suggests log transformation --> compute with log-transformed RTs as s control analysis
## for the main analyses we will use a GLMM
boxcox(log(df_RTs_PWA$VOT)~  df_RTs_PWA$PosOr*df_RTs_PWA$session)

df_RTs_PWA$VOTlog <- log(df_RTs_PWA$VOT)
```

```{r}
library(lmerTest)
# m1_lmm_PWA <- lmer(VOTlog ~ PosOr.cont*session +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session|category),
#              data = df_RTs_PWA,
#             control=lmerControl(optimizer = "bobyqa"))
# didLmerConverge(m1_lmm_PWA)

```

Model fails to converge --> Reduce

```{r}
# 1) Increase optimizer iterations
# m1_lmm_PWA <- lmer(VOTlog ~ PosOr.cont*session +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session|category),
#              data = df_RTs_PWA,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# didLmerConverge(m1_lmm_PWA)

# 2) Omit correlation parameters as model still fails to converge
# m1_lmm_PWA <- afex::lmer_alt(VOTlog ~ PosOr.cont*session +
#                (PosOr.cont*session||subject) +
#               (PosOr.cont*session||category),
#              data = df_RTs_PWA,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# rePCA(m1_lmm_PWA)

# 3) The model still has a singular fit -> reduce
# m1_lmm_PWA <- afex::lmer_alt(VOTlog ~ PosOr.cont*session +
#                (PosOr.cont*session||subject) +
#               (PosOr.cont*session-PosOr.cont||category),
#              data = df_RTs_PWA,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# m1_lmm_PWA <- afex::lmer_alt(VOTlog ~ PosOr.cont*session +
#                (PosOr.cont*session||subject) +
#               (PosOr.cont*session-PosOr.cont-session||category),
#              data = df_RTs_PWA,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# m1_lmm_PWA <- afex::lmer_alt(VOTlog ~ PosOr.cont*session +
#                (PosOr.cont*session||subject) +
#               (1|category),
#              data = df_RTs_PWA,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# m1_lmm_PWA <- afex::lmer_alt(VOTlog ~ PosOr.cont*session +
#                (PosOr.cont+session||subject) +
#               (1|category),
#              data = df_RTs_PWA,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

# 4) Test whether the model also converges including correlation parameters -> yes
m1_lmm_PWA <- lmer(VOTlog ~ PosOr.cont*session +
               (PosOr.cont+session|subject) +
              (1|category),
             data = df_RTs_PWA,
            control=lmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_lmm_PWA)
## Warnings can be ignored

summary(m1_lmm_PWA)
anova(m1_lmm_PWA)

saveRDS(m1_lmm_PWA,  file = here::here("results", "tables", "CSI_online_aphasia_PWA_control_lmm_VOT.RDS"))
tab_model(m1_lmm_PWA,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "LMM of VOTs Predicted by Ordinal Position and Session",
          pred.labels = c("(Intercept)", "Ordinal Position", "Session 2 vs 1", 
                          "Session 3 vs 1", "Ord.Pos. x Session2-1",
                          "Ord.Pos. x Session3-1"),
          df.method = "satterthwaite",
          dv.labels = "Vocal Onset Time (log-transformed)",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_PWA_control_lmm_VOT.html"))
```


#### Secondary analysis with factor group
*Box-cox test*  
(common transformations: -2 -> 1/(Y^2), -1 -> 1/y, -0.5 -> 1/(sqrt(y))), 
0 -> log(y), 0.5 -> sqrt(y), *1 -> y*, 2 -> y^2, 3 -> y^3)  

```{r}
boxcox(df_RTs$VOT ~ df_RTs$PosOr*df_RTs$session*df_RTs$group)

## Box-Cox suggests 1/sqrt transformation --> compute with transformed RTs as s control analysis
## for the main analyses we will use a GLMM
# boxcox(log(df_RTs$VOT) ~  df_RTs$PosOr*df_RTs$session*df_RTs$group)
# boxcox(1000/df_RTs$VOT~  df_RTs$PosOr*df_RTs$session*df_RTs$group)
boxcox(1/sqrt(df_RTs$VOT)~  df_RTs$PosOr*df_RTs$session*df_RTs$group)



df_RTs$VOTsqrt <- 1/sqrt(df_RTs$VOT)
```


```{r}
library(lmerTest)
# m2_lmm <- lmer(VOTsqrt ~ PosOr.cont*session*group +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session*group|category),
#              data = df_RTs,
#             control=lmerControl(optimizer = "bobyqa"))
# didLmerConverge(m2_lmm)

```

Model fails to converge --> Reduce

```{r}
# 1) Increase optimizer iterations
# m2_lmm <- lmer(VOTsqrt ~ PosOr.cont*session*group +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session*group|category),
#              data = df_RTs,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# didLmerConverge(m2_lmm)

# 2) Omit correlation parameters as model still fails to converge
# m2_lmm <- afex::lmer_alt(VOTsqrt ~ PosOr.cont*session*group +
#                (PosOr.cont*session||subject) +
#               (PosOr.cont*session*group||category),
#              data = df_RTs,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

# 3) Model fit is still singular -> Further reduce the model 
# m2_lmm <- afex::lmer_alt(VOTsqrt ~ PosOr.cont*session*group +
#                (PosOr.cont*session||subject) +
#               (PosOr.cont*session*group-session-PosOr.cont:group-session:group||category),
#              data = df_RTs,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

  # m2_lmm <- afex::lmer_alt(VOTsqrt ~ PosOr.cont*session*group +
  #                (PosOr.cont*session||subject) +
  #               (PosOr.cont*session*group-session-PosOr.cont:group-session:group||category),
  #              data = df_RTs,
  #             control=lmerControl(optimizer = "bobyqa",
  #                                  optCtrl = list(maxfun = 2e5)))
# m2_lmm <- afex::lmer_alt(VOTsqrt ~ PosOr.cont*session*group +
#                (PosOr.cont+session||subject) +
#               (PosOr.cont+group||category),
#              data = df_RTs,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

# 4) Does the model also converge when correlation parameters are included - yes! 
m2_lmm <- lmer(VOTsqrt ~ PosOr.cont*session*group +
               (PosOr.cont+session|subject) +
              (PosOr.cont+group|category),
             data = df_RTs,
            control=lmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
# rePCA(m2_lmm)
didLmerConverge(m2_lmm)
## Warnings can be ignored

summary(m2_lmm)
anova(m2_lmm)

saveRDS(m2_lmm,  file = here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_control_lmm_VOT.RDS"))
tab_model(m2_lmm,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "LMM of VOTs Predicted by Ordinal Position and Session",
          # pred.labels = c("(Intercept)", "Ordinal Position", "Session 2 vs 1", 
          #                 "Session 3 vs 1", "Ord.Pos. x Session2-1",
          #                 "Ord.Pos. x Session3-1"),
          dv.labels = "Vocal Onset Time (1/sqrt-transformed)",
          #string.pred = "",
          df.method = "satterthwaite",
          string.stat = "t-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_spoken_SessionxGroup_lmm_VOT.html"))
```


# ERROR RATES

### Descriptives
#### Error types

```{r}
df_errors %>% group_by(group) %>% count(error_class) %>% 
  mutate(percentage=n/(nrow(df[df$category!="Filler" & df$group=="PWA",])))
df_errors %>% group_by(group, session) %>% count(error_class)  %>% 
  mutate(percentage=n/(nrow(df[df$category!="Filler" & df$group=="PWA" & df$session=="1",])))


df_errors %>% group_by(group) %>% count(error) %>%
  mutate(percentage=n/(nrow(df[df$category!="Filler" & df$group=="PWA",])))
df_errors %>% group_by(group, session) %>% count(error) %>% 
  mutate(percentage=n/(nrow(df[df$category!="Filler" & df$group=="PWA" & df$session=="1",])))


table(df_errors$error_class, df_errors$error) # technical errors are not counted as errors
table(df_errors$error_class[is.na(df_errors$error)]) # correct responses
```


#### Amount of errors

```{r descriptives_errors_overall}
error_overview <- data.frame(subject=factor(rep(unique(df$subject), 
                                         each=5*3)),
                             group=factor(rep(c("PWA", "control"), 
                                       each=20*5*3)),
                             session=factor(rep(c("1","2","3"),
                                                each=5,
                                         times=length(unique(df$subject)))),
                             PosOr=factor(rep(c("1","2","3","4","5"),
                                         times=length(unique(df$subject))*3)),
                             error_class=0)
x <- df_errors %>% group_by(subject, session, PosOr) %>% 
  count(error_class) %>% 
  filter(error_class==1)
for(i in 1:nrow(x)){
  error_overview$error_class[error_overview$subject==x$subject[i] &
                         error_overview$session==x$session[i] &
                         error_overview$PosOr==x$PosOr[i] ] <- 
    x$n[i]
}
error_overview$percentage <- (error_overview$error_class/24)*100

(means_final_errors <- error_overview %>%  
    group_by(group,session,PosOr) %>% 
    summarise(count=sum(error_class), mean=mean(error_class),
              sd=sd(error_class), se=sd(error_class)/20,
              mean_p = mean(percentage),
              sd_p=sd(percentage), se_p=sd(percentage)/20))
 
# Export as word file
library(flextable)
huxt_word <- huxtable::huxtable(means_final_errors)
huxt_word <- huxtable::set_number_format(huxt_word, round(2))
huxtable::quick_docx(huxt_word, 
                     file = here::here("results", "tables",
                                       "CSI_online_PWA_errors_by_session.docx"), 
                                       open = FALSE)

```

Calculate increase mean by ordinal position, separately for each session (not controlled for random variances, weighted only per session):

```{r}
means_final_errors$increase_count <- NA
means_final_errors$increase_mean <- NA
for(k in 1:length(unique(means_final_errors$group))){
for(i in 1:length(unique(means_final_errors$session))){
  for(j in 2:length(unique(means_final_errors$PosOr))) {
    means_final_errors$increase_count[means_final_errors$session==unique(means_final_errors$session)[i] &
                           means_final_errors$PosOr==unique(means_final_errors$PosOr)[j]&
                             means_final_errors$group==unique(means_final_errors$group)[k]] <- 
     means_final_errors$count[means_final_errors$session==unique(means_final_errors$session)[i] &
                           means_final_errors$PosOr==unique(means_final_errors$PosOr)[j]&
                             means_final_errors$group==unique(means_final_errors$group)[k]] - 
      means_final_errors$count[means_final_errors$session==unique(means_final_errors$session)[i] &
                           means_final_errors$PosOr==unique(means_final_errors$PosOr)[j-1]&
                             means_final_errors$group==unique(means_final_errors$group)[k]]
    means_final_errors$increase_mean[means_final_errors$session==unique(means_final_errors$session)[i] &
                           means_final_errors$PosOr==unique(means_final_errors$PosOr)[j]&
                             means_final_errors$group==unique(means_final_errors$group)[k]] <- 
     means_final_errors$mean[means_final_errors$session==unique(means_final_errors$session)[i] &
                           means_final_errors$PosOr==unique(means_final_errors$PosOr)[j]&
                             means_final_errors$group==unique(means_final_errors$group)[k]] - 
      means_final_errors$mean[means_final_errors$session==unique(means_final_errors$session)[i] &
                           means_final_errors$PosOr==unique(means_final_errors$PosOr)[j-1]&
                             means_final_errors$group==unique(means_final_errors$group)[k]]
  }}}
#means_final_errors

## Calculate overall mean increase per session (weighted: all PosOrs had the same amount of trials)
mean(means_final_errors$increase_mean[means_final_errors$session==1], na.rm=T)
means_final_errors$PosOr_effect <- NA
means_final_errors$PosOr_effect[means_final_errors$PosOr==1] <- 1
for(k in 1:length(unique(means_final_errors$group))){
for(i in 1:length(unique(means_final_errors$session))){
  means_final_errors$PosOr_effect[means_final_errors$session==unique(means_final_errors$session)[i] &
        means_final_errors$group==unique(means_final_errors$group)[k] &
        means_final_errors$PosOr=="1"] <-
    (means_final_errors$increase_mean[means_final_errors$session==unique(means_final_errors$session)[i] &
        means_final_errors$group==unique(means_final_errors$group)[k] &
        means_final_errors$PosOr=="2"]+
       means_final_errors$increase_mean[means_final_errors$session==unique(means_final_errors$session)[i] &
        means_final_errors$group==unique(means_final_errors$group)[k] &
        means_final_errors$PosOr=="3"]+
       means_final_errors$increase_mean[means_final_errors$session==unique(means_final_errors$session)[i] &
        means_final_errors$group==unique(means_final_errors$group)[k] &
        means_final_errors$PosOr=="4"]+
       means_final_errors$increase_mean[means_final_errors$session==unique(means_final_errors$session)[i] &
        means_final_errors$group==unique(means_final_errors$group)[k] &
        means_final_errors$PosOr=="5"])/4
}}
means_final_errors
```

### Plotting

#### Errors by ordinal position and repetition

```{r}
means_final_errors$session_group <- paste0(means_final_errors$group, 
                                           means_final_errors$session)
override.linetype<-c("dotted", "dashed")
(plot_error <- means_final_errors %>%
    ggplot(., aes(x=PosOr, y=mean_p, 
                  color = session)) +
  geom_point(size = 2)+
  stat_summary(aes(x=PosOr, y=mean_p, group=session_group,
                  color = session, linetype=group),
               fun=mean,  geom="line", size = 0.5) +
  scale_linetype_manual(values=c("dotted", "dashed"))+
  scale_color_manual(values=c("#0072B2", "#E69F00", "#000000"))+
  geom_errorbar(aes(ymin=mean_p-se_p, ymax=mean_p+se_p, group = session), width =.1) +
  apatheme+
  scale_y_continuous(breaks = seq(0, 40, by = 5), limits=c(0,35))+
      theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"))+
  # guides(color=guide_legend(
  #    override.aes=list(linetype=override.linetype)))+
  labs(x="Ordinal Position ",y ="Percentage of errors"))

override.linetype<-c("solid", "dashed", "dotted")
(plot_error_PWA <- means_final_errors %>% filter(group=="PWA") %>%
    ggplot(., aes(x=PosOr, y=mean_p, group=session, color = session)) +
  geom_point( size = 2)+
      stat_summary(aes(linetype=session),fun=mean,  geom="line", size = 0.5) +
    #scale_linetype_manual(values=c("solid", "dashed", "dotted"))+
    scale_color_manual(values=c("#0072B2", "#E69F00", "#000000"))+
  geom_errorbar(aes(ymin=mean_p-se_p, ymax=mean_p+se_p, group = session), width =.1) +
  apatheme+
  scale_y_continuous(breaks = seq(10,30, by = 5), limits=c(10,33))+
      theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
  guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
  labs(x="Ordinal Position ",y ="Percentage of errors", 
       title="Patients with Aphasia"))

(plot_error_control <- means_final_errors %>% filter(group=="control") %>%
    ggplot(., aes(x=PosOr, y=mean_p, group=session, color = session)) +
  geom_point( size = 2)+
      stat_summary(aes(linetype=session),fun=mean,  geom="line", size = 0.5) +
    #scale_linetype_manual(values=c("solid", "dashed", "dotted"))+
    scale_color_manual(values=c("#0072B2", "#E69F00", "#000000"))+
  geom_errorbar(aes(ymin=mean_p-se_p, ymax=mean_p+se_p, group = session), width =.1) +
  apatheme+
  scale_y_continuous(breaks = seq(0, 5, by =1), limits=c(0,5.5))+
      theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"))+
  guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
  labs(x="Ordinal Position ",y ="Percentage of errors", 
       title="Control group"))


filename <- "CSI_online_spoken_plot_error.pdf"
ggsave(plot_error, filename = 
         here::here("results", "figures", filename),
       width = 18, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("data", "verbal_CSI", "Plots", filename))
 
ggsave(plot_error_PWA, filename = 
         here::here("results", "figures", "CSI_online_spoken_plot_error_PWA.pdf"),
       width = 18, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
ggsave(plot_error_control, filename = 
         here::here("results", "figures", "CSI_online_spoken_plot_error_control.pdf"),
       width = 18, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
```

#### Control: Plot Errors accross the experiment

```{r plot_errors_all}
(plot_errors_all <- ggplot(data=df_errors, 
                        aes(x=trial, y=error_class, linetype=session,
                              shape=session, color=group)) +
   stat_summary(aes(color=group, shape=session),fun=mean,  geom="point", size = 2)+
  #stat_summary(aes(color=group, linetype=session),fun=mean,  geom="line", size = 1) +
  apatheme+
  labs(x="Trial ",y ="Errors")+
  scale_color_manual(values=c(control_color, PWA_color)))
 # annotate(geom="text", x=20, y=200, label="n = 19", 
  #         color="black", size = 8))


filename <- "CSI_online_aphasia_errors_across_experiment.pdf"
ggsave(plot_errors_all, filename = 
         here::here("results", "figures", filename),
       width = 18, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))
```

### GLMM with binomial distribution
#### Contrast coding
*Center predictor variable*

```{r}
df_errors_PWA <- df_errors %>% filter(group=="PWA") %>% droplevels()
df_errors_PWA$PosOr.cont <-
  c(scale(as.numeric(as.character(df_errors_PWA$PosOr)),
        center = T, scale = F))

df_errors$PosOr.cont <-
  c(scale(as.numeric(as.character(df_errors$PosOr)),
        center = T, scale = F))
```

*Contrast coding*

```{r}
# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_errors$session)<-my.simple
levels(df_errors$session)
contrasts(df_errors_PWA$session)<-my.simple
levels(df_RTs_PWA$session)

## Define contrast of group
contrasts(df_errors$group) <- MASS::contr.sdif(2)
levels(df_errors$group)
levels(df_errors_PWA$group)
```

#### PWA only
*GLMM*

```{r GLMM_errors}
# m1_error <- glmer(error_class ~ PosOr.cont*session + 
#                     (PosOr.cont*session|subject) +
#                     (PosOr.cont*session|category) ,
#                   data =df_errors_PWA, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))

# 2) The model fit is singular -> reduce optimizer iterations
# m1_error <- glmer(error_class ~ PosOr.cont*session + 
#                     (PosOr.cont*session|subject) +
#                     (PosOr.cont*session|category) ,
#                   data =df_errors_PWA, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

# 3) Further reduce by excluding correlation parameters
# m1_error <- afex::lmer_alt(error_class ~ PosOr.cont*session + 
#                     (PosOr.cont*session||subject) +
#                     (PosOr.cont*session||category) ,
#                   data =df_errors_PWA, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

# 4) Model fit is still singular -> further reduce
# m1_error <- afex::lmer_alt(error_class ~ PosOr.cont*session +
#                     (PosOr.cont*session||subject) +
#                     (1|category) ,
#                   data =df_errors_PWA, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
 # m1_error <- afex::lmer_alt(error_class ~ PosOr.cont*session + 
 #                    (PosOr.cont+session||subject) +
 #                    (1|category) ,
 #                  data =df_errors_PWA, family = "binomial",
 #                  control=glmerControl(optimizer = "bobyqa",
 #                                 optCtrl = list(maxfun = 2e5)))
m1_error <- glmer(error_class ~ PosOr.cont*session + 
                    (PosOr.cont |subject) +
                    (1|category) ,
                  data =df_errors_PWA, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
rePCA(m1_error)
didLmerConverge(m1_error)
summary(m1_error)

# save model output
saveRDS(m1_error, file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_errors.RDS"))
tab_model(m1_error,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Binomial distribution) of Errors Predicted by Ordinal Position and Session, 
          PWA only",
          pred.labels = c("(Intercept)", "Ordinal Position", "Session 2 vs 1", 
                          "Session 3 vs 1", "Ord.Pos. x Session2-1",
                          "Ord.Pos. x Session3-1"),
          dv.labels = "Error Rate",
          #string.pred = "",
          string.stat = "z-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_errors.html"))
```

Make the estimates interpretable 

```{r}
# Odds Ratio:
x <- data.frame(summary(m1_error)$coefficients)
x$Odds_Ratio <- plogis(x$Estimate)
x %>% dplyr::select(Estimate, Odds_Ratio) %>% 
  mutate(Estimate=round(Estimate,2),
         Odds_Ratio=round(Odds_Ratio,2))
```

#### Secondary analysis: Session x Group
*GLMM*

```{r}
# m2_error <- glmer(error_class ~ PosOr.cont*session*group + 
#                     (PosOr.cont*session|subject) +
#                     (PosOr.cont*session*group|category) ,
#                   data =df_errors, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))

# 2) The model fit is singular -> reduce optimizer iterations
# m2_error <- glmer(error_class ~ PosOr.cont*session + 
#                     (PosOr.cont*session|subject) +
#                     (PosOr.cont*session*group|category) ,
#                   data =df_errors, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

# 3) Further reduce by excluding correlation parameters
# m2_error <- afex::lmer_alt(error_class ~ PosOr.cont*session*group +
#                     (PosOr.cont*session||subject) +
#                     (PosOr.cont*session*group||category) ,
#                   data =df_errors, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

# 4) Model fit is still singular -> further reduce
# m2_error <- afex::lmer_alt(error_class ~ PosOr.cont*session*group +
#                     (PosOr.cont+session||subject) +
#                     (PosOr.cont*session*group-session-PosOr.cont:session-
#                        PosOr.cont:group-session:group||category) ,
#                   data =df_errors, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# m2_error <- afex::lmer_alt(error_class ~ PosOr.cont*session*group +
#                     (PosOr.cont||subject) +
#                     (PosOr.cont*session*group-session-PosOr.cont:session-
#                        PosOr.cont:group-session:group-PosOr.cont||category) ,
#                   data =df_errors, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
m2_error <- afex::lmer_alt(error_class ~ PosOr.cont*session*group +
                    (PosOr.cont||subject) +
                    (group||category) ,
                  data =df_errors, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
# rePCA(m2_error)
didLmerConverge(m2_error)
summary(m2_error)

# save model output
saveRDS(m2_error, file = here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_glmm_errors.RDS"))
tab_model(m2_error,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Binomial distribution) of Errors Predicted by Ordinal Position and Session, 
          PWA only",
          # pred.labels = c("(Intercept)", "Ordinal Position", "Session 2 vs 1", 
          #                 "Session 3 vs 1", "Ord.Pos. x Session2-1",
          #                 "Ord.Pos. x Session3-1"),
          dv.labels = "Error Rate",
          #string.pred = "",
          string.stat = "z-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_glmm_errors.html"))
```



#### Exploratory follow-up: Make sure there is enough power in the control group

```{r}
# m2_error_control <- glmer(error_class ~ PosOr.cont*session +
#                     (PosOr.cont*session|subject) +
#                     (PosOr.cont*session|category) ,
#                   data =df_errors[df_errors$group=="control",], 
#                   family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))
# m2_error_control <- afex::lmer_alt(error_class ~ PosOr.cont*session +
#                     (PosOr.cont*session||subject) +
#                     (PosOr.cont*session||category) ,
#                   data =df_errors[df_errors$group=="control",], 
#                   family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))
# m2_error_control <- afex::lmer_alt(error_class ~ PosOr.cont*session +
#                     (1|subject) +
#                     (PosOr.cont*session-PosOr.cont-session||category) ,
#                   data =df_errors[df_errors$group=="control",], 
#                   family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))
m2_error_control <- glmer(error_class ~ PosOr.cont*session +
                    (1|subject) +
                    (1|category) ,
                  data =df_errors[df_errors$group=="control",], 
                  family = "binomial",
                  control=glmerControl(optimizer = "bobyqa"))

# rePCA(m2_error_control)
didLmerConverge(m2_error_control)
summary(m2_error_control)

# save model output
saveRDS(m2_error_control, file = here::here("results", "tables", "CSI_online_aphasia_Session_control_group_errors.RDS"))
tab_model(m2_error_control,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Binomial distribution) of Errors Predicted by Ordinal Position and Session, 
          Control group only",
          # pred.labels = c("(Intercept)", "Ordinal Position", "Session 2 vs 1", 
          #                 "Session 3 vs 1", "Ord.Pos. x Session2-1",
          #                 "Ord.Pos. x Session3-1"),
          dv.labels = "Error Rate",
          #string.pred = "",
          string.stat = "z-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_Session_control_group_errors.html"))
```


# ---------------------------------------------
# Comparison to verbal CSI with young participants

###  Load data
Load data from both the verbal online CSI experiment (Stark et al., 2022)

```{r load_verbal_data}
load(here::here("data", "verbal_CSI_young_starketal2022", "CSI_online_verbal_df_full.RData"))
df_young <- df_full
```

###  Combine both data frames into one
1) Subset relevant columns and give identical names

```{r subset_and_rename_columns}
df_young <- df_young %>% 
  dplyr::select(VP, Item, subcat, VOT, correct, Pos) %>%
  dplyr::rename(subject = VP, item = Item, category = subcat, PosOr=Pos) %>%
  mutate(group="young") %>% 
  mutate(session="young group")

x <- df_RTs %>% 
  dplyr::select(subject, group, session, item, category, VOT, PosOr)
```

2) Give subjects from both experiments different names

```{r adapt_subject_names}
df_young <- df_young %>% mutate(subject = subject + 300)
```

3) Put columns into correct format 

```{r factorize}
df_young <- df_young %>% 
  mutate(subject = as.factor(subject)) %>%
  mutate(item = as.character(item)) %>%
  mutate(category = as.factor(category)) %>% 
  mutate(VOT = as.numeric(VOT)) %>%
  mutate(PosOr = as.factor(PosOr)) %>%
  filter(!is.na(correct) & correct != 0) %>% 
  dplyr::select(-correct) %>%
  droplevels()
```

4) Bind both data frames into one

```{r combine_df}
df_combi <- bind_rows(x, df_young)
```

5) Give identical category names in both experiments

```{r category_names}
df_combi <- df_combi %>% dplyr::mutate(category = case_when(category == "Buero" ~ "Büro",
                                  category == "Gebaeude" ~ "Gebäude",
                                  category == "Gemuese" ~ "Gemüse",
                                  category == 
                                    "Koerperteile" ~ "Körperteile",
                                  category == "Kueche" ~ "Küche",
                                  category == 
                                    "Suessigkeiten" ~ "Süssigkeiten",
                                  category == 
                                    "Trinkgefaesse" ~ "Trinkgefässe",
                                  category == "Voegel" ~ "Vögel",
                                  TRUE ~ as.character(category))) %>%
  mutate(category == as.factor(category)) %>% droplevels()
table(df_combi$category)
```

5) Drop filler trials

```{r drop_filler}
 df_combi <- df_combi %>% filter(category != "Filler" & 
                      category != "Filler1" & category != "Filler2") %>%
  droplevels()
```

6) Export combined data frame for post-hoc power plot

```{r export_df}
write.csv(df_combi, here::here("data", "CSI_online_young_PWA_old_combined.csv"))
```

### Descriptives

```{r}
(descriptives <- df_combi %>% 
   Rmisc::summarySEwithin(.,"VOT",idvar = "subject",
                          withinvars = c("PosOr", "session"),
                          betweenvars = "group",
                          na.rm = T))
```

### Plotting

Plot RTs by Session and ordinal position for both experiments

````{r}
override.linetype<-c("solid", "dashed", "dotted", "longdash")
(plot_rt_repetition_PWA <- descriptives %>% 
    filter(group=="PWA" | group=="young") %>% 
    ggplot(., aes(x=PosOr, y=VOT, group=session, color = session)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=session),fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("solid", "dashed", "dotted", "longdash"))+
    scale_color_manual(values=c("#0072B2", "#E69F00", "#000000", "gray"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, group = session), width =.1) +
    apatheme + 
    # stat_summary(df_combi[df_combi$group=="young",],
    #              aes(x=PosOr, y=VOT), fun=mean,  geom="line", size = 1) +
    scale_y_continuous(limits = c(1040, 1450), breaks =seq(1050,1450, by = 50)) + 
    labs(x="Ordinal Position ",y ="RT (ms)", colour="Session", linetype="Session",
         title = "PWA vs Young Group") + #+
  # annotate(geom="text", x=1.5, y=1330, label="n = 30", 
  #         color="black", size = 8))
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))

(plot_rt_repetition_control <- descriptives %>% 
    filter(group=="control" | group=="young") %>% 
    ggplot(., aes(x=PosOr, y=VOT, group=session, color = session)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=session),fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("solid", "dashed", "dotted", "longdash"))+
    scale_color_manual(values=c("#0072B2", "#E69F00", "#000000", "gray"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, group = session), width =.1) +
    apatheme+
    scale_y_continuous(limits = c(1040, 1450), breaks =seq(1050,1450, by = 50)) +
    #breaks = c(1100, 1150, 1200, 1250, 1300, 1350)) +
    labs(x="Ordinal Position ",y ="RT (ms)", colour="Session", linetype="Session",
         title = "Control vs Young Group") + #+
  # annotate(geom="text", x=1.5, y=1330, label="n = 30", 
  #         color="black", size = 8))
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"))+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))

plots <- cowplot::plot_grid(plot_rt_repetition_PWA,plot_rt_repetition_control,
          nrow = 1, ncol=2,  rel_widths = c(0.7,1), #rel_height = c(1,1),
          margin(1,1,1,1),
          labels = c("A", "B"),label_size = 34,
                    label_fontfamily = "Helvetica", label_y = 1.01, label_x=-0.03)
filename <- "CSI_online_aphasia_spoken_comparison-to-young.pdf"
ggsave(plots, filename = 
         here::here("results", "figures", filename),
       width = 25, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))

````


# ---------------------------------------------
# Additional plots
### RTs by subject
Line graph for each participant: 

```{r, warning=FALSE}
modeloutput <- coef(m2)$subject
means_final_subject <- df_RTs %>%
   summarySEwithin(.,"VOT",withinvars = c("subject","PosOr", "session"),
                   betweenvars="group")
means_final<- df_RTs %>%
   Rmisc::summarySEwithin(.,"VOT",idvar = "subject",
                          withinvars = c("PosOr"),#, "session"),
                          #betweenvars="group",
                          na.rm = T)

for(i in 1:nrow(means_final_subject)) {
  means_final_subject$grandmean[i] <- means_final$VOT[means_final$PosOr == means_final_subject$PosOr[i]] -
    means_final$VOT[means_final$PosOr== 1]
  means_final_subject$normalizedRT[i] <- means_final_subject$VOT[i] -
    means_final_subject$VOT[means_final_subject$subject == means_final_subject$subject[i] & means_final_subject$PosOr == 1 & 
                                    means_final_subject$session == 1]
  # prepare for ordering
  means_final_subject$effect[i] <- 
    modeloutput$PosOr.cont[means_final_subject$subject[i]] + 
    modeloutput$re1.PosOr.cont[means_final_subject$subject[i]]
}

means_final_subject <- means_final_subject[order(desc(means_final_subject$group), desc(means_final_subject$effect)),] 
means_final_subject$effect <- as.factor(round(means_final_subject$effect, 2))
means_final_subject$effect <- factor(means_final_subject$effect, levels=rev(levels(means_final_subject$effect )))


# add participant number
means_final_subject <- means_final_subject %>% 
  mutate(subject_en = case_when(
    group == "PWA" ~ paste0("PWA ",
                            substr(as.character(means_final_subject$subject), 2,3),
                            "\n(",effect,")",sep=''),
    group == "control" ~ paste0("Control ",
                            substr(as.character(means_final_subject$subject), 2,3),
                            "\n(",effect,")",sep='')))  %>%
  mutate(subject_en = case_when(subject_en=="PWA 04\n(29.1)" ~
                                    "PWA 04\n(29.10)",
                                  subject_en=="PWA 16\n(24.3)" ~
                                    "PWA 16\n(24.30)",
                                  subject_en=="Participant 12\n(38.3)" ~
                                    "Participant 12\n(38.30)",
                                    subject_en=="Control 12\n(17.5)" ~
                                      "Control 12\n(17.50)",
                                  TRUE~subject_en)) %>%
  mutate(subject_en=factor(subject_en,levels=c(
     "PWA 03\n(42.36)","PWA 05\n(37.11)","PWA 20\n(33.71)",
     "PWA 13\n(32.42)","PWA 07\n(29.28)","PWA 08\n(29.13)",  
     "PWA 04\n(29.10)","PWA 12\n(27.84)","PWA 16\n(24.30)",
     "PWA 18\n(23.59)","PWA 06\n(23.31)", "PWA 09\n(19.86)", 
     "PWA 14\n(18.04)","PWA 11\n(16.91)","PWA 17\n(16.18)",
     "PWA 10\n(12.79)","PWA 19\n(10.94)","PWA 02\n(4.11)",    
     "PWA 01\n(0.72)","PWA 15\n(0.02)","Control 09\n(44.58)",
     "Control 17\n(41.22)","Control 10\n(34.06)","Control 20\n(29.22)",
     "Control 02\n(26.54)","Control 07\n(26.11)","Control 01\n(23.97)",
     "Control 05\n(22.77)","Control 03\n(22.53)","Control 15\n(21.83)",
     "Control 19\n(21.75)", "Control 13\n(21.66)","Control 14\n(20.13)",
     "Control 04\n(19.86)","Control 08\n(17.97)","Control 12\n(17.50)",
     "Control 11\n(13.73)","Control 06\n(12.86)","Control 16\n(12.39)",
     "Control 18\n(9.51)" )))

# Plotting
(plot_rt_subject <- means_final_subject %>%
    ggplot(., aes(x=PosOr,y=normalizedRT, color=session, group=session, na.rm=T)) +
    geom_point(size =1, color = 'black') +
    geom_line(aes(x=PosOr,y=normalizedRT, color=session, linetype="c"),
              size = 0.5) +
    geom_line(aes(x=PosOr,y=grandmean, color="b", linetype="d"),
              group = 1,size = 0.8)+
    geom_errorbar(aes(ymin=normalizedRT-se, ymax=normalizedRT+se), width =.1) +
    scale_color_manual(name="Session",values=c("#0072B2", "#E69F00", "#000000", "dark gray"),
                       labels=c("1", "2", "3", "Grand Mean (across subjects, sessions, groups)")) +
    scale_linetype_manual(name="",values=c("c"="solid","d"="dashed"),
                          labels=c("Participant mean",
                                   "Grand Mean"))+
    apatheme+
    labs(x="Ordinal Position",y ="Normalized RTs (ms)") +
    facet_wrap(means_final_subject$subject_en, scales='free', ncol=8)+
    scale_y_continuous(limits = c(-800, 800),
                       breaks = c(-600,-400,-200,0,200,400,600)) +
    scale_x_discrete(breaks=c(1,2,3,4,5))+
    theme(legend.position = "bottom"))

#plot_rt <- lemon::reposition_legend(plot_rt, "bott1.1.om right",panel='panel-5-5')

filename <- "CSI_online_aphasia_effect_by_participant.pdf"
ggsave(plot_rt_subject, filename =
         here::here("results", "figures", filename),
       width = 34, height = 26, units = "cm",
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))
```

### RTs by category
Line graph for each category: 

```{r, warning=FALSE}
modeloutput <- coef(m2)$category
means_final_category <- df_RTs %>%
   summarySEwithin(.,"VOT",withinvars = c("category","PosOr", "session"))#,
                   #betweenvars="group")
means_final<- df_RTs %>%
   Rmisc::summarySEwithin(.,"VOT",idvar = "category",
                          withinvars = c("PosOr"),#, "session"),
                          #betweenvars="group",
                          na.rm = T)

for(i in 1:nrow(means_final_category)) {
  means_final_category$grandmean[i] <- means_final$VOT[means_final$PosOr == means_final_category$PosOr[i]] -
    means_final$VOT[means_final$PosOr== 1]
  means_final_category$normalizedRT[i] <- means_final_category$VOT[i] -
    means_final_category$VOT[means_final_category$category == means_final_category$category[i] & means_final_category$PosOr == 1 & 
                                    means_final_category$session == 1]
  # prepare for ordering
  means_final_category$effect[i] <- 
    modeloutput$PosOr.cont[means_final_category$category[i]] + 
    modeloutput$re2.PosOr.cont[means_final_category$category[i]]
}

means_final_category <- means_final_category[order(desc(means_final_category$effect)),] 
means_final_category$effect <- as.factor(round(means_final_category$effect, 2))
means_final_category$effect <- factor(means_final_category$effect, levels=rev(levels(means_final_category$effect )))
means_final_category$category <- factor(
  means_final_category$category, levels=c(
       "Insekten",     "Sitzen",       "Kochen",       "Jacken",
       "Obst",         "Trinkgefässe", "Wasser",       "Heimwerker",   
       "Küche",        "Fische",       "Aufbewahrung",
       "Büro", "Bauernhof", "Raubtiere", "Huftiere", "Gemüse",
       "Körperteile", "Vögel", "Instrumente", "Blumen",
       "Gebäude", "Schmuck", "Strasse", "Süssigkeiten"))

# order category levels by effect size
means_final_category$category <- factor(
  means_final_category$category, levels=c(
    "Gebäude","Schmuck","Raubtiere","Sitzen","Jacken",
    "Blumen","Huftiere","Wasser","Trinkgefässe","Küche",
    "Insekten","Büro","Bauernhof","Strasse","Kochen",
    "Gemüse","Körperteile","Fische","Heimwerker","Aufbewahrung",
    "Obst","Vögel","Instrumente","Süssigkeiten"))
# give categories English names and combine with effect size
means_final_category <- means_final_category %>% 
  mutate(category_en = case_when(
    category == "Aufbewahrung" ~ paste0(
      "Storage\n\n(", effect, ")", sep=''), 
    category == "Bauernhof" ~ paste0(
      "Farming\ntools\n(", effect, ")", sep=''), 
    category == "Blumen" ~ paste0(
      "Flowers\n\n(", effect, ")", sep=''),
    category == "Büro" ~ paste0(
      "Office\ntools\n(", effect, ")", sep=''),
    category == "Fische" ~ paste0(
      "Fish\n\n(", effect, ")", sep=''),
    category == "Gebäude" ~ paste0(
      "Buildings\n\n(", effect, ")", sep=''),
    category == "Gemüse" ~ paste0(
      "Vegetables\n\n(", effect, ")", sep=''),
    category == "Heimwerker" ~ paste0(
      "Carpenter.s\ntools\n(", effect, ")", sep=''),
    category == "Huftiere" ~ paste0(
      "Hoofed\nanimals\n(", effect, ")", sep=''),
    category == "Insekten" ~ paste0(
      "Insects\n\n(", effect, ")", sep=''),
    category == "Instrumente" ~ paste0(
      "Instruments\n\n(", effect, ")", sep=''),
    category == "Jacken" ~ paste0(
      "Jackets\n\n(", effect, ")", sep=''),
    category == "Kochen" ~ paste0(
      "Cooking\nequipment\n(", effect, ")", sep=''),
    category == "Körperteile" ~ paste0(
      "Body parts\n\n(", effect, ")", sep=''),
    category == "Küche" ~ paste0(
      "Kitchen\nfurniture\n(", effect, ")", sep=''),
    category == "Obst" ~ paste0(
      "Fruits\n\n(", effect, ")", sep=''),
    category == "Raubtiere" ~ paste0(
      "Predators\n\n(", effect, ")", sep=''),
    category == "Schmuck" ~ paste0(
      "Jewelry\n\n(", effect, ")", sep=''),
    category == "Sitzen" ~ paste0(
      "Seating\nfurniture\n(", effect, ")", sep=''),
    category == "Strasse" ~ paste0(
      "Street\nvehicles\n(", effect, ")", sep=''),
    category == "Süssigkeiten" ~ paste0(
      "Sweets\n\n(", effect, ")", sep=''),
    category == "Trinkgefässe" ~ paste0(
      "Drinking\nvessels\n(", effect, ")", sep=''),
    category == "Vögel" ~ paste0(
      "Birds\n\n(", effect, ")", sep=''),
    category == "Wasser" ~ paste0(
      "Water\nvehicles\n(", effect, ")", sep='')))  %>%
  mutate(category_en = case_when(category_en=="Insects\n\n(35.4)" ~
                                    "Insects\n\n(35.40)",
                                  category_en=="Jackets\n\n(27.9)"  ~
                                    "Jackets\n\n(27.90)" ,
                                  TRUE~category_en)) %>%
  mutate(category_en=factor(category_en,levels=c(
     "Insects\n\n(35.40)", "Seating\nfurniture\n(33.45)", 
     "Cooking\nequipment\n(28.45)", "Jackets\n\n(27.90)",
     "Fruits\n\n(27.77)", "Drinking\nvessels\n(26.47)",  
     "Water\nvehicles\n(26.44)","Carpenter.s\ntools\n(26.18)",
     "Kitchen\nfurniture\n(25.76)", "Fish\n\n(23.97)",
     "Storage\n\n(23.56)","Office\ntools\n(23.13)",
     "Farming\ntools\n(22.55)","Predators\n\n(21.51)",
     "Hoofed\nanimals\n(21.18)","Vegetables\n\n(20.74)" ,
     "Body parts\n\n(19.93)","Birds\n\n(19.33)",
     "Instruments\n\n(18.27)","Flowers\n\n(15.53)",
     "Buildings\n\n(13.56)","Jewelry\n\n(12.87)",
     "Street\nvehicles\n(12.76)","Sweets\n\n(11.11)")))


# Plotting
(plot_rt_category <- means_final_category %>%
    ggplot(., aes(x=PosOr,y=normalizedRT, color=session, group=session, na.rm=T)) +
    geom_point(size =1) +
    geom_line(aes(x=PosOr,y=normalizedRT, color=session, linetype="c"),
              size = 0.5) +
    geom_line(aes(x=PosOr,y=grandmean, color="b", linetype="d"),
              group = 1,size = 0.8)+
    geom_errorbar(aes(ymin=normalizedRT-se, ymax=normalizedRT+se), width =.1) +
    scale_color_manual(name="Session",values=c("#0072B2", "#E69F00", "#000000", "dark gray"),
                       labels=c("1", "2", "3", "Grand Mean")) +
    scale_linetype_manual(name="",values=c("c"="solid","d"="dashed"),
                          labels=c("Category mean (across groups)",
                                   "Grand Mean"))+
    apatheme+
    labs(x="Ordinal Position",y ="Normalized RTs (ms)") +
    facet_wrap(means_final_category$category_en, scales='free', ncol=6)+
    scale_y_continuous(limits = c(-500, 500),
                       breaks = c(-400,-200,0,200,400)) +
    scale_x_discrete(breaks=c(1,2,3,4,5))+
    theme(legend.position = "bottom"))

#plot_rt <- lemon::reposition_legend(plot_rt, "bott1.1.om right",panel='panel-5-5')

filename <- "CSI_online_aphasia_effect_by_category.pdf"
ggsave(plot_rt_category, filename =
         here::here("results", "figures", filename),
       width = 26, height = 20,units = "cm",
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))
```

### Errors by subject
Line graph for each participant: 

```{r, warning=FALSE}
m2_error <- readRDS(here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_glmm_errors.RDS"))
modeloutput <- coef(m2_error)$subject
means_final_subject <- df_errors %>%
   summarySEwithin(.,"error_class",withinvars = c("subject","PosOr", "session"),
                   betweenvars="group")
means_final<- df_errors %>%
   Rmisc::summarySEwithin(.,"error_class",idvar = "subject",
                          withinvars = c("PosOr"),#, "session"),
                          #betweenvars="group",
                          na.rm = T)

for(i in 1:nrow(means_final_subject)) {
  means_final_subject$grandmean[i] <- means_final$error_class[means_final$PosOr == means_final_subject$PosOr[i]] -
    means_final$error_class[means_final$PosOr== 1]
  means_final_subject$normalizedRT[i] <- means_final_subject$error_class[i] -
    means_final_subject$error_class[means_final_subject$subject == means_final_subject$subject[i] & means_final_subject$PosOr == 1 & 
                                    means_final_subject$session == 1]
  # prepare for ordering
  means_final_subject$effect[i] <- 
    modeloutput$PosOr.cont[means_final_subject$subject[i]] + 
    modeloutput$re1.PosOr.cont[means_final_subject$subject[i]]
}

means_final_subject <- means_final_subject[order(desc(means_final_subject$group), desc(means_final_subject$effect)),] 
means_final_subject$effect <- as.factor(round(means_final_subject$effect, 2))
means_final_subject$effect <- factor(means_final_subject$effect, levels=rev(levels(means_final_subject$effect )))


# add participant number
means_final_subject <- means_final_subject %>% 
  mutate(subject_en = case_when(
     group == "PWA" & as.numeric(as.character(effect)) >= 0.01~ paste0("PWA ",
                            substr(as.character(means_final_subject$subject), 2,3),
                            "\n(",effect,")",sep=''),
    group == "control"& as.numeric(as.character(effect)) >= 0.01 ~ paste0("Control ",
                            substr(as.character(means_final_subject$subject), 2,3),
                            "\n(",effect,")",sep=''),
    group == "PWA" & as.numeric(as.character(effect)) < 0.01~ paste0("PWA ",
                            substr(as.character(means_final_subject$subject), 2,3),
                            "\n(< .01)",sep=''),
    group == "control"& as.numeric(as.character(effect)) < 0.01 ~ paste0("Control ",
                            substr(as.character(means_final_subject$subject), 2,3),
                            "\n(<.01)",sep='')))  %>%
  mutate(subject_en=factor(subject_en,levels=c(
      "Control 01\n(0.09)", "Control 02\n(0.12)", "Control 03\n(0.03)", 
      "Control 04\n(0.08)", "Control 05\n(0.12)", "Control 06\n(0.07)",
      "Control 07\n(0.1)","Control 08\n(0.06)", "Control 09\n(0.07)",
      "Control 10\n(0.09)", "Control 11\n(0.04)", "Control 12\n(0.07)",
      "Control 13\n(0.05)", "Control 14\n(0.06)","Control 15\n(0.09)",
      "Control 16\n(0.09)", "Control 17\n(0.04)", "Control 18\n(0.03)",
      "Control 19\n(0.07)", "Control 20\n(0.08)", "PWA 01\n(< .01)",
      "PWA 02\n(< .01)","PWA 03\n(0.09)","PWA 04\n(0.11)","PWA 05\n(0.14)",
      "PWA 06\n(0.07)","PWA 07\n(0.14)","PWA 08\n(0.14)",
      "PWA 09\n(< .01)","PWA 10\n(0.12)","PWA 11\n(< .01)","PWA 12\n(0.18)",
      "PWA 13\n(0.05)","PWA 14\n(0.04)","PWA 15\n(0.06)","PWA 16\n(0.06)",
      "PWA 17\n(< .01)","PWA 18\n(0.11)","PWA 19\n(0.11)","PWA 20\n(0.05)")))

# Plotting
(plot_error_subject <- means_final_subject %>%
    ggplot(., aes(x=PosOr,y=normalizedRT, color=session, group=session, na.rm=T)) +
    geom_point(size =1, color = 'black') +
    geom_line(aes(x=PosOr,y=normalizedRT, color=session, linetype="c"),
              size = 0.5) +
    geom_line(aes(x=PosOr,y=grandmean, color="b", linetype="d"),
              group = 1,size = 0.8)+
    geom_errorbar(aes(ymin=normalizedRT-se, ymax=normalizedRT+se), width =.1) +
    scale_color_manual(name="Session",values=c("#0072B2", "#E69F00", "#000000", "dark gray"),
                       labels=c("1", "2", "3", "Grand Mean (across subjects, sessions, groups)")) +
    scale_linetype_manual(name="",values=c("c"="solid","d"="dashed"),
                          labels=c("Participant mean",
                                   "Grand Mean"))+
    apatheme+
    labs(x="Ordinal Position",y ="Error Rate") +
    facet_wrap(means_final_subject$subject_en, scales='free', ncol=8)+
    scale_y_continuous(limits = c(-0.5, 0.5),
                       breaks = c(-0.4,-0.2,0,0.2,0.4)) +
    scale_x_discrete(breaks=c(1,2,3,4,5))+
    theme(legend.position = "bottom"))

#plot_rt <- lemon::reposition_legend(plot_rt, "bott1.1.om right",panel='panel-5-5')

filename <- "CSI_online_aphasia_errors_by_participant.pdf"
ggsave(plot_error_subject, filename =
         here::here("results", "figures", filename),
       width = 34, height = 26, units = "cm",
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))
```


### Errors by categry
Line graph for each participant: 

```{r, warning=FALSE}
m2_error <- readRDS(here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_glmm_errors.RDS"))
modeloutput <- coef(m2_error)$category
means_final_category <- df_errors %>%
   summarySEwithin(.,"error_class",withinvars = c("category","PosOr", "session"))
means_final<- df_errors %>%
   Rmisc::summarySEwithin(.,"error_class",idvar = "category",
                          withinvars = c("PosOr"),#, "session"),
                          #betweenvars="group",
                          na.rm = T)

for(i in 1:nrow(means_final_category)) {
  means_final_category$grandmean[i] <- means_final$error_class[means_final$PosOr == means_final_category$PosOr[i]] -
    means_final$error_class[means_final$PosOr== 1]
  means_final_category$normalized_error[i] <-
    means_final_category$error_class[i] -
    means_final_category$error_class[means_final_category$category == means_final_category$category[i] &
                                       means_final_category$PosOr == 1 & 
                                    means_final_category$session == 1]
  # prepare for ordering
  means_final_category$effect[i] <- 
    modeloutput$PosOr.cont[means_final_category$category[i]] + 
    modeloutput$re1.PosOr.cont[means_final_category$category[i]]
}

means_final_category <- means_final_category[order(desc(means_final_category$effect)),] 
means_final_category$effect <- as.factor(round(means_final_category$effect, 2))
means_final_category$effect <- factor(means_final_category$effect, levels=rev(levels(means_final_category$effect )))

means_final_category$category <- factor(
  means_final_category$category, levels=c(
       "Insekten",     "Sitzen",       "Kochen",       "Jacken",
       "Obst",         "Trinkgefässe", "Wasser",       "Heimwerker",   
       "Küche",        "Fische",       "Aufbewahrung",
       "Büro", "Bauernhof", "Raubtiere", "Huftiere", "Gemüse",
       "Körperteile", "Vögel", "Instrumente", "Blumen",
       "Gebäude", "Schmuck", "Strasse", "Süssigkeiten"))

# give categories English names and combine with effect size
means_final_category <- means_final_category %>% 
  mutate(category_en = category)
    #        
    #        case_when(
    # category == "Aufbewahrung" ~ "Storage", 
    # category == "Bauernhof" ~"Farming\ntools", 
    # category == "Blumen" ~ "Flowers", 
    # category == "Büro" ~"Office\ntools",
    # category == "Fische" ~ "Fish",
    # category == "Gebäude" ~ "Buildings",
    # category == "Gemüse" ~"Vegetables",
    # category == "Heimwerker" ~ "Carpenter.s\ntools",
    # category == "Huftiere" ~ "Hoofed\nanimals",
    # category == "Insekten" ~ "Insects", 
    # category == "Instrumente" ~  "Instruments", 
    # category == "Jacken" ~ "Jackets", 
    # category == "Kochen" ~ "Cooking\nequipment",
    # category == "Körperteile" ~ "Body part",
    # category == "Küche" ~ "Kitchen\nfurniture",
    # category == "Obst" ~ "Fruits", 
    # category == "Raubtiere" ~"Predators", 
    # category == "Schmuck" ~ "Jewelry", 
    # category == "Sitzen" ~"Seating\nfurniture", 
    # category == "Strasse" ~"Street\nvehicles",
    # category == "Süssigkeiten" ~ "Sweets", 
    # category == "Trinkgefässe" ~  "Drinking\nvessels", 
    # category == "Vögel" ~  "Birds",
    # category == "Wasser" ~ "Water\nvehicles"))

# Plotting
(plot_error_category <- means_final_category %>%
    ggplot(., aes(x=PosOr,y=normalized_error, color=session, group=session, na.rm=T)) +
    geom_point(size =1, color = 'black') +
    geom_line(aes(x=PosOr,y=normalized_error, color=session, linetype="c"),
              size = 0.5) +
    geom_line(aes(x=PosOr,y=grandmean, color="b", linetype="d"),
              group = 1,size = 0.8)+
    geom_errorbar(aes(ymin=normalized_error-se, ymax=normalized_error+se), width =.1) +
    scale_color_manual(name="Session",values=c("#0072B2", "#E69F00", "#000000", "dark gray"),
                       labels=c("1", "2", "3", "Grand Mean (across categories, sessions, groups)")) +
    scale_linetype_manual(name="",values=c("c"="solid","d"="dashed"),
                          labels=c("Participant mean",
                                   "Grand Mean"))+
    apatheme+
    labs(x="Ordinal Position",y ="Error Rate") +
     facet_wrap(means_final_category$category_en, scales='free', ncol=6)+
    scale_y_continuous(limits = c(-0.3, 0.3),
                       breaks = c(-0.2,-0.1,0,0.1,0.2)) +
    scale_x_discrete(breaks=c(1,2,3,4,5))+
    theme(legend.position = "bottom"))

#plot_rt <- lemon::reposition_legend(plot_rt, "bott1.1.om right",panel='panel-5-5')

filename <- "CSI_online_aphasia_errors_by_category.pdf"
ggsave(plot_error_category, filename =
         here::here("results", "figures", filename),
       width = 26, height = 20, units = "cm",
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))
```

# -------------------------
# Exploratory analyses
### Intercept-only models
#### RTs
*Center predictor variable and contrast coding* 

```{r}
# PWA + control
df_RTs$PosOr.cont <- scale(as.numeric(as.character(df_RTs$PosOr)),
                                        center = T, scale = F)
# PWA
df_RTs_PWA <- df_RTs %>% filter(group=="PWA") %>% droplevels()
df_RTs_PWA$PosOr.cont <- scale(as.numeric(as.character(df_RTs_PWA$PosOr)),
                                        center = T, scale = F)

# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_RTs$session)<-my.simple
levels(df_RTs$session)
contrasts(df_RTs_PWA$session)<-my.simple
levels(df_RTs_PWA$session)

## Define contrast of group
contrasts(df_RTs$group) <- MASS::contr.sdif(2)
levels(df_RTs$group)
levels(df_RTs_PWA$group)
```


*Exclude unrealistically short reaction times < 200 ms*

```{r}
sum(df_RTs$VOT < 200)
df_RTs <- df_RTs %>% filter(VOT >=200)

sum(df_RTs_PWA$VOT < 200)
df_RTs_PWA <- df_RTs_PWA %>% filter(VOT >=200)
```


##### Main 1: PWA only - Ordinal position x session 

```{r}
m1_intercept <- glmer(VOT ~ PosOr.cont*session +
               (1|subject) +
              (1|category),
             data = df_RTs_PWA,
            family =Gamma(link ="identity"),
            control=glmerControl(optimizer = "bobyqa"))
didLmerConverge(m1_intercept)
## The warnings can be safely ignored

# inspect model
summary(m1_intercept)
anova(m1_intercept)

# save model output
saveRDS(m1_intercept, file = here::here("results", "tables",
                          "CSI_online_aphasia_PWA_glmm_intercept_only.RDS"))
tab_model(m1_intercept,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Gamma distribution) of VOTs Predicted by Ordinal Position and Session, PWA only\nIntercept-Only-Modell",
          pred.labels = c("(Intercept)", "Ordinal Position", 
                          "Session 2 vs 1",
                          "Session 3 vs 1", "Ord.Pos. x Session2-1",
                          "Ord.Pos. x Session3-1"),
          dv.labels = "Vocal Onset Time",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_intercept_only.html"))
```


##### Main 2: Ordinal position x session x group

```{r}
m2_intercept <- glmer(VOT ~  PosOr.cont *group * session  +
               (1|subject) +
              (1|category),
             data = df_RTs,
            family =Gamma(link ="identity"),
            control=glmerControl(optimizer = "bobyqa"))
didLmerConverge(m2_intercept)
## The warnings can be safely ignored

# inspect model
summary(m2_intercept)
anova(m2_intercept)

# save model output
saveRDS(m2_intercept, file = here::here("results", "tables",
                          "CSI_online_aphasia_glmm_intercept_only.RDS"))
tab_model(m2_intercept,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Gamma distribution) of VOTs Predicted by Ordinal Position, Group, and Session\nIntercept-Only-Modell",
          pred.labels = c("(Intercept)", "Ordinal Position", 
                          "Gruppe (PWA-control)",
                          "Session 2 vs 1",
                          "Session 3 vs 1", "Ord.Pos x Gruppe", 
                          "Ord.Pos. x Session2-1",
                          "Ord.Pos. x Session3-1", 
                          "Ord.Pos. x Gruppe x Session2-1",
                          "Ord.Pos. x Gruppe xSession3-1" ),
          dv.labels = "Vocal Onset Time",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_glmm_intercept_only.html"))
```


### Errors
*Center predictor variable*

```{r}
df_errors_PWA <- df_errors %>% filter(group=="PWA") %>% droplevels()
df_errors_PWA$PosOr.cont <-
  c(scale(as.numeric(as.character(df_errors_PWA$PosOr)),
        center = T, scale = F))

df_errors$PosOr.cont <-
  c(scale(as.numeric(as.character(df_errors$PosOr)),
        center = T, scale = F))
```

*Contrast coding*

```{r}
# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_errors$session)<-my.simple
levels(df_errors$session)
contrasts(df_errors_PWA$session)<-my.simple
levels(df_RTs_PWA$session)

## Define contrast of group
contrasts(df_errors$group) <- MASS::contr.sdif(2)
levels(df_errors$group)
levels(df_errors_PWA$group)
```

#### Main 1: PWA only

```{r }
m1_error_intercept <- glmer(error_class ~ PosOr.cont*session +
                    (1|subject) +
                    (1|category) ,
                  data =df_errors_PWA, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa"))
didLmerConverge(m1_error_intercept)
summary(m1_error_intercept)

# save model output
saveRDS(m1_error_intercept, file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_errors_intercept_only.RDS"))
tab_model(m1_error_intercept,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Binomial distribution) of Errors Predicted by Ordinal Position and Session, 
          PWA only\n Intercept-Only-Modell",
          pred.labels = c("(Intercept)", "Ordinal Position", "Session 2 vs 1", 
                          "Session 3 vs 1", "Ord.Pos. x Session2-1",
                          "Ord.Pos. x Session3-1"),
          dv.labels = "Error Rate",
          #string.pred = "",
          string.stat = "z-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_errors_intercept_only.html"))
```

## Polynomial contrasts in VOT of people with aphasia (Session 1)
### RTs, PWA; session 1
Ordinal position effect is only a trend in session 1. Does another than a linear trend describe the data better? 

```{r}
x <- df_RTs_PWA %>% filter(session == "1")
x$PosOr <- as.factor(x$PosOr)
levels(x$PosOr)
contrasts(x$PosOr) <- contr.poly(5)
contrasts(x$PosOr)

# m1_poly <- glmer(VOT ~ PosOr + 
#                (PosOr|subject) +
#               (PosOr|category),
#              data = x, 
#             family =Gamma(link ="identity"), 
#             control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# m1_poly <- afex::lmer_alt(VOT ~ PosOr + 
#                (PosOr||subject) +
#               (PosOr||category),
#              data = x, 
#             family =Gamma(link ="identity"), 
#             control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# didLmerConverge(m1_poly)
# rePCA(m1_poly)
# summary(m1_poly)
# m1_poly <- afex::lmer_alt(VOT ~ PosOr + 
#                (1|subject) +
#               (PosOr||category),
#              data = x, 
#             family =Gamma(link ="identity"), 
#             control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
m1_poly <- glmer(VOT ~ PosOr + 
               (1|subject) +
              (1|category),
             data = x, 
            family =Gamma(link ="identity"), 
            control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
summary(m1_poly)

saveRDS(m1_poly, file = here::here("results", "tables",
                          "CSI_online_aphasia_PWA_session1_glmm_poly_contrast.RDS"))
tab_model(m1_poly,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = 
            "GLMM (Gamma distribution) of VOTs Predicted by Ordinal Position (polynomial contrasts)in Session 1, PWA only",
          dv.labels = "Vocal Onset Time",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_PWA_session1_glmm_poly_contrast.html"))
```

## Sliding-difference contrasts
### RTs
*Center predictor variable and contrast coding* 

```{r}
# PWA + control
df_RTs$PosOr.cont <- scale(as.numeric(as.character(df_RTs$PosOr)),
                                        center = T, scale = F)
# PWA
df_RTs_PWA <- df_RTs %>% filter(group=="PWA") %>% droplevels()
df_RTs_PWA$PosOr.cont <- scale(as.numeric(as.character(df_RTs_PWA$PosOr)),
                                        center = T, scale = F)

# define contrasts of session: sliding difference contrasts
contrasts(df_RTs$session) <- MASS::contr.sdif(3)
levels(df_RTs$session)
contrasts(df_RTs_PWA$session) <- MASS::contr.sdif(3)
levels(df_RTs_PWA$session)

## Define contrast of group
contrasts(df_RTs$group) <- MASS::contr.sdif(2)
levels(df_RTs$group)
levels(df_RTs_PWA$group)
```


*Exclude unrealistically short reaction times < 200 ms*

```{r}
sum(df_RTs$VOT < 200)
df_RTs <- df_RTs %>% filter(VOT >=200)

sum(df_RTs_PWA$VOT < 200)
df_RTs_PWA <- df_RTs_PWA %>% filter(VOT >=200)
```


#### Main 1: PWA only - Ordinal position x session 

```{r}
# m1_sdif <- glmer(VOT ~ PosOr.cont*session +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session|category),
#              data = df_RTs_PWA,
#             family =Gamma(link ="identity"),
#             control=glmerControl(optimizer = "bobyqa"))
m1_sdif <- afex::lmer_alt(VOT ~ PosOr.cont*session +
               (PosOr.cont*session||subject) +
              (PosOr.cont*session||category),
             data = df_RTs_PWA,
            family =Gamma(link ="identity"),
            control=glmerControl(optimizer = "bobyqa"))
didLmerConverge(m1_sdif)
## The warnings can be safely ignored

# inspect model
summary(m1_sdif)

# save model output
saveRDS(m1_sdif, file = here::here("results", "tables",
                          "CSI_online_aphasia_PWA_glmm_sliding_difference_contrast.RDS"))
tab_model(m1_sdif,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Gamma distribution) of VOTs Predicted by Ordinal Position and Session, PWA only (Sliding-difference_contrast)",
          pred.labels = c("(Intercept)", "Ordinal Position", 
                          "Session 2 vs 1",
                          "Session 3 vs 2", "Ord.Pos. x Session2-1",
                          "Ord.Pos. x Session3-2"),
          dv.labels = "Vocal Onset Time",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_sliding_difference_contrast.html"))
```


#### Main 2: Ordinal position x session x group

```{r}
# m2_sdif <- afex::lmer_alt(VOT ~ PosOr.cont*session*group +
#                (PosOr.cont*session||subject) +
#               (PosOr.cont*session*group||category),
#              data = df_RTs,
#             family =Gamma(link ="identity"),
#             control=glmerControl(optimizer = "bobyqa"))
m2_sdif <- afex::lmer_alt(VOT ~ PosOr.cont*session*group +
               (PosOr.cont*session||subject) +
              (PosOr.cont*session*group||category),
             data = df_RTs,
            family =Gamma(link ="identity"),
            control=glmerControl(optimizer = "bobyqa"))

didLmerConverge(m2_sdif)
didLmerConverge(m2_sdif)
## The warnings can be safely ignored

# inspect model
summary(m2_sdif)
anova(m2_sdif)

# save model output
saveRDS(m2_sdif, file = here::here("results", "tables",
                          "CSI_online_aphasia_glmm_sliding_difference_contrast.RDS"))
tab_model(m2_sdif,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Gamma distribution) of VOTs Predicted by Ordinal Position, Group, and Session (Sliding difference contrasts)",
          dv.labels = "Vocal Onset Time",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_glmm_sliding_difference_contrast.html"))
```

## Errors
#### RTs as covariate (PWA only)
Exclude null responses

```{r}
table(df_errors_PWA$error)
df_errors_PWA_control <- df_errors_PWA %>% 
  filter((error != 4 & error != 99) | is.na(error)) %>% 
  filter(VOT > 200) %>% droplevels()
```

*Center predictor variable*

```{r}
df_errors_PWA_control$PosOr.cont <-
  c(scale(as.numeric(as.character(df_errors_PWA_control$PosOr)),
        center = T, scale = F))

df_errors_PWA_control$PosOr.cont <-
  c(scale(as.numeric(as.character(df_errors_PWA_control$PosOr)),
        center = T, scale = F))

range(df_errors_PWA_control$VOT)/1000
df_errors_PWA_control$VOT_c <-
  c(scale(as.numeric(as.character(df_errors_PWA_control$VOT))/1000,
        center = T, scale = F))
```

*Contrast coding*

```{r}
# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_errors_PWA_control$session)<-my.simple
```

*GLMM*

```{r }
# m1_error_VOT <- glmer(error_class ~ PosOr.cont*session*VOT_c +
#                     (PosOr.cont*session|subject) +
#                     (PosOr.cont*session|category) ,
#                   data =df_errors_PWA_control, family = "binomial",
# #                   control=glmerControl(optimizer = "bobyqa"))
# m1_error_VOT <- afex::lmer_alt(error_class ~ PosOr.cont*session*VOT_c +
#                     (PosOr.cont*session||subject) +
#                     (PosOr.cont*session||category) ,
#                   data =df_errors_PWA_control, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))
# m1_error_VOT <- afex::lmer_alt(error_class ~ PosOr.cont*session*VOT_c +
#                     (PosOr.cont+session||subject) +
#                     (PosOr.cont+session||category) ,
#                   data =df_errors_PWA_control, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))
m1_error_VOT <- afex::lmer_alt(error_class ~ PosOr.cont*session*VOT_c +
                    (PosOr.cont+session||subject) +
                    (PosOr.cont||category) ,
                  data =df_errors_PWA_control, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa"))
#rePCA(m1_error_VOT)
didLmerConverge(m1_error_VOT)
summary(m1_error_VOT)

# save model output
saveRDS(m1_error_VOT, file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_errors_VOT_covariate.RDS"))
tab_model(m1_error_VOT,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Binomial distribution) of Errors Predicted by Ordinal Position and Session and VOT, 
          PWA only",
          # pred.labels = c("(Intercept)", "Ordinal Position", "Session 2 vs 1", 
          #                 "Session 3 vs 1", "Ord.Pos. x Session2-1",
          #                 "Ord.Pos. x Session3-1"),
          dv.labels = "Error Rate",
          #string.pred = "",
          string.stat = "z-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_errors_VOT_covariate.html"))
```

#### Word errors only
Exclude null responses, other, and phonematic errors

```{r}
table(df_errors_PWA$error)
df_errors_PWA_control <- df_errors_PWA %>% 
  filter((error != 4 & error != 1 & error != 9 & error != 99) | is.na(error)) %>% 
  filter(VOT > 200) %>% droplevels()
table(df_errors_PWA_control$error)
```

*Center predictor variable*

```{r}
df_errors_PWA_control$PosOr.cont <-
  c(scale(as.numeric(as.character(df_errors_PWA_control$PosOr)),
        center = T, scale = F))

df_errors_PWA_control$PosOr.cont <-
  c(scale(as.numeric(as.character(df_errors_PWA_control$PosOr)),
        center = T, scale = F))

range(df_errors_PWA_control$VOT)/1000
df_errors_PWA_control$VOT_c <-
  c(scale(as.numeric(as.character(df_errors_PWA_control$VOT))/1000,
        center = T, scale = F))
```

*Contrast coding*

```{r}
# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_errors_PWA_control$session)<-my.simple
```

*GLMM*


```{r }
# m1_worderror <- glmer(error_class ~ PosOr.cont*session +
#                     (PosOr.cont*session|subject) +
#                     (PosOr.cont*session|category) ,
#                   data =df_errors_PWA_control, family = "binomial",
#                    control=glmerControl(optimizer = "bobyqa"))
# m1_worderror <- afex::lmer_alt(error_class ~ PosOr.cont*session +
#                     (PosOr.cont*session||subject) +
#                     (PosOr.cont*session||category) ,
#                   data =df_errors_PWA_control, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))
# m1_worderror <- afex::lmer_alt(error_class ~ PosOr.cont*session +
#                     (PosOr.cont+session||subject) +
#                     (PosOr.cont+session||category) ,
#                   data =df_errors_PWA_control, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))
m1_worderror <- afex::lmer_alt(error_class ~ PosOr.cont*session +
                    (PosOr.cont+session||subject) +
                    (PosOr.cont||category) ,
                  data =df_errors_PWA_control, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa"))
#rePCA(m1_worderror)
didLmerConverge(m1_worderror)
summary(m1_worderror)

# save model output
saveRDS(m1_worderror, 
        file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_worderrors.RDS"))
tab_model(m1_worderror,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Binomial distribution) of WORD Errors Predicted by Ordinal Position and Session, 
          PWA only",
          # pred.labels = c("(Intercept)", "Ordinal Position", "Session 2 vs 1", 
          #                 "Session 3 vs 1", "Ord.Pos. x Session2-1",
          #                 "Ord.Pos. x Session3-1"),
          dv.labels = "Error Rate",
          #string.pred = "",
          string.stat = "z-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_worderrors.html"))
```





```{r }
# m1_worderror_VOT <- glmer(error_class ~ PosOr.cont*session*VOT_c +
#                     (PosOr.cont*session|subject) +
#                     (PosOr.cont*session|category) ,
#                   data =df_errors_PWA_control, family = "binomial",
# #                   control=glmerControl(optimizer = "bobyqa"))
# m1_worderror_VOT <- afex::lmer_alt(error_class ~ PosOr.cont*session*VOT_c +
#                     (PosOr.cont*session||subject) +
#                     (PosOr.cont*session||category) ,
#                   data =df_errors_PWA_control, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))
# m1_worderror_VOT <- afex::lmer_alt(error_class ~ PosOr.cont*session*VOT_c +
#                     (PosOr.cont+session||subject) +
#                     (PosOr.cont+session||category) ,
#                   data =df_errors_PWA_control, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))
m1_worderror_VOT <- afex::lmer_alt(error_class ~ PosOr.cont*session*VOT_c +
                    (PosOr.cont+session||subject) +
                    (1|category) ,
                  data =df_errors_PWA_control, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa"))

#rePCA(m1_worderror_VOT)
didLmerConverge(m1_worderror_VOT)
summary(m1_worderror_VOT)

# save model output
saveRDS(m1_worderror_VOT, file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_worderrors_VOT_covariate.RDS"))
tab_model(m1_worderror_VOT,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Binomial distribution) of WORD Errors Predicted by Ordinal Position, Session and VOT, 
          PWA only",
          # pred.labels = c("(Intercept)", "Ordinal Position", "Session 2 vs 1", 
          #                 "Session 3 vs 1", "Ord.Pos. x Session2-1",
          #                 "Ord.Pos. x Session3-1"),
          dv.labels = "Error Rate",
          #string.pred = "",
          string.stat = "z-Value",
          file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_worderrors_VOT_covariate.html"))
```


## RTs: Add Array to model
Center array 

```{r}
df_RTs$array <- as.factor(df_RTs$array)
contrasts(df_RTs$array) <- contr.sdif(30)
```

Add array to fixed structure of intercept only model 
(otherwise it takes veeery long to converge)

```{r}
# m2_array <- afex::lmer_alt(VOT ~ PosOr.cont*session*group*array + 
#                (1|subject) +
#               (1|category),
#              data = df_RTs, 
#             family =Gamma(link ="identity"), 
#             control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# didLmerConverge(m2_array)
# ## The warnings can be safely ignored
# 
# # inspect model
# summary(m2_array)
# anova(m2_array)
# 
# # save model output
# saveRDS(m2_array, file = here::here("results", "tables",
#                           "CSI_online_aphasia_SessionxGroupxArray.RDS"))
```

Model still fails to converge, but there seems to be some influence of array.   
What if we add array to the random structure only? 

```{r}
# m2_array_rand <- afex::lmer_alt(VOT ~ PosOr.cont*session*group + 
#                (PosOr.cont*session*array||subject) +
#               (PosOr.cont*session*group*array||category),
#              data = df_RTs, 
#             family =Gamma(link ="identity"), 
#             control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# summary(m2_array_rand)
# # save model output
# saveRDS(m2_array_rand, file = here::here("results", "tables",
#                           "CSI_online_aphasia_SessionxGroupxArray_random_structure.RDS"))
```