---
title: '04 CSI online spoken: Spoken - Plotting and analysis - final data'
author: "Kirsten Stark"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load packages

```{r load_packages}
#library(dplyr)
library(tidyr)
library(lme4)
library(lmerTest)
library(Rmisc)
library(Cairo)
#library(strengejacke)
library(ggplot2)
# devtools::install_github("strengejacke/sjPlot")
library(sjPlot)
library(dplyr)

options(scipen=999)

rm(list = ls())
options( "encoding" = "UTF-8" )
set.seed(99)
```


## Load preprocessed data

```{r load_data}
# input 
input = "aphasia_final.csv"

# load data
df <- read.csv2(here::here("data","transient_data_files", input), sep=",") #%>% select(-"X")
```

Check amount of participants and trials

```{r checks}
# no. of participants: 
length(unique(df$subject))

# no. of trials is 160 per participant? 
nrow(df) == 3*160 * length(unique(df$subject))

#table(df$subject, df$session)

# how many non-responses
df %>% filter(VOT==0) %>% dplyr::group_by(type, subject,session) %>% 
  dplyr::summarise(length(VOT))
# table(df$VOT==0, df$subject, df$session)
```

## Drop filler trials

```{r}
df <- df %>% filter(category!="Filler") %>% droplevels()
```

## Add ordinal position

```{r warning=FALSE}
      # add position number
df <- df %>% group_by(subject, session, category) %>% 
      add_count() %>% 
      dplyr::mutate(PosOr = seq(1:n)) %>% dplyr::select(-n)
table(df$PosOr)
#table(df$PosOr,df$session, df$subject)
```

## Factorize columns

```{r transform_variables}
# factorize columns
df$VOT <- as.numeric(as.character(df$VOT))
is.numeric(df$VOT)
df$PosOr <- as.factor(df$PosOr)
df$group <- as.factor(df$type)
df$subject <- as.factor(df$subject)
df$session <- as.factor(df$session)

# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df$session)<-my.simple
levels(df$session)

## Define contrast of group
contrasts(df$group) <- MASS::contr.sdif(2)
levels(df$group)

## Define Ordinal position as continuous predictor variable
df$PosOr_cont <- as.numeric(scale(as.numeric(as.character(df$PosOr)),
                                        center = T, scale = F))
```

## Errors and correct responses
Correct responses start with 1.  
  
1 - correct.  
1.1 - correct with alternative response.  
1.2 - correct with phonematic paraphasia (<=25% of the word).  
1.3 - correct with correct article [*].  

1.4 - correct, but VOT invalid. 

0 - wrong. 
0.1 - wrong with phonematic paraphrasia (> 25 % of the word). 
0.2 - wrong: semantic paraphrasia (word in the experiment). 
0.3 - wrong: semantic paraphrasia (word not in the experiment). 
0.4 - wrong: null reaction. 
0.5 - wrong: replacement without connection to the word (word in the experiment)    
0.6 - wrong: replacement without connection to the word (word not in the experiment).  
0.7 - superordinate word.  
0.8 - neologism. 
0.9 - etc.   

0.99 - TECHNICAL ERROR.  

We will consider all responses in 1.1-1.3 for analyses of response times and responses 1.1-1.4 and 0.1-0.9 (not 1.4 and 0.99) fir analyses of error rates.  

```{r fix_correctness}
## Add technical errors in the missing trials
sum(is.na(df$VOT)) # NA VOT so far are technical errors
df$error[is.na(df$VOT)] <- "99"
df$correct[is.na(df$VOT)] <- "0"

## Two trials were forgotten to be classified, but AR == 99 --> technical error?
#sum(is.na(df$correct))
#df %>% filter(is.na(correct))
df$error[is.na(df$correct) & df$AR == "99"] <- "99"
df$correct[is.na(df$correct) & df$AR == "99"] <- "0"
sum(is.na(df$correct))

## NR and 0.4 are the same -> replace this
df$error[df$error=="NR"] <- "4"

## Rename broken names
# unique(df$error)
df$error <- stringr::str_replace(df$error, ";;;;;;", "")
df$error <- stringr::str_replace(df$error, "ok", "") # subject 113, session 2, trial 121 (Couch)
df$error <- gsub("?",NA,df$error, fixed = TRUE)
# unique(df$error)

# unique(df$correct)
df$correct <- stringr::str_replace(df$correct, ";;;;;;", "")
# unique(df$correct)
```

```{r table_correctness}
## Overall amount of correct answers
sum(df$correct != 0)
sum(is.na(df$correct)) # these are the technical errors were no audio file was recorded

## Overview of correct responses
table(df$correct)
#df$VOT[df$correct==1.4] 

# Overview of incorrect responses
sum(df$correct==0, na.rm=T)

sum(df$correct == 0 & !is.na(df$error)) # here the error classification was missing
df[df$correct == 0 & is.na(df$error),]
df$error[df$correct == 0 & is.na(df$error)] <- 1 # phonet. paraphrasia > 25 % 
```

Overview of correctness classifications by group

```{r}
df %>% group_by(type) %>% dplyr::count(correct)
```

Errors 

```{r}
table(df$error)
```

Show amount of incorrect trials per ordinal position (excluding fillers):

```{r}
## How many incorrect (correct) non-filler trials per ordinal position?
table(df$PosOr[df$category != "Filler" & df$correct == 0],
      df$correct[df$category != "Filler" & df$correct == 0])
table(df$PosOr[df$category != "Filler" & startsWith("1", df$correct)],
      df$correct[df$category != "Filler" & startsWith("1", df$correct)])

## How many incorrect trials (no technical errors) per ordinal position? 
table(df$PosOr[df$category != "Filler" & df$correct == 0 & 
                 df$error != 99])
```

Show amount of incorrect trials per subject

```{r}
df %>% filter(category != "Filler") %>% 
  group_by(subject, session) %>%
  dplyr::count(correct) %>%  
  mutate(prop=round(n/160*100,2)) %>% #round(prop.table(n), 4)) %>% 
  filter(correct == "0") %>%
  dplyr::select(-c(correct, n))
```

Total percentage of errors

```{r}
sum(df$correct[df$category != "Filler"]=="0", na.rm=T)/nrow(df%>%filter(category != "Filler"))
```

## Summarise erroneous and correct responses

```{r}
classification_summary <- df %>% group_by(group, session) %>% count(correct) %>%
  mutate(correct = case_when(correct == "0" ~ "wrong sum",
                             correct == "1" ~ "correct",
                             correct == "1.1" ~ 
                               "correct with alternative response",
                             correct == "1.2" ~ 
                               "correct with phonematic paraphasia (<=25% of the word)",
                             correct == "1.3" ~ "correct with correct article",
                             correct == "1.4" ~ "correct, but VOT invalid")) %>%
  rename(classification=correct)

x <- df %>% group_by(group, session) %>% count(error) %>%
  mutate(error=as.character(error)) %>% 
  mutate(error=case_when(
    error == "1" ~ 
      "wrong with phonematic paraphrasia (> 25 % of the word)",
    error == "2" ~ 
      "wrong: semantic paraphrasia (word in the experiment)",
    error == "3" ~ 
      "wrong: semantic paraphrasia (word not in the experiment)",
    error == "4" ~ 
      "wrong: null reaction",
    error == "5" ~ 
      "wrong: replacement without connection to the word (word in the experiment) ",
    error == "6" ~ 
    "wrong: replacement without connection to the word (word not in the experiment)",
    error == "7" ~ "wrong: superordinate word",
    error == "8" ~ "wrong: neologism",
    error == "9" ~ "wrong: etc.",
    error == "99" ~ "TECHNICAL ERROR",
    is.na(error) ~ "sum correct")) %>%
  rename(classification = error)
(classification_summary <- rbind(classification_summary, x) %>% 
  arrange(group, session))

# Export as word file
library(flextable)
huxt_word <- huxtable::huxtable(classification_summary)
huxt_word <- huxtable::set_number_format(huxt_word, round(2))
huxtable::quick_docx(
  huxt_word, file = here::here(
    "results", "tables",
    "CSI_online_aphasia_classification_summary.docx"), 
  open = FALSE)
```


## Subset data for reaction time and error analyses and delete fillers
As correct reaction times will be considered:  
1 - correct.  
1.1 - correct with alternative response.  
1.2 - correct with phonematic paraphasia (<=25% of the word).  
1.3 - correct with correct article [*].  

```{r}
df %>% mutate(correct_class = case_when(
  correct == 1 ~ 1, 
  correct ==1.1 ~ 1,
  correct == 1.2 ~ 1,
  correct == 1.3 ~ 1,
  correct == 1.4 ~ 0,
  correct == 0 ~ 0)) -> df
  
# Fillers included
# df %>% group_by(group, session) %>% dplyr::count(correct_class) 
table(df$correct_class)

# Fillers excluded
# df %>% filter(category != "Filler") %>% 
#   group_by(group, session) %>% dplyr::count(correct_class) 
table(df$correct_class[df$category != "Filler"])

### Save data frame for RT analyses: Only correct responses and no fillers
df_RTs <- df %>% filter(correct_class == 1 & category != "Filler")
# table(df_RTs$correct_class, df_RTs$correct)
# sum(df_RTs$VOT == 0); sum(is.na(df_RTs$VOT))

df_RTs %>% group_by(group, session) %>% count()
(df_RTs %>% group_by(group, session) %>% count(correct) -> x)
# sum(x$n)

print(paste0("Amount of trials that went into RT analyses: ",
             nrow(df_RTs)))
table(df_RTs$group)
```

As errors on the participant side will be considered:   
1 - wrong with phonematic paraphrasia (> 25 % of the word).  
2 - wrong: semantic paraphrasia (word in the experiment).  
3 - wrong: semantic paraphrasia (word not in the experiment).  
4 - wrong: null reaction.  
5 - wrong: replacement without connection to the word (word in the experiment).   
6 - wrong: replacement without connection to the word (word not in the experiment).  
7 - superordinate word.  
8 - neologism.  
9 - etc.    

```{r}
df %>% mutate(error_class = case_when(
  error ==1 | error == 2 |error == 3 |
    error==4 | error==5 | error == 6 | error == 7 |
    error == 8 | error == 9 ~ 1, 
  error == 99 | is.na(error) ~ 0)) -> df
# Overview including Fillers
# df %>% group_by(group, session) %>% count(error_class)
table(df$error_class)

# Overview excluding Fillers
# df %>% filter(category != "Filler") %>% 
#   group_by(group, session) %>% count(error_class)
table(df$error_class[df$category != "Filler"])

#### Subset data for error analyses: All trials excluding technical errors, invalid RTs and fillers
df_errors <- df %>% filter(category != "Filler" & 
                             (error != "99" | is.na(error)))

print(paste0("Amount of trials that went into RT analyses: ",
             nrow(df_errors)))
table(df_errors$group)
```

# -------------------------------------
# RESPONSE TIMES

```{r}
sum(!is.na(df_RTs$error))
```


### Descriptives

```{r descriptives}
(means_final<- df_RTs %>% 
   filter(category != "Filler") %>% 
   Rmisc::summarySEwithin(.,"VOT",idvar = "subject",
                          withinvars = c("session", "PosOr"), 
                          betweenvars = "group", na.rm = T))
(means_final_cat<- df_RTs %>% 
   filter(category != "Filler") %>% 
   Rmisc::summarySEwithin(.,"VOT",idvar = "category",
                          withinvars = c("session", "PosOr"), 
                          betweenvars = "group",na.rm = T))
(means_final_wo_session <- df_RTs %>% 
   filter(category != "Filler") %>% 
   Rmisc::summarySEwithin(.,"VOT",idvar = "subject",
                          withinvars = c("PosOr"), 
                          betweenvars = "group",na.rm = T))
# Export as word file
library(flextable)
huxt_word <- huxtable::huxtable(means_final)
huxt_word <- huxtable::set_number_format(huxt_word, round(2))
huxtable::quick_docx(huxt_word, 
                     file = here::here("results", "tables",
                                       "CSI_online_aphasia_subject_RT_by_session.docx"), 
                                       open = FALSE)

```

Calculate the main effects

```{r}
## Ordinal position effect
x <- df_RTs %>% 
   filter(category != "Filler") %>% 
   Rmisc::summarySEwithin(.,"VOT",idvar = "subject",
                          withinvars = "PosOr", #c("session", "PosOr"), 
                         # betweenvars = "group",
                         na.rm = T)
((x$VOT[1]-x$VOT[2])+(x$VOT[2]-x$VOT[3])+(x$VOT[3]-x$VOT[4])+
    (x$VOT[4]-x$VOT[5]))/4
((x$VOT[1]-x$VOT[5]))/4

## session effect
x <- df_RTs %>% 
   filter(category != "Filler") %>% 
   Rmisc::summarySEwithin(.,"VOT",idvar = "subject",
                          withinvars = "session", #c("session", "PosOr"), 
                         # betweenvars = "group",
                         na.rm = T)
(x$VOT[2]-x$VOT[1])
(x$VOT[3]-x$VOT[1])

## group effect
x <- df_RTs %>% 
   filter(category != "Filler") %>% 
   Rmisc::summarySE(.,"VOT",#idvar = "subject",
                          #withinvars = "session", #c("session", "PosOr"), 
                          groupvars = "group",
                         na.rm = T)
(x$VOT[2]-x$VOT[1])
```

Calculate increase mean by ordinal position, separately for each session (not controlled for random variances, weighted only per session):

```{r}
means_final$increase <- NA
for(k in 1:length(unique(means_final$group))){
  for(i in 1:length(unique(means_final$session))){
    for(j in 2:length(unique(means_final$PosOr))) {
      means_final$increase[means_final$session==unique(means_final$session)[i] &
                             means_final$PosOr==unique(means_final$PosOr)[j] & 
                             means_final$group == unique(means_final$group)[k]] <- 
       means_final$VOT[means_final$session==unique(means_final$session)[i] &
                             means_final$PosOr==unique(means_final$PosOr)[j] & 
                             means_final$group == unique(means_final$group)[k]] - 
        means_final$VOT[means_final$session==unique(means_final$session)[i] &
                             means_final$PosOr==unique(means_final$PosOr)[j-1] & 
                             means_final$group == unique(means_final$group)[k]]
    }
}}
# means_final

## Calculate overall mean increase per session (weighted)
## PWA
mean(means_final$increase[means_final$session==1 & means_final$group == "PWA"], na.rm=T)
## control
mean(means_final$increase[means_final$session==1 & means_final$group == "control"], na.rm=T)

means_final$PosOr_effect <- NA
means_final$PosOr_effect[means_final$PosOr==1] <- 1
for(k in 1:length(unique(means_final$group))){
for(i in 1:length(unique(means_final$session))){
  for(j in 2:length(unique(means_final$PosOr))) {
    means_final$PosOr_effect[
      means_final$session==unique(means_final$session)[i] & 
        means_final$PosOr==unique(means_final$PosOr)[1] & 
        means_final$group == unique(means_final$group)[k]] <-
      means_final$PosOr_effect[
      means_final$session==unique(means_final$session)[i] & 
        means_final$PosOr==unique(means_final$PosOr)[1] & 
        means_final$group == unique(means_final$group)[k]] + 
      means_final$increase[means_final$session==unique(means_final$session)[i] &
                             means_final$PosOr==unique(means_final$PosOr)[j]& 
                             means_final$group == unique(means_final$group)[k]]*
      (means_final$N[means_final$session==unique(means_final$session)[i] &
                          means_final$PosOr==unique(means_final$PosOr)[j]& 
                             means_final$group == unique(means_final$group)[k]]+
        means_final$N[means_final$session==unique(means_final$session)[i] &
                          means_final$PosOr==unique(means_final$PosOr)[j-1]& 
                             means_final$group == unique(means_final$group)[k]])
  }
  means_final$PosOr_effect[means_final$session==unique(means_final$session)[i] &
                             means_final$PosOr==unique(means_final$PosOr)[1]& 
                             means_final$group == unique(means_final$group)[k]] <-
    means_final$PosOr_effect[means_final$session==unique(means_final$session)[i] &
                               means_final$PosOr==unique(means_final$PosOr)[1]& 
                             means_final$group == unique(means_final$group)[k]]/
    (sum(means_final$N[means_final$session==unique(means_final$session)[i]& 
                             means_final$group == unique(means_final$group)[k]])+
       sum(means_final$N[means_final$session==unique(means_final$session)[i] &
                           (means_final$PosOr=="2" |
                              means_final$PosOr=="3" |
                              means_final$PosOr=="4")& 
                             means_final$group == unique(means_final$group)[k]]))
}}
means_final
```

### Trial types within correct responses

```{r}
df %>% group_by(group) %>% count(correct)
df %>% group_by(group,session) %>% count(correct)
```

### Plotting
Make plots suitable for APA format, font sizes can be adjusted

```{r apatheme}
apatheme <- theme_bw()+
  theme(plot.title=element_text(size=22,hjust = .5),# (family="Arial",size=22,hjust = .5),
        panel.grid.major=element_blank(), panel.grid.minor=element_blank(),
        panel.border=element_blank(),axis.line=element_line(),
        text=element_text(size=16))# text=element_text(family="Arial",size=16))

control_color <- "dark green" # #DDAA33"
PWA_color <- "purple" ##004488"
```

#### RTs across session, by ordinal position and group
Line graph (only correct trials, without fillers): RTs, split by group but summarised across sessions

```{r plot_rt}
(plot_vot <- means_final_wo_session %>% 
    ggplot(., aes(x=PosOr, y=VOT,color=group, group=group)) +
    geom_point(aes(shape=group), size=3)+
    scale_shape_manual(values=c(16,17))+
    stat_summary(aes(linetype=group),fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("dotted", "longdash"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, color=group), width =.1) +
    scale_color_manual(values=c(control_color, PWA_color))+
    apatheme+
    scale_y_continuous(limits = c(1120, 1450), 
                       breaks =seq(1150,1450, by = 50)) +
    labs(x="Ordinal position",y ="VOT in ms", colour="Group",
         linetype="Group",
         shape="Group") +
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm")))
```

```{r}
filename <- "CSI_online_aphasia_spoken_plot_rt_across_sessions.pdf"
ggsave(plot_vot, filename =
         here::here("results", "figures", filename),
       width = 18, height = 13, units = "cm",
       dpi = 300, device = cairo_pdf)
```

#### RTs by Group, session, and ordinal position

```{r }
override.linetype<-c("longdash", "dashed", "dotted")
(plot_rt_repetition_PWA <- means_final %>% filter(group=="PWA") %>% 
    ggplot(., aes(x=PosOr, y=VOT, group=session, color = session)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=session),fun=mean,  
                 geom="line", size = 0.5) +
    scale_linetype_manual(values=c("longdash", "dashed", "dotted"))+
    scale_color_manual(values=c("#0072B2", "#E69F00", "#000000"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, group = session), 
                  width =.1) +
    apatheme+
    scale_y_continuous(limits = c(1120, 1450), 
                       breaks =seq(1150,1450, by = 50)) +
    labs(x="Ordinal Position ",y ="RT (ms)", colour="Session",
         linetype="Session",
         title = "People with Aphasia") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))

(plot_rt_repetition_control <- means_final %>% 
    filter(group=="control") %>% 
    ggplot(., aes(x=PosOr, y=VOT, group=session, color = session)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=session),fun=mean,  
                 geom="line", size = 0.5) +
    scale_linetype_manual(values=c("longdash", "dashed", "dotted"))+
    scale_color_manual(values=c("#0072B2", "#E69F00", "#000000"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, group = session), 
                  width =.1) +
    apatheme+
    scale_y_continuous(limits = c(1120, 1450), 
                       breaks =seq(1150,1450, by = 50)) +
    labs(x="Ordinal Position ",y ="RT (ms)", colour="Session", linetype="Session",
         title = "Control Group") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"))+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))

plots <- cowplot::plot_grid(
  plot_rt_repetition_PWA,plot_rt_repetition_control,
  nrow = 1, ncol=2,  rel_widths = c(0.81,1), #rel_height = c(1,1),
  margin(1,1,1,1),
  labels = c("A", "B"),label_size = 34,
  label_fontfamily = "Helvetica", label_y = 1.01,
  label_x=-0.03)
filename <- "CSI_online_aphasia_spoken_plot_rt_by_repetition.pdf"
ggsave(plots, filename = 
         here::here("results", "figures", filename),
       width = 25, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))

```

#### Normalized boxplot 

```{r boxplot_rt}
# means_subject <- df_RTs %>% 
#    filter(category != "Filler") %>% 
#    summarySEwithin(.,"VOT",withinvars = c("subject","session", "PosOr"),
#                    betweenvars="group")
# (means_subject <- means_subject %>%
#   group_by(subject) %>%
#   dplyr::mutate(VOT_norm = VOT - first(VOT)))
# 
# (boxplot <- 
#   ggplot() + 
#   ## boxplot
#   geom_boxplot(data=means_subject, aes(x = PosOr,y =VOT_norm,
#                                        color=group),
#                #colour = "grey",
#                width = 0.3,fatten = 1)+
#   # ### individual means
#   geom_jitter(data=means_subject, aes(x = PosOr,y =VOT_norm, color=group),
#               position = position_dodge(0.6),
#               shape=19,
#               #color = "dark grey",
#               size=2)+
#   ### group means
#   stat_summary(data=means_subject, aes(x = PosOr,y =VOT_norm,
#                                        color=group),
#                fun=mean, geom="point",
#                #colour = "black",
#                shape=18, size=5)+
#   ### line
#   stat_summary(data=means_subject, aes(x = PosOr,y =VOT_norm, 
#                                        color=group, group=group),
#                fun=mean, geom="line",
#                #colour = "black",
#                linetype = "longdash")+
#   
#   ## other stuff
#   #scale_y_continuous(breaks = seq(600, 1300, by = 50))+
#   labs(x="Ordinal Position",y ="Normalized RTs (ms)")+
#   apatheme +
#   theme(
#     axis.title.y = element_text(margin = margin(0,10,0,0)),
#     axis.title.x = element_text(margin = margin(10,0,0,0))) +
#   coord_equal(ratio = 1/100))
# 
# filename <- "CSI_online_aphasia_spoken_boxplot.pdf"
# ggsave(boxplot, filename = 
#          here::here("results", "figures", filename),
#        width = 18, height = 18, units = "cm", 
#        dpi = 300, device = cairo_pdf)
# #embedFonts(file = here::here("results", "figures", filename))
```

Export plot grid

```{r plot_grid}
# cowplot::plot_grid(plot_rt, boxplot,
#           nrow = 1, labels = c("A", "B"), label_fontfamily = "Arial") %>%
#   ggsave(filename = here::here("results", "figures",
#                                "CSI_online_aphasia_typing_RTs_and_normalized_RTs"),
#          width = 18, height = 13, units = "cm", dpi = 300, 
#          device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", "CSI_online_typing_RTs_and_normalized_RTs"))

```

#### ... with fillers for control

```{r plot_rt_fillers}
# (plot_rt_fillers <- df %>% 
#     mutate(kind = case_when(category == "Filler" ~"Filler",
#                           category != "Filler" ~"Experimental")) %>%
#     ggplot(., aes(x=PosOr, y=timing.01, group=kind, color=kind)) +
#     stat_summary(fun=mean,  geom="point", size = 2)+
#     stat_summary(fun=mean,  geom="line", size = 1) +
#     apatheme+
#     labs(x="Ordinal Position ",y ="RT (ms)", color = "Trial type")+
#   annotate(geom="text", x=1.5, y=1350, label="n = 30", 
#            color="black", size = 8))
# 
# filename <- "CSI_online_typing_plot_rt_with_fillers.pdf"
# ggsave(plot_rt_fillers, filename = 
#          here::here("results", "figures", filename),
#        width = 18, height = 13, units = "cm", 
#        dpi = 300, device = cairo_pdf)
# embedFonts(file = here::here("results", "figures", filename))
```

#### Control: Plot RTs accross the experiment
All correct trials (Excluding filler)

```{r plot_RTs_all}
(plot_RTs_all <- ggplot(data=df_RTs, aes(x=trial, y=VOT,
                                         linetype=session,shape=session,
                                         color=group)) +
  stat_summary(aes(color=group, shape=session),fun=mean,  
               geom="point", size = 2)+
  stat_summary(aes(color=group, linetype=session),fun=mean,  
               geom="line", size = 1) +
  apatheme+
  labs(x="Trial ",y ="VOT (ms)")+
  scale_color_manual(values=c(control_color, PWA_color)))

filename <- "CSI_online_aphasia__spoken_plot_rts_across_experiment.pdf"
ggsave(plot_RTs_all, filename = 
         here::here("results", "figures", filename),
       width = 18, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))
```



### Inferential statistics
#### Contrast coding
*Center predictor variable*   
Across both groups.  

```{r}
write.csv2(df_RTs,
  here::here("data","transient_data_files",
             "RT_data_final"),
  sep=",")
df_RTs$PosOr.cont <- scale(as.numeric(as.character(df_RTs$PosOr)),
                                        center = T, scale = F)
table(df_RTs$PosOr.cont)
mean(df_RTs$PosOr.cont); sd(df_RTs$PosOr.cont)
```

For PWA only

```{r}
df_RTs_PWA <- df_RTs %>% filter(group=="PWA") %>% droplevels()
df_RTs_PWA$PosOr.cont <- scale(as.numeric(as.character(df_RTs_PWA$PosOr)),
                                        center = T, scale = F)
table(df_RTs_PWA$PosOr.cont)
mean(df_RTs_PWA$PosOr.cont); sd(df_RTs_PWA$PosOr.cont)
```

*Compute further contrasts*

```{r}
# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_RTs$session)<-my.simple
levels(df_RTs$session)
contrasts(df_RTs_PWA$session)<-my.simple
levels(df_RTs_PWA$session)

## Define contrast of group
contrasts(df_RTs$group) <- MASS::contr.sdif(2)
levels(df_RTs$group)
levels(df_RTs_PWA$group)
```

*didLMERconverge function*

```{r}
## This function provides a better convergence check for lme4 v>1.0 models, which have a nasty habit of throwing up false nonconvergence warnings.  It implements Ben Bolker's suggestion here (https://github.com/lme4/lme4/issues/120), referred to again here (http://stats.stackexchange.com/questions/97929/lmer-model-fails-to-converge).
didLmerConverge = function(lmerModel){
  relativeMaxGradient=signif(max(abs(with(
    lmerModel@optinfo$derivs,solve(Hessian,gradient)))),3)
  if (relativeMaxGradient < 0.001) {
    cat(sprintf("\tThe relative maximum gradient of %s is less than our 0.001 criterion.\n\tYou can safely ignore any warnings about a claimed convergence failure.\n\n", relativeMaxGradient))
  }
  else {
    cat(sprintf("The relative maximum gradient of %s exceeds our 0.001 criterion.\nThis looks like a real convergence failure; maybe try simplifying your model?\n\n", relativeMaxGradient))
  }
}

#didLmerConverge(m1)
```

#### Check distribution of data
Are the data normally distributed or do they need to be converted? Does a Gamma function fit the data better?

*Histogram of the reaction time data*

```{r RT_hist}
hist(df_RTs$VOT)
hist(df_RTs_PWA$VOT)
```

*Exclude unrealistically short reaction times < 200 ms*

```{r}
sum(df_RTs$VOT < 200)
df_RTs <- df_RTs %>% filter(VOT >=200)

sum(df_RTs_PWA$VOT < 200)
df_RTs_PWA <- df_RTs_PWA %>% filter(VOT >=200)
```

#### LMMs: Transformed RTs
In our pre-registration, we planned to conduct a GLMM with a Gamma distribution to account for the non-normality of the data. However, the standard errors seem suspiciously small and additional analyses showed that the GLMM doesn't converge with other types of analyses (see Appendix). Therefore, we decided to conduct an LMM with transformed RTs instead. 

##### Analysis with factors Ordinal position x Session x Group
*Box-cox test*  
(common transformations: -2 -> 1/(Y^2), -1 -> 1/y, -0.5 -> 1/(sqrt(y))), 
0 -> log(y), 0.5 -> sqrt(y), *1 -> y*, 2 -> y^2, 3 -> y^3)  

```{r}
MASS::boxcox(df_RTs$VOT ~ df_RTs$PosOr*df_RTs$session*df_RTs$group)

## Box-Cox suggests log transformation
df_RTs$lVOT <- log(df_RTs$VOT)
```

*Compute full model, then compute step-wise reduction*

```{r}
library(lmerTest)
# m2_lmm <- lmer(lVOT ~ PosOr.cont*session*group +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session*group|category),
#              data = df_RTs,
#             control=lmerControl(optimizer = "bobyqa"))
# didLmerConverge(m2_lmm)

```

Model fails to converge --> Reduce

```{r}
# 1) Increase optimizer iterations
# m2_lmm <- lmer(lVOT ~ PosOr.cont*session*group +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session*group|category),
#              data = df_RTs,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# didLmerConverge(m2_lmm)

# 2) Omit correlation parameters as model still fails to converge
# m2_lmm <- afex::lmer_alt(lVOT ~ PosOr.cont*session*group +
#                (PosOr.cont*session||subject) +
#               (PosOr.cont*session*group||category),
#              data = df_RTs,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

# 3) Model fit is still singular -> Further reduce the model 
# m2_lmm <- afex::lmer_alt(lVOT ~ PosOr.cont*session*group +
#                (PosOr.cont+session||subject) +
#               (PosOr.cont+group||category),
#              data = df_RTs,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# 4) Does the model also converge when correlation parameters are included - yes! 
m2_lmm <- lmer(lVOT ~ PosOr.cont*session*group +
               (PosOr.cont+session|subject) +
              (PosOr.cont+group|category),
             data = df_RTs,
            control=lmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
# rePCA(m2_lmm)
didLmerConverge(m2_lmm)
## Warnings can be ignored

summary(m2_lmm)
anova(m2_lmm)

saveRDS(m2_lmm,  file = here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_control_lmm_VOT.RDS"))
tab_model(m2_lmm,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "LMM of VOTs Predicted by Ordinal Position and Session",
          dv.labels = "Vocal Onset Time (log-transformed)",
          #string.pred = "",
          df.method = "satterthwaite",
          string.stat = "t-Value",
          file = here::here(
            "results", "tables",
            "CSI_online_aphasia_spoken_SessionxGroup_lmm_VOT.html"))

## Check model
# performance::check_model(m2_lmm) 
# ggResidpanel::resid_panel(m2_lmm, smoother = TRUE, 
                          # qqbands = TRUE, type = "pearson")
```

###### PWA only

```{r}
MASS::boxcox(df_RTs$VOT ~ df_RTs$group*df_RTs$PosOr*df_RTs$session)
MASS::boxcox(df_RTs_PWA$VOT ~ df_RTs_PWA$PosOr*df_RTs_PWA$session)

## Box-Cox suggests log transformation --> compute with log-transformed RTs as s control analysis
MASS::boxcox(log(df_RTs_PWA$VOT)~  df_RTs_PWA$PosOr*df_RTs_PWA$session)

df_RTs_PWA$VOTlog <- log(df_RTs_PWA$VOT)
```

*Compute full model, then compute step-wise reduction until model convergence*

```{r}
library(lmerTest)
# m1_lmm_PWA <- lmer(VOTlog ~ PosOr.cont*session +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session|category),
#              data = df_RTs_PWA,
#             control=lmerControl(optimizer = "bobyqa"))
# didLmerConverge(m1_lmm_PWA)

```

Model fails to converge --> Reduce

```{r}
# 1) Increase optimizer iterations
# m1_lmm_PWA <- lmer(VOTlog ~ PosOr.cont*session +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session|category),
#              data = df_RTs_PWA,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# didLmerConverge(m1_lmm_PWA)

# 2) Omit correlation parameters as model still fails to converge
# m1_lmm_PWA <- afex::lmer_alt(VOTlog ~ PosOr.cont*session +
#                (PosOr.cont*session||subject) +
#               (PosOr.cont*session||category),
#              data = df_RTs_PWA,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# rePCA(m1_lmm_PWA)

# 3) The model still has a singular fit -> reduce
# m1_lmm_PWA <- afex::lmer_alt(VOTlog ~ PosOr.cont*session +
#                (PosOr.cont*session||subject) +
#               (PosOr.cont*session-PosOr.cont||category),
#              data = df_RTs_PWA,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# m1_lmm_PWA <- afex::lmer_alt(VOTlog ~ PosOr.cont*session +
#                (PosOr.cont*session||subject) +
#               (PosOr.cont*session-PosOr.cont-session||category),
#              data = df_RTs_PWA,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# m1_lmm_PWA <- afex::lmer_alt(VOTlog ~ PosOr.cont*session +
#                (PosOr.cont*session||subject) +
#               (1|category),
#              data = df_RTs_PWA,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# m1_lmm_PWA <- afex::lmer_alt(VOTlog ~ PosOr.cont*session +
#                (PosOr.cont+session||subject) +
#               (1|category),
#              data = df_RTs_PWA,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

# 4) Test whether the model also converges including correlation parameters -> yes
m1_lmm_PWA <- lmer(VOTlog ~ PosOr.cont*session +
               (PosOr.cont+session|subject) +
              (1|category),
             data = df_RTs_PWA,
            control=lmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_lmm_PWA)
## Warnings can be ignored

summary(m1_lmm_PWA)
anova(m1_lmm_PWA)

saveRDS(m1_lmm_PWA,  file = here::here(
  "results", "tables", "CSI_online_aphasia_PWA_control_lmm_VOT.RDS"))
tab_model(m1_lmm_PWA,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "LMM of VOTs Predicted by Ordinal Position and Session",
          df.method = "satterthwaite",
          dv.labels = "Vocal Onset Time (log-transformed)",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here(
            "results", "tables",
            "CSI_online_aphasia_PWA_control_lmm_VOT.html"))
```

# -------------------------------------
# ERROR RATES

### Descriptives
#### Error types

```{r}
df_errors %>% group_by(group) %>% count(error_class) %>% 
  mutate(percentage=n/(nrow(df[df$category!="Filler" &
                                 df$group=="PWA",])))
df_errors %>% group_by(group, session) %>% count(error_class)  %>% 
  mutate(percentage=n/(nrow(df[df$category!="Filler" & df$group=="PWA" &
                                 df$session=="1",])))


df_errors %>% group_by(group) %>% count(error) %>%
  mutate(percentage=n/(nrow(df[df$category!="Filler" &
                                 df$group=="PWA",])))
df_errors %>% group_by(group, session) %>% count(error) %>% 
  mutate(percentage=n/(nrow(df[df$category!="Filler" & df$group=="PWA" &
                                 df$session=="1",])))


table(df_errors$error_class, df_errors$error) # technical errors are not counted as errors
table(df_errors$error_class[is.na(df_errors$error)]) # correct responses
```


#### Amount of errors

```{r descriptives_errors_overall}
error_overview <- data.frame(subject=factor(rep(unique(df$subject), 
                                         each=5*3)),
                             group=factor(rep(c("PWA", "control"), 
                                       each=20*5*3)),
                             session=factor(rep(c("1","2","3"),
                                                each=5,
                                         times=
                                           length(unique(df$subject)))),
                             PosOr=factor(rep(c("1","2","3","4","5"),
                                         times=length(unique(df$subject))*3)),
                             error_class=0)
x <- df_errors %>% group_by(subject, session, PosOr) %>% 
  count(error_class) %>% 
  filter(error_class==1)
for(i in 1:nrow(x)){
  error_overview$error_class[error_overview$subject==x$subject[i] &
                         error_overview$session==x$session[i] &
                         error_overview$PosOr==x$PosOr[i] ] <- 
    x$n[i]
}
error_overview$percentage <- (error_overview$error_class/24)*100

(means_final_errors <- error_overview %>%  
    group_by(group,session,PosOr) %>% 
    summarise(count=sum(error_class), mean=mean(error_class),
              sd=sd(error_class), se=sd(error_class)/20,
              mean_p = mean(percentage),
              sd_p=sd(percentage), se_p=sd(percentage)/20))
 
# Export as word file
library(flextable)
huxt_word <- huxtable::huxtable(means_final_errors)
huxt_word <- huxtable::set_number_format(huxt_word, round(2))
huxtable::quick_docx(huxt_word, 
                     file = 
                       here::here(
                         "results", "tables",
                          "CSI_online_PWA_errors_by_session.docx"), 
                     open = FALSE)

```

Calculate increase mean by ordinal position, separately for each session (not controlled for random variances, weighted only per session):

```{r}
means_final_errors$increase_count <- NA
means_final_errors$increase_mean <- NA
for(k in 1:length(unique(means_final_errors$group))){
for(i in 1:length(unique(means_final_errors$session))){
  for(j in 2:length(unique(means_final_errors$PosOr))) {
    means_final_errors$increase_count[
      means_final_errors$session==unique(means_final_errors$session)[i] &
        means_final_errors$PosOr==unique(means_final_errors$PosOr)[j]&
                             means_final_errors$group==unique(means_final_errors$group)[k]] <- 
     means_final_errors$count[means_final_errors$session==
                                unique(means_final_errors$session)[i] &
                                means_final_errors$PosOr==
                                unique(means_final_errors$PosOr)[j]&
                             means_final_errors$group==unique(means_final_errors$group)[k]] - 
      means_final_errors$count[
        means_final_errors$session==
          unique(means_final_errors$session)[i] &
        means_final_errors$PosOr==
          unique(means_final_errors$PosOr)[j-1]&
                             means_final_errors$group==unique(means_final_errors$group)[k]]
    means_final_errors$increase_mean[
      means_final_errors$session==unique(means_final_errors$session)[i] &
        means_final_errors$PosOr==
        unique(means_final_errors$PosOr)[j]&
                             means_final_errors$group==unique(means_final_errors$group)[k]] <- 
     means_final_errors$mean[
       means_final_errors$session==unique(means_final_errors$session)[i] &
         means_final_errors$PosOr==unique(means_final_errors$PosOr)[j]&
         means_final_errors$group==unique(means_final_errors$group)[k]] -
      means_final_errors$mean[means_final_errors$session==
                                unique(means_final_errors$session)[i] &
                           means_final_errors$PosOr==
                             unique(means_final_errors$PosOr)[j-1]&
                            means_final_errors$group==
                             unique(means_final_errors$group)[k]]
  }}}
#means_final_errors

## Calculate overall mean increase per session (weighted: all PosOrs had the same amount of trials)
mean(means_final_errors$increase_mean[
  means_final_errors$session==1], na.rm=T)
means_final_errors$PosOr_effect <- NA
means_final_errors$PosOr_effect[means_final_errors$PosOr==1] <- 1
for(k in 1:length(unique(means_final_errors$group))){
for(i in 1:length(unique(means_final_errors$session))){
  means_final_errors$PosOr_effect[
    means_final_errors$session==unique(means_final_errors$session)[i] &
        means_final_errors$group==unique(means_final_errors$group)[k] &
        means_final_errors$PosOr=="1"] <-
    (means_final_errors$increase_mean[
      means_final_errors$session==unique(means_final_errors$session)[i] &
        means_final_errors$group==unique(means_final_errors$group)[k] &
        means_final_errors$PosOr=="2"]+
       means_final_errors$increase_mean[
         means_final_errors$session==
           unique(means_final_errors$session)[i] &
        means_final_errors$group==unique(means_final_errors$group)[k] &
        means_final_errors$PosOr=="3"]+
       means_final_errors$increase_mean[
         means_final_errors$session==
           unique(means_final_errors$session)[i] &
        means_final_errors$group==unique(means_final_errors$group)[k] &
        means_final_errors$PosOr=="4"]+
       means_final_errors$increase_mean[
         means_final_errors$session==
           unique(means_final_errors$session)[i] &
        means_final_errors$group==unique(means_final_errors$group)[k] &
        means_final_errors$PosOr=="5"])/4
}}
means_final_errors
```

### Plotting

#### Errors by ordinal position and repetition

```{r}
means_final_errors$session_group <- paste0(means_final_errors$group, 
                                           means_final_errors$session)
means_final_errors %>% rename(Session = session, Group = group) %>% 
  mutate(Group = factor(Group, levels=c("PWA", "control")))->
  means_final_errors

override.linetype<-c("dotted", "dashed")
(plot_error <- means_final_errors %>%
    ggplot(., aes(x=PosOr, y=mean_p, 
                  color = Session)) +
  geom_point(size = 2)+
  stat_summary(aes(x=PosOr, y=mean_p, group=session_group,
                  color = Session, linetype=Group),
               fun=mean,  geom="line", size = 0.5) +
  scale_linetype_manual(values=c("dotted", "dashed"))+
  scale_color_manual(values=c("#0072B2", "#E69F00", "#000000"))+
  geom_errorbar(
    aes(ymin=mean_p-se_p, ymax=mean_p+se_p, group = Session), width =.1) +
  apatheme+
  scale_y_continuous(breaks = seq(0, 40, by = 5), limits=c(0,35))+
      theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"))+
  labs(x="Ordinal Position ",y ="Percentage of errors"))

override.linetype<-c("solid", "dashed", "dotted")
(plot_error_PWA <- means_final_errors %>% filter(Group=="PWA") %>%
    ggplot(., aes(x=PosOr, y=mean_p, group=Session, color = Session)) +
  geom_point( size = 2)+
      stat_summary(aes(linetype=Session),fun=mean,  geom="line", 
                   size = 0.5) +
    scale_color_manual(values=c("#0072B2", "#E69F00", "#000000"))+
  geom_errorbar(aes(ymin=mean_p-se_p, ymax=mean_p+se_p, group = Session),
                width =.1) +
  apatheme+
  scale_y_continuous(breaks = seq(10,30, by = 5), limits=c(10,33))+
      theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
  guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
  labs(x="Ordinal Position ",y ="Percentage of errors", 
       title="Patients with Aphasia"))

(plot_error_control <- means_final_errors %>% filter(Group=="control") %>%
    ggplot(., aes(x=PosOr, y=mean_p, group=Session, color = Session)) +
  geom_point( size = 2)+
      stat_summary(aes(linetype=Session),fun=mean,  geom="line", 
                   size = 0.5) +
    scale_color_manual(values=c("#0072B2", "#E69F00", "#000000"))+
  geom_errorbar(aes(ymin=mean_p-se_p, ymax=mean_p+se_p, group = Session), width =.1) +
  apatheme+
  scale_y_continuous(breaks = seq(0, 5, by =1), limits=c(0,5.5))+
      theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"))+
  guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
  labs(x="Ordinal Position ",y ="Percentage of errors", 
       title="Control group"))


filename <- "CSI_online_spoken_plot_error.pdf"
ggsave(plot_error, filename = 
         here::here("results", "figures", filename),
       width = 18, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("data", "verbal_CSI", "Plots", filename))
 
ggsave(plot_error_PWA, filename = 
         here::here("results", "figures",
                    "CSI_online_spoken_plot_error_PWA.pdf"),
       width = 18, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
ggsave(plot_error_control, filename = 
         here::here("results", "figures",
                    "CSI_online_spoken_plot_error_control.pdf"),
       width = 18, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
```

#### Control: Plot Errors accross the experiment

```{r plot_errors_all}
(plot_errors_all <- ggplot(data=df_errors, 
                        aes(x=trial, y=error_class, linetype=session,
                              shape=session, color=group)) +
   stat_summary(aes(color=group, shape=session),fun=mean,  
                geom="point", size = 2)+
  apatheme+
  labs(x="Trial ",y ="Errors")+
  scale_color_manual(values=c(control_color, PWA_color)))

filename <- "CSI_online_aphasia_errors_across_experiment.pdf"
ggsave(plot_errors_all, filename = 
         here::here("results", "figures", filename),
       width = 18, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))
```

### GLMM with binomial distribution
#### Contrast coding
*Center predictor variable*

```{r}
df_errors_PWA <- df_errors %>% filter(group=="PWA") %>% droplevels()
df_errors_PWA$PosOr.cont <-
  c(scale(as.numeric(as.character(df_errors_PWA$PosOr)),
        center = T, scale = F))

df_errors$PosOr.cont <-
  c(scale(as.numeric(as.character(df_errors$PosOr)),
        center = T, scale = F))
```

*Contrast coding*

```{r}
# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_errors$session)<-my.simple
levels(df_errors$session)
contrasts(df_errors_PWA$session)<-my.simple
levels(df_RTs_PWA$session)

## Define contrast of group
contrasts(df_errors$group) <- MASS::contr.sdif(2)
levels(df_errors$group)
levels(df_errors_PWA$group)
```

#### Error analyses with factors Ordinal position x  Session x Group
*GLMM*

Compute the full model with the maximal random structure. If model fails to converge, increase optimizer iterations, exclude correlation parameters, andd step-wise reduce the random structure by excluding variables explaining close to zero variance. If the model converges, test whether it also converges with correlation parameters. 

```{r}
# m2_error <- glmer(error_class ~ PosOr.cont*session*group + 
#                     (PosOr.cont*session|subject) +
#                     (PosOr.cont*session*group|category) ,
#                   data =df_errors, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))

# 2) The model fit is singular -> increase optimizer iterations
# m2_error <- glmer(error_class ~ PosOr.cont*session + 
#                     (PosOr.cont*session|subject) +
#                     (PosOr.cont*session*group|category) ,
#                   data =df_errors, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

# 3) Further reduce by excluding correlation parameters
# m2_error <- afex::lmer_alt(error_class ~ PosOr.cont*session*group +
#                     (PosOr.cont*session||subject) +
#                     (PosOr.cont*session*group||category) ,
#                   data =df_errors, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

# 4) Model fit is still singular -> further reduce
# m2_error <- afex::lmer_alt(error_class ~ PosOr.cont*session*group +
#                     (PosOr.cont+session||subject) +
#                     (PosOr.cont*session*group-session-PosOr.cont:session-
#                        PosOr.cont:group-session:group||category) ,
#                   data =df_errors, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# m2_error <- afex::lmer_alt(error_class ~ PosOr.cont*session*group +
#                     (PosOr.cont||subject) +
#                     (PosOr.cont*session*group-
#                     session-PosOr.cont:session-
#                        PosOr.cont:group-
#                       session:group-PosOr.cont||category) ,
#                   data =df_errors, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
m2_error <- afex::lmer_alt(error_class ~ PosOr.cont*session*group +
                    (PosOr.cont||subject) +
                    (group||category) ,
                  data =df_errors, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
# rePCA(m2_error)
didLmerConverge(m2_error)
summary(m2_error)


# save model output
saveRDS(m2_error, file = here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_glmm_errors.RDS"))
tab_model(m2_error,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Binomial distribution) of Errors Predicted by Ordinal Position and Session, 
          PWA only",
          dv.labels = "Error Rate",
          #string.pred = "",
          string.stat = "z-Value",
          file = 
            here::here(
              "results", "tables",
              "CSI_online_aphasia_SessionxGroup_glmm_errors.html"))
```

Make the estimates interpretable 

```{r}
# Odds Ratio:
x <- data.frame(summary(m2_error)$coefficients)
x$Odds_Ratio <- plogis(x$Estimate)
x %>% dplyr::select(Estimate, Odds_Ratio) %>% 
  mutate(Estimate=round(Estimate,2),
         Odds_Ratio=round(Odds_Ratio,2))
```


#### PWA only
*GLMM*

```{r GLMM_errors}
# m1_error <- glmer(error_class ~ PosOr.cont*session + 
#                     (PosOr.cont*session|subject) +
#                     (PosOr.cont*session|category) ,
#                   data =df_errors_PWA, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))

# 2) The model fit is singular -> reduce optimizer iterations
# m1_error <- glmer(error_class ~ PosOr.cont*session + 
#                     (PosOr.cont*session|subject) +
#                     (PosOr.cont*session|category) ,
#                   data =df_errors_PWA, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

# 3) Further reduce by excluding correlation parameters
# m1_error <- afex::lmer_alt(error_class ~ PosOr.cont*session + 
#                     (PosOr.cont*session||subject) +
#                     (PosOr.cont*session||category) ,
#                   data =df_errors_PWA, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

# 4) Model fit is still singular -> further reduce
# m1_error <- afex::lmer_alt(error_class ~ PosOr.cont*session +
#                     (PosOr.cont*session||subject) +
#                     (1|category) ,
#                   data =df_errors_PWA, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
 # m1_error <- afex::lmer_alt(error_class ~ PosOr.cont*session + 
 #                    (PosOr.cont+session||subject) +
 #                    (1|category) ,
 #                  data =df_errors_PWA, family = "binomial",
 #                  control=glmerControl(optimizer = "bobyqa",
 #                                 optCtrl = list(maxfun = 2e5)))
m1_error <- glmer(error_class ~ PosOr.cont*session + 
                    (PosOr.cont |subject) +
                    (1|category) ,
                  data =df_errors_PWA, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
rePCA(m1_error)
didLmerConverge(m1_error)
summary(m1_error)

# save model output
saveRDS(m1_error, file = 
          here::here("results", "tables",
                     "CSI_online_aphasia_PWA_glmm_errors.RDS"))
tab_model(m1_error,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Binomial distribution) of Errors Predicted by Ordinal Position and Session, 
          PWA only",
          dv.labels = "Error Rate",
          string.stat = "z-Value",
          file = here::here(
            "results", "tables",
            "CSI_online_aphasia_PWA_glmm_errors.html"))
```

Make the estimates interpretable 

```{r}
# Odds Ratio:
x <- data.frame(summary(m1_error)$coefficients)
x$Odds_Ratio <- plogis(x$Estimate)
x %>% dplyr::select(Estimate, Odds_Ratio) %>% 
  mutate(Estimate=round(Estimate,2),
         Odds_Ratio=round(Odds_Ratio,2))
```

#### Exploratory follow-up: Make sure there is enough power in the control group

```{r}
# m2_error_control <- glmer(error_class ~ PosOr.cont*session +
#                     (PosOr.cont*session|subject) +
#                     (PosOr.cont*session|category) ,
#                   data =df_errors[df_errors$group=="control",], 
#                   family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))
# m2_error_control <- afex::lmer_alt(error_class ~ PosOr.cont*session +
#                     (PosOr.cont*session||subject) +
#                     (PosOr.cont*session||category) ,
#                   data =df_errors[df_errors$group=="control",], 
#                   family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))
# m2_error_control <- afex::lmer_alt(error_class ~ PosOr.cont*session +
#                     (1|subject) +
#                     (PosOr.cont*session-PosOr.cont-session||category) ,
#                   data =df_errors[df_errors$group=="control",], 
#                   family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa"))
m2_error_control <- glmer(error_class ~ PosOr.cont*session +
                    (1|subject) +
                    (1|category) ,
                  data =df_errors[df_errors$group=="control",], 
                  family = "binomial",
                  control=glmerControl(optimizer = "bobyqa"))

# rePCA(m2_error_control)
didLmerConverge(m2_error_control)
summary(m2_error_control)

# save model output
saveRDS(m2_error_control, file = here::here("results", "tables", "CSI_online_aphasia_Session_control_group_errors.RDS"))
tab_model(m2_error_control,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Binomial distribution) of Errors Predicted by Ordinal Position and Session, 
          Control group only",
          dv.labels = "Error Rate",
          #string.pred = "",
          string.stat = "z-Value",
          file = here::here(
            "results", "tables",
            "CSI_online_aphasia_Session_control_group_errors.html"))
```

# ---------------------------------------------
# Control analyses: Covariate tests (AAT, LEMO test, MPO, lesion size) 
Add covariates individually into the converging models, and use LRT to assess which covariates exlpain additional variance when added to the main model. Then conduct one model with all covariates that explain additional variance. 

### Add covariates

```{r}
read.csv2(here::here("data", "additional_data",
                     "questionnaire-test_data.csv")) -> tests


read.csv2(here::here("data", "additional_data",
                     "MRT_ROIs.csv")) -> mrt
mrt$Proband_in <- mrt$Proband_in+100
mrt$SoSci_ID <- toupper(mrt$SoSci_ID)
all(mrt$SoSci_ID %in% df_RTs_PWA$OR02_01) & 
  all(df_RTs_PWA$OR02_01 %in% mrt$SoSci_ID)
# table(df_RTs_PWA$subject)
```


Combine with PWA data 

```{r}
df_RTs_PWA$TokenTest <- NA
df_RTs_PWA$AAT <- NA
df_RTs_PWA$AAT_spontansprache <- NA
df_RTs_PWA$LEMO <- NA
df_RTs_PWA$mont_post_onset <- NA
df_RTs_PWA$LHoverall <- NA
df_RTs_PWA$ATL <- NA
df_RTs_PWA$IFG <- NA
df_RTs_PWA$MTG_ITG <- NA
df_RTs_PWA$SMG_AG <- NA
df_RTs_PWA$Precentral <- NA
df_RTs_PWA$ID <- NA
df_RTs_PWA$SoSci_ID <- NA
df_RTs_PWA$Proband_in <- NA
for(i in 1:nrow(mrt)){
  df_RTs_PWA$TokenTest[
    toupper(df_RTs_PWA$OR02_01) == toupper(tests$Code[i])] <-
    as.numeric(as.character(tests$Token.Test..Prozentrang.[i]))
  df_RTs_PWA$AAT[
    toupper(df_RTs_PWA$OR02_01) == toupper(tests$Code[i])] <-
    as.numeric(as.character(tests$AAT.Ben.gesamt..Prozentrang.[i]))
  df_RTs_PWA$AAT_spontansprache[
    toupper(df_RTs_PWA$OR02_01) == toupper(tests$Code[i])] <-
    as.numeric(as.character(tests$AAT.Untertest.Spontansprache.Semantik..Punktwert.Anzahl.korrekt.[i]))
  df_RTs_PWA$LEMO[
    toupper(df_RTs_PWA$OR02_01) == toupper(tests$Code[i])] <-
    as.numeric(as.character(tests$LEMO.V15.Syn.aud..Mit.Abl..n.40...Anz.korr[i]))
  df_RTs_PWA$months_post_onset[
    toupper(df_RTs_PWA$OR02_01) == toupper(tests$Code[i])] <-
    as.numeric(as.character(tests$MPO..months.post.onset.[i]))
  df_RTs_PWA$LHoverall[
    df_RTs_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
    as.numeric(as.character(mrt$LH.Gesamt[i]))
  df_RTs_PWA$ATL[
    df_RTs_PWA$OR02_01 == mrt$SoSci_ID[i]] <- 
     as.numeric(as.character(mrt$ATL[i]))
  df_RTs_PWA$IFG[
    df_RTs_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
     as.numeric(as.character(mrt$IFGorb.op.tri[i]))
  df_RTs_PWA$MTG_ITG[
    df_RTs_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
     as.numeric(as.character(mrt$MTG...ITG[i]))
  df_RTs_PWA$SMG_AG[
    df_RTs_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
     as.numeric(as.character(mrt$SMG...AG[i]))
  df_RTs_PWA$Precentral[
    df_RTs_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
     as.numeric(as.character(mrt$Precentral[i]))
  df_RTs_PWA$ID[
    df_RTs_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
     mrt$ID[i]
  df_RTs_PWA$SoSci_ID[
    df_RTs_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
     mrt$SoSci_ID[i]
  df_RTs_PWA$Proband_in[
    df_RTs_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
     as.numeric(as.character(mrt$Proband_in[i]))
}
sum(!(df_RTs_PWA$OR02_01==df_RTs_PWA$SoSci_ID), na.rm=T)

write.csv(df_RTs_PWA, here::here(
  "data", "additional_data",
  "CSI_online_aphasia_raw_data_for_RT_analyses_incl_MRT.csv"))


df_errors_PWA$TokenTest <- NA
df_errors_PWA$AAT <- NA
df_errors_PWA$AAT_spontansprache <- NA
df_errors_PWA$LEMO <- NA
df_errors_PWA$mont_post_onset <- NA
df_errors_PWA$LHoverall <- NA
df_errors_PWA$ATL <- NA
df_errors_PWA$IFG <- NA
df_errors_PWA$MTG_ITG <- NA
df_errors_PWA$SMG_AG <- NA
df_errors_PWA$Precentral <- NA
df_errors_PWA$ID <- NA
df_errors_PWA$SoSci_ID <- NA
df_errors_PWA$Proband_in <- NA
for(i in 1:nrow(mrt)){
  df_errors_PWA$TokenTest[
    toupper(df_errors_PWA$OR02_01) == toupper(tests$Code[i])] <-
    as.numeric(as.character(tests$Token.Test..Prozentrang.[i]))
  df_errors_PWA$AAT[
    toupper(df_errors_PWA$OR02_01) == toupper(tests$Code[i])] <-
    as.numeric(as.character(tests$AAT.Ben.gesamt..Prozentrang.[i]))
  df_errors_PWA$AAT_spontansprache[
    toupper(df_errors_PWA$OR02_01) == toupper(tests$Code[i])] <-
    as.numeric(as.character(
      tests$AAT.Untertest.Spontansprache.Semantik..Punktwert.Anzahl.korrekt.[i]))
  df_errors_PWA$LEMO[
    toupper(df_errors_PWA$OR02_01) == toupper(tests$Code[i])] <-
    as.numeric(as.character(
      tests$LEMO.V15.Syn.aud..Mit.Abl..n.40...Anz.korr[i]))
  df_errors_PWA$months_post_onset[
    toupper(df_errors_PWA$OR02_01) == toupper(tests$Code[i])] <-
    as.numeric(as.character(tests$MPO..months.post.onset.[i]))
  df_errors_PWA$LHoverall[
    df_errors_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
    as.numeric(as.character(mrt$LH.Gesamt[i]))
  df_errors_PWA$ATL[
    df_errors_PWA$OR02_01 == mrt$SoSci_ID[i]] <- 
     as.numeric(as.character(mrt$ATL[i]))
  df_errors_PWA$IFG[
    df_errors_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
     as.numeric(as.character(mrt$IFGorb.op.tri[i]))
  df_errors_PWA$MTG_ITG[
    df_errors_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
     as.numeric(as.character(mrt$MTG...ITG[i]))
  df_errors_PWA$SMG_AG[
    df_errors_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
     as.numeric(as.character(mrt$SMG...AG[i]))
  df_errors_PWA$Precentral[
    df_errors_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
     as.numeric(as.character(mrt$Precentral[i]))
  df_errors_PWA$ID[
    df_errors_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
     mrt$ID[i]
  df_errors_PWA$SoSci_ID[
    df_errors_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
     mrt$SoSci_ID[i]
  df_errors_PWA$Proband_in[
    df_errors_PWA$OR02_01 == mrt$SoSci_ID[i]] <-
     as.numeric(as.character(mrt$Proband_in[i]))
}
sum(!(df_errors_PWA$OR02_01==df_errors_PWA$SoSci_ID), na.rm=T)

write.csv(df_errors_PWA, here::here(
  "data", "additional_data",
  "CSI_online_aphasia_raw_data_for_error_analyses_incl_MRT.csv"))
```

### Add tests individually and assess whehther they explain additional variance

#### AAT: Token test
##### RTs
Add into converging model 

```{r}
df_RTs_PWA$PosOr.cont <- scale(as.numeric(as.character(df_RTs_PWA$PosOr)),
                                        center = T, scale = F)
table(df_RTs_PWA$PosOr.cont)
mean(df_RTs_PWA$PosOr.cont); sd(df_RTs_PWA$PosOr.cont)

# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_RTs_PWA$session)<-my.simple
levels(df_RTs_PWA$session)

## Center token test
df_RTs_PWA$TokenTest_c <- scale(df_RTs_PWA$TokenTest, center=T, scale=T)
```


```{r}
m1_lmm_PWA_tt <- lmer(VOTlog ~ PosOr.cont*session*TokenTest_c +
               (PosOr.cont+session|subject) +
              (1|category),
             data = df_RTs_PWA,
            control=lmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_lmm_PWA_tt)
## Warnings can be ignored

# summary(m1_lmm_PWA_tt)
# anova(m1_lmm_PWA_tt)
# 
# saveRDS(m1_lmm_PWA_tt,  file = here::here("results", "tables", "CSI_online_aphasia_PWA_lmm_VOT_plus-Token-Test.RDS"))
# tab_model(m1_lmm_PWA_tt,transform = NULL,
#           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
#           title = "LMM of VOTs Predicted by Ordinal Position and Session",
#           df.method = "satterthwaite",
#           dv.labels = "Vocal Onset Time (log-transformed)",
#           #string.pred = "",
#           string.stat = "t-Value",
#           file = here::here(
#             "results", "tables",
#             "CSI_online_aphasia_PWA_control_lmm_VOT_TokenTest.html"))
```

Does the model with Token test fit the data better? -> yes! 

```{r}
#summary(m1_lmm_PWA)
anova(m1_lmm_PWA, m1_lmm_PWA_tt)
```

##### Errors

Add into converging model 

```{r}
df_errors_PWA$PosOr.cont <- scale(as.numeric(as.character(df_errors_PWA$PosOr)),
                                        center = T, scale = F)
# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_errors_PWA$session)<-my.simple
levels(df_errors_PWA$session)

## Center token test
df_errors_PWA$TokenTest_c <- 
  scale(df_errors_PWA$TokenTest, center=T, scale=T)
```

```{r}
m1_glmm_PWA_tt <- glmer(error_class ~ PosOr.cont*session*TokenTest_c + 
                    (PosOr.cont |subject) +
                    (1|category) ,
                  data =df_errors_PWA, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_glmm_PWA_tt)
## Warnings can be ignored

# summary(m1_glmm_PWA_tt)
# anova(m1_glmm_PWA_tt)
# 
# saveRDS(m1_glmm_PWA_tt,  file = here::here("results", "tables", "CSI_online_aphasia_PWA_lmm_error_plus-Token-Test.RDS"))
# tab_model(m1_glmm_PWA_tt,transform = NULL,
#           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
#           title = "GLMM of errors Predicted by Ordinal Position and Session",
#           dv.labels = "Errors",
#           #string.pred = "",
#           string.stat = "z-Value",
#           file = here::here(
#             "results", "tables",
#             "CSI_online_aphasia_PWA_control_glmm_error_TokenTest.html"))
```

Does the model with Token test fit the data better? -> yes! 

```{r}
#summary(m1_lmm_PWA)
anova(m1_error, m1_glmm_PWA_tt)
```

#### AAT: Naming test
##### RTs
Add into converging model 

```{r}
df_RTs_PWA$PosOr.cont <- scale(as.numeric(as.character(df_RTs_PWA$PosOr)),
                                        center = T, scale = F)
table(df_RTs_PWA$PosOr.cont)
mean(df_RTs_PWA$PosOr.cont); sd(df_RTs_PWA$PosOr.cont)

# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_RTs_PWA$session)<-my.simple
levels(df_RTs_PWA$session)

## Center naming test
df_RTs_PWA$AAT_c <- scale(df_RTs_PWA$AAT, center=T, scale=T)
```


```{r}
m1_lmm_PWA_aat <- lmer(VOTlog ~ PosOr.cont*session*AAT_c +
               (PosOr.cont+session|subject) +
              (1|category),
             data = df_RTs_PWA,
            control=lmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_lmm_PWA_aat)
## Warnings can be ignored

# summary(m1_lmm_PWA_aat)
# anova(m1_lmm_PWA_aat)
# 
# saveRDS(m1_lmm_PWA_aat,  file = here::here("results", "tables", "CSI_online_aphasia_PWA_lmm_VOT_plus-AachenAphhasie.RDS"))
# tab_model(m1_lmm_PWA_aat,transform = NULL,
#           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
#           title = "LMM of VOTs Predicted by Ordinal Position and Session",
#           df.method = "satterthwaite",
#           dv.labels = "Vocal Onset Time (log-transformed)",
#           #string.pred = "",
#           string.stat = "t-Value",
#           file = here::here(
#             "results", "tables",
#             "CSI_online_aphasia_PWA_control_lmm_VOT_AachenAphase.html"))
```

Does the model with Token test fit the data better? -> yes! 

```{r}
#summary(m1_lmm_PWA)
anova(m1_lmm_PWA, m1_lmm_PWA_aat)
```

##### Errors

Add into converging model 

```{r}
df_errors_PWA$PosOr.cont <- scale(as.numeric(as.character(df_errors_PWA$PosOr)),
                                        center = T, scale = F)

# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_errors_PWA$session)<-my.simple
levels(df_errors_PWA$session)

## Center naming test
df_errors_PWA$AAT_c <- scale(df_errors_PWA$AAT, center=T, scale=T)
```

```{r}
m1_glmm_PWA_aat <- glmer(error_class ~ PosOr.cont*session*AAT_c + 
                    (PosOr.cont |subject) +
                    (1|category) ,
                  data =df_errors_PWA, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_glmm_PWA_aat)
## Warnings can be ignored

# summary(m1_glmm_PWA_aat)
# anova(m1_glmm_PWA_aat)
# 
# saveRDS(m1_glmm_PWA_aat,  file = here::here(
#   "results", "tables", "CSI_online_aphasia_PWA_lmm_error_plus-AAT.RDS"))
# tab_model(m1_glmm_PWA_aat,transform = NULL,
#           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
#           title = "GLMM of errors Predicted by Ordinal Position and Session",
#           dv.labels = "Errors",
#           #string.pred = "",
#           string.stat = "z-Value",
#           file = here::here(
#             "results", "tables",
#             "CSI_online_aphasia_PWA_control_glmm_error_AAT.html"))
```

Does the model with Naming subtest fit the data better? -> yes! 

```{r}
#summary(m1_lmm_PWA)
anova(m1_error, m1_glmm_PWA_aat)
```

#### AAT: Spontaneous speech test
##### RTs
Add into converging model 

```{r}
df_RTs_PWA$PosOr.cont <- scale(as.numeric(as.character(df_RTs_PWA$PosOr)),
                                        center = T, scale = F)
table(df_RTs_PWA$PosOr.cont)
mean(df_RTs_PWA$PosOr.cont); sd(df_RTs_PWA$PosOr.cont)

# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_RTs_PWA$session)<-my.simple
levels(df_RTs_PWA$session)

## Center spontaneous speech test
df_RTs_PWA$AAT_spontansprache_c <- 
  scale(df_RTs_PWA$AAT_spontansprache, center=T, scale=T)
```


```{r}
m1_lmm_PWA_aat_spontansprache <- lmer(
  VOTlog ~ PosOr.cont*session*AAT_spontansprache_c +
               (PosOr.cont+session|subject) +
              (1|category),
             data = df_RTs_PWA,
            control=lmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_lmm_PWA_aat_spontansprache)
## Model converges


# summary(m1_lmm_PWA_aat_spontansprache)
# anova(m1_lmm_PWA_aat_spontansprache)
# 
# saveRDS(m1_lmm_PWA_spontansprache,  file = here::here("results", "tables", "CSI_online_aphasia_PWA_lmm_VOT_plus-AachenAphhasie_Spontansprache.RDS"))
# tab_model(m1_lmm_aat_spontansprache,transform = NULL,
#           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
#           title = "LMM of VOTs Predicted by Ordinal Position and Session",
#           df.method = "satterthwaite",
#           dv.labels = "Vocal Onset Time (log-transformed)",
#           #string.pred = "",
#           string.stat = "t-Value",
#           file = here::here(
#             "results", "tables", "CSI_online_aphasia_PWA_control_lmm_VOT_AachenAphase_Spontansprache.html"))
```

Does the model with Token test fit the data better? -> no, only a trend. 

```{r}
#summary(m1_lmm_PWA)
anova(m1_lmm_PWA, m1_lmm_PWA_aat_spontansprache)
```


##### Errors

Add into converging model 

```{r}
df_errors_PWA$PosOr.cont <-
  scale(as.numeric(as.character(df_errors_PWA$PosOr)),
                                        center = T, scale = F)
# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_errors_PWA$session)<-my.simple
levels(df_errors_PWA$session)

## Center spontenous speech test
df_errors_PWA$AAT_spontansprache_c <- 
  scale(df_errors_PWA$AAT_spontansprache, center=T, scale=T)
```

```{r}
m1_glmm_PWA_aat_spontan <- glmer(error_class ~ PosOr.cont*session*
                                   AAT_spontansprache_c + 
                    (PosOr.cont |subject) +
                    (1|category) ,
                  data =df_errors_PWA, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_glmm_PWA_aat_spontan)
## Warnings can be ignored

# summary(m1_glmm_PWA_aat_spontan)
# anova(m1_glmm_PWA_aat_spontan)
# 
# saveRDS(m1_glmm_PWA_aat_spontan,  file = here::here("results", "tables", "CSI_online_aphasia_PWA_lmm_error_plus-AAT_spontansprache.RDS"))
# tab_model(m1_glmm_PWA_aat_spontan,transform = NULL,
#           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
#           title = "GLMM of errors Predicted by Ordinal Position and Session",
#           dv.labels = "Errors",
#           #string.pred = "",
#           string.stat = "z-Value",
#           file = here::here("results", "tables", "CSI_online_aphasia_PWA_control_glmm_error_AAT_spontansprache.html"))
```

Does the model with spontenous speech test fit the data better? -> yes! 

```{r}
#summary(m1_lmm_PWA)
anova(m1_error, m1_glmm_PWA_aat_spontan)
```

#### LEMO
##### RTs
Add into converging model 

```{r}
df_RTs_PWA$PosOr.cont <- 
  scale(as.numeric(as.character(df_RTs_PWA$PosOr)),
        center = T, scale = F)
table(df_RTs_PWA$PosOr.cont)
mean(df_RTs_PWA$PosOr.cont); sd(df_RTs_PWA$PosOr.cont)

# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_RTs_PWA$session)<-my.simple
levels(df_RTs_PWA$session)

## Center LEMO test
df_RTs_PWA$LEMO_c <- scale(df_RTs_PWA$LEMO, center=T, scale=T)
```

```{r}
m1_lmm_PWA_lemo <- lmer(VOTlog ~ PosOr.cont*session*LEMO_c +
               (PosOr.cont+session|subject) +
              (1|category),
             data = df_RTs_PWA,
            control=lmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_lmm_PWA_lemo)
## Warnings can be ignored

# summary(m1_lmm_PWA_lemo)
# anova(m1_lmm_PWA_lemo)
# 
# saveRDS(m1_lmm_PWA_lemo,  file = here::here(
#   "results", "tables", "CSI_online_aphasia_PWA_lmm_VOT_plus-LEMO.RDS"))
# tab_model(m1_lmm_PWA_lemo,transform = NULL,
#           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
#           title = "LMM of VOTs Predicted by Ordinal Position and Session",
#           df.method = "satterthwaite",
#           dv.labels = "Vocal Onset Time (log-transformed)",
#           #string.pred = "",
#           string.stat = "t-Value",
#           file = here::here(
#             "results", "tables",
#             "CSI_online_aphasia_PWA_control_lmm_VOT_LEMO.html"))
```

Does the model with LEMO fit the data better? -> no! (but a trend)

```{r}
#summary(m1_lmm_PWA)
anova(m1_lmm_PWA, m1_lmm_PWA_lemo)
```


##### Errors

Add into converging model 

```{r}
df_errors_PWA$PosOr.cont <- scale(as.numeric(as.character(df_errors_PWA$PosOr)),
                                        center = T, scale = F)

# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_errors_PWA$session)<-my.simple
levels(df_errors_PWA$session)

## Center LEMO test
df_errors_PWA$LEMO_c <- scale(df_errors_PWA$LEMO, center=T, scale=T)
```

*Compute further contrasts*

```{r}
m1_glmm_PWA_lemo <- glmer(error_class ~ PosOr.cont*session*LEMO_c + 
                    (PosOr.cont |subject) +
                    (1|category) ,
                  data =df_errors_PWA, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_glmm_PWA_lemo)
## Warnings can be ignored

# summary(m1_glmm_PWA_lemo)
# anova(m1_glmm_PWA_lemo)
# 
# saveRDS(m1_glmm_PWA_lemo,  file = here::here("results", "tables", "CSI_online_aphasia_PWA_lmm_error_plus-lemo.RDS"))
# tab_model(m1_glmm_PWA_lemo,transform = NULL,
#           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
#           title = "GLMM of errors Predicted by Ordinal Position and Session",
#           dv.labels = "Errors",
#           #string.pred = "",
#           string.stat = "z-Value",
#           file = here::here(
#             "results", "tables",
#             "CSI_online_aphasia_PWA_control_glmm_error_Lemo.html"))
```

Does the model with LEMO test fit the data better? -> no! 

```{r}
#summary(m1_lmm_PWA)
anova(m1_error, m1_glmm_PWA_lemo)
```

#### Time since stroke
##### RTs
Add into converging model 

```{r}
df_RTs_PWA$PosOr.cont <- scale(as.numeric(as.character(df_RTs_PWA$PosOr)),
                                        center = T, scale = F)
table(df_RTs_PWA$PosOr.cont)
mean(df_RTs_PWA$PosOr.cont); sd(df_RTs_PWA$PosOr.cont)

# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_RTs_PWA$session)<-my.simple
levels(df_RTs_PWA$session)

## Center months post onset
df_RTs_PWA$months_post_onset_c <- scale(df_RTs_PWA$months_post_onset,
                                        center=T, scale=T)
```

```{r}
m1_lmm_PWA_MPO <- lmer(VOTlog ~ PosOr.cont*session*months_post_onset_c +
               (PosOr.cont+session|subject) +
              (1|category),
             data = df_RTs_PWA,
            control=lmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_lmm_PWA_MPO)
## Warnings can be ignored

# summary(m1_lmm_PWA_MPO)
# anova(m1_lmm_PWA_MPO)
# 
# saveRDS(m1_lmm_PWA_MPO,  file = here::here(
#   "results", "tables", "CSI_online_aphasia_PWA_lmm_VOT_plus-MPO.RDS"))
# tab_model(m1_lmm_PWA_MPO,transform = NULL,
#           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
#           title = "LMM of VOTs Predicted by Ordinal Position and Session",
#           df.method = "satterthwaite",
#           dv.labels = "Vocal Onset Time (log-transformed)",
#           #string.pred = "",
#           string.stat = "t-Value",
#           file = here::here(
#             "results", "tables",
#             "CSI_online_aphasia_PWA_control_lmm_VOT_MPO.html"))
```

Does the model with MPO fit the data better? -> no!

```{r}
#summary(m1_lmm_PWA)
anova(m1_lmm_PWA, m1_lmm_PWA_MPO)
```


##### Errors

Add into converging model 

```{r}
df_errors_PWA$PosOr.cont <-
  scale(as.numeric(as.character(df_errors_PWA$PosOr)),
                                        center = T, scale = F)

# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_errors_PWA$session)<-my.simple
levels(df_errors_PWA$session)

## Center months post onse
df_errors_PWA$MPO_c <- 
  scale(df_errors_PWA$months_post_onset, center=T, scale=T)
```


```{r}
m1_glmm_PWA_MPO <- glmer(error_class ~ PosOr.cont*session*MPO_c + 
                    (PosOr.cont |subject) +
                    (1|category) ,
                  data =df_errors_PWA, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_glmm_PWA_MPO)
## Warnings can be ignored

# summary(m1_glmm_PWA_MPO)
# anova(m1_glmm_PWA_MPO)
# 
# saveRDS(m1_glmm_PWA_MPO,  file = here::here(
#   "results", "tables", "CSI_online_aphasia_PWA_lmm_error_plus-MPO.RDS"))
# tab_model(m1_glmm_PWA_MPO,transform = NULL,
#           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
#           title = 
#             "GLMM of errors Predicted by Ordinal Position and Session",
#           #df.method = "satterthwaite",
#           dv.labels = "Errors",
#           #string.pred = "",
#           string.stat = "z-Value",
#           file = here::here(
#             "results", "tables",
#             "CSI_online_aphasia_PWA_control_glmm_error_MPO.html"))
```

Does the model with MPO fit the data better? -> no! 

```{r}
#summary(m1_lmm_PWA)
anova(m1_error, m1_glmm_PWA_MPO)
```

#### Lesion size
##### RTs

```{r}
df_RTs_PWA$LHoverall_c <- scale(df_RTs_PWA$LHoverall, center=T, scale=F)

m1_lmm_PWA_LH <- lmer(VOTlog ~ PosOr.cont*session*LHoverall_c +
               (PosOr.cont+session|subject) +
              (1|category),
             data = df_RTs_PWA,
            control=lmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_lmm_PWA_LH)
## Warnings can be ignored

# summary(m1_lmm_PWA_LH)
# anova(m1_lmm_PWA_LH)
# 
# saveRDS(m1_lmm_PWA_LH,  file = here::here("results", "tables",
#       "CSI_online_aphasia_PWA_lmm_VOT_plus-Lesion-size.RDS"))
# tab_model(m1_lmm_PWA_LH,transform = NULL,
#           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
#           title = "LMM of VOTs Predicted by Ordinal Position and Session",
#           df.method = "satterthwaite",
#           dv.labels = "Vocal Onset Time (log-transformed)",
#           #string.pred = "",
#           string.stat = "t-Value",
#           file = here::here(
#             "results", "tables",
#             "CSI_online_aphasia_PWA_control_lmm_VOT_Lesion-size.html"))
```

Does the model with lesion size fit the data better? -> no! 

```{r}
#summary(m1_lmm_PWA)
anova(m1_lmm_PWA, m1_lmm_PWA_LH)
```

##### Errors

Add into converging model 

```{r}
df_errors_PWA$PosOr.cont <- scale(as.numeric(as.character(df_errors_PWA$PosOr)),
                                        center = T, scale = F)
# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_errors_PWA$session)<-my.simple
levels(df_errors_PWA$session)
## Center lesion size
df_errors_PWA$LHoverall_c <- scale(df_errors_PWA$LHoverall, center=T, scale=T)
```


```{r}
m1_glmm_PWA_LH <- glmer(error_class ~ PosOr.cont*session*LHoverall_c + 
                    (PosOr.cont |subject) +
                    (1|category) ,
                  data =df_errors_PWA, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_glmm_PWA_LH)
## Warnings can be ignored

# summary(m1_glmm_PWA_LH)
# anova(m1_glmm_PWA_LH)
# 
# saveRDS(m1_glmm_PWA_LH,  file = here::here("results", "tables", "CSI_online_aphasia_PWA_lmm_error_plus-Lesion-size.RDS"))
# tab_model(m1_glmm_PWA_LH,transform = NULL,
#           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
#           title = "GLMM of errors Predicted by Ordinal Position and Session",
#           dv.labels = "Errors",
#           #string.pred = "",
#           string.stat = "z-Value",
#           file = here::here(
#             "results", "tables",
#             "CSI_online_aphasia_PWA_control_glmm_error_LH.html"))
```

Does the model with Token test fit the data better? -> yes! 

```{r}
#summary(m1_lmm_PWA)
anova(m1_error, m1_glmm_PWA_LH)
```


### Add covariates explaining significant variance in a single model 
#### RTs
Add Token Test and Naming Test into converging model. 

```{r}
cor.test(df_RTs_PWA$AAT_c, df_RTs_PWA$TokenTest_c)

df_RTs_PWA$PosOr.cont <- scale(as.numeric(as.character(df_RTs_PWA$PosOr)),
                                        center = T, scale = F)
# define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE)
c<-contr.treatment(3)
my.coding<-matrix(rep(1/3, 6), ncol=2)
my.simple<-c-my.coding
my.simple
contrasts(df_RTs_PWA$session)<-my.simple
levels(df_RTs_PWA$session)

## Center token test and Naming test
df_RTs_PWA$TokenTest_c <- scale(df_RTs_PWA$TokenTest, center=T, scale=T)
df_RTs_PWA$AAT_c <- scale(df_RTs_PWA$AAT, center=T, scale=T)


m1_lmm_PWA_tt_aat <- lmer(VOTlog ~ PosOr.cont*session*(TokenTest_c*AAT_c)+
               (PosOr.cont+session|subject) +
              (1|category),
             data = df_RTs_PWA,
            control=lmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1_lmm_PWA_tt_aat)
## Warnings can be ignored

summary(m1_lmm_PWA_tt_aat)
anova(m1_lmm_PWA_tt_aat)

saveRDS(m1_lmm_PWA_tt_aat,  file = here::here("results", "tables",
 "CSI_online_aphasia_PWA_lmm_VOT_plus-TokenTest-plus-AachenAphhasie.RDS"))
tab_model(m1_lmm_PWA_tt_aat,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "LMM of VOTs Predicted by Ordinal Position and Session",
          df.method = "satterthwaite",
          dv.labels = "Vocal Onset Time (log-transformed)",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here(
            "results", "tables",
    "CSI_online_aphasia_PWA_control_lmm_VOT_TokenTestAachenAphase.html"))
```

Main effect of Naming Test. Trend between Ordinal position and Session 2-1 x Token Test x Naming and Ordinal position x Session2-1

Does the model with Naming and Token test fit the data better? -> no (Trend)! 
Does the model with Naming and Token test fit the data better than the model only with Naming? -> no! => The variance explained by the token Test is also explained by the naming test
Does the model with Naming test fit the data better than the main model? -> yes! 

```{r}
#summary(m1_lmm_PWA)
anova(m1_lmm_PWA, m1_lmm_PWA_tt_aat)
anova(m1_lmm_PWA_aat, m1_lmm_PWA_tt_aat)
anova(m1_lmm_PWA, m1_lmm_PWA_aat)
```

##### Plot Naming test

```{r }
(means_final<- df_RTs_PWA %>% 
   filter(category != "Filler") %>% 
   Rmisc::summarySEwithin(.,"VOT",idvar = "category",
                          withinvars = c("session", "PosOr"), 
                          betweenvars = c("subject", "AAT"), na.rm = T))

override.linetype<-c("dashed")
(plot_rt_repetition_PWA_session1 <- means_final %>% 
    filter(session=="1") %>% 
    ggplot(., aes(x=PosOr, y=VOT, group=AAT, color = AAT)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=AAT, color=AAT),
                 fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("dashed"))+
    scale_colour_manual(values=c("#feedec", "#fdcac6", "#fca7a0",
                                          "#fb8479", "#fa6153",
                                          "#f93e2d", "#f81b07",
                                          "#d21706", "#ac1305", 
                                          "#860f04", "#5f0b03",
                                          "#390602", "#130201"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, group = AAT), width =.1) +
    apatheme+
    scale_y_continuous(limits = c(600, 2400), 
                       breaks =seq(800,2400, by = 200)) +
    labs(x="Ordinal Position ",y ="RT (ms)", colour="Session",
         linetype="Session",
         title = "Session 1") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))

(plot_rt_repetition_PWA_session2 <- means_final %>% 
    filter(session=="2") %>% 
    ggplot(., aes(x=PosOr, y=VOT, group=AAT, color = AAT)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=AAT, color=AAT),
                 fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("dashed"))+
    scale_colour_manual(values=c("#feedec", "#fdcac6", "#fca7a0",
                                          "#fb8479", "#fa6153",
                                          "#f93e2d", "#f81b07",
                                          "#d21706", "#ac1305", 
                                          "#860f04", "#5f0b03",
                                          "#390602", "#130201"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, group = AAT), width =.1) +
    apatheme+
    scale_y_continuous(limits = c(600, 2400), 
                       breaks =seq(800,2400, by = 200)) +
    labs(x="Ordinal Position ",y ="RT (ms)", colour="Session",
         linetype="Session",
         title = "Session 2") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))


(plot_rt_repetition_PWA_session3 <- means_final %>% 
    filter(session=="3") %>% 
    ggplot(., aes(x=PosOr, y=VOT, group=AAT, color = AAT)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=AAT, color=AAT),
                 fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("dashed"))+
    scale_colour_manual(values=c("#feedec", "#fdcac6", "#fca7a0",
                                          "#fb8479", "#fa6153",
                                          "#f93e2d", "#f81b07",
                                          "#d21706", "#ac1305", 
                                          "#860f04", "#5f0b03",
                                          "#390602", "#130201"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, group = AAT), width =.1) +
    apatheme+
    scale_y_continuous(limits = c(600, 2400), 
                       breaks =seq(800,2400, by = 200)) +
    labs(x="Ordinal Position ",y ="RT (ms)", colour="Naming score",
        # linetype="Session",
         title = "Session 3") +
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="right")+
    scale_linetype(guide="none"))


plots <- cowplot::plot_grid(plot_rt_repetition_PWA_session1,
                            plot_rt_repetition_PWA_session2,
                            plot_rt_repetition_PWA_session3,
          nrow = 1, ncol=3,  rel_widths = c(0.81,0.81,1), 
          margin(1,1,1,1),
          labels = c("B", "C", "D"),label_size = 34,
                    label_fontfamily = "Helvetica", label_y = 1.01,
          label_x=-0.03)
filename <- "CSI_online_aphasia_spoken_plot_PWA_AAT_scores.pdf"
ggsave(plots, filename = 
         here::here("results", "figures", filename),
       width = 25, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))


#### Trying to understand the interaction: 
# median split of means final 
median(as.numeric(as.character(means_final$AAT)))
means_final %>% 
  mutate(med_split=case_when(as.numeric(as.character(AAT)) > 
                               median(as.numeric(as.character(
                                               means_final$AAT))) ~"high",
                              as.numeric(as.character(AAT)) < 
                                median(as.numeric(as.character(
                              means_final$AAT))) ~ "low",
                               as.numeric(as.character(AAT)) == 
                               median(as.numeric(as.character(
                                               means_final$AAT))) ~
                               "median"),
                       mean_split=case_when(
                         as.numeric(as.character(AAT)) > 
                           mean(as.numeric(as.character(
                             means_final$AAT))) ~ "high",
                         as.numeric(as.character(AAT)) < 
                           mean(as.numeric(as.character(
                             means_final$AAT))) ~ "low",
                         as.numeric(as.character(AAT)) == 
                           mean(as.numeric(as.character(
                             means_final$AAT))) ~ "median")) ->
  means_final

means_final %>% group_by(med_split) %>% summarise(mean=mean(VOT),
                                                  sd = sd(VOT))
means_final %>% group_by(mean_split) %>% summarise(mean=mean(VOT),
                                                  sd = sd(VOT))



(means_final<- df_RTs_PWA %>% 
   filter(category != "Filler") %>% 
   Rmisc::summarySE(.,measurevar="VOT",
                          groupvars = c("subject","AAT"), na.rm = T))

(plot_rt_PWA_AAT <- means_final %>% 
    ggplot(., aes(x=AAT, y=VOT)) +
    geom_point(size = 2)+
    scale_colour_manual(values=c("#feedec", "#fdcac6", "#fca7a0",
                                          "#fb8479", "#fa6153",
                                          "#f93e2d", "#f81b07",
                                          "#d21706", "#ac1305",
                                          "#860f04", "#5f0b03",
                                          "#390602", "#130201"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, group = AAT), width =.1) +
    apatheme+
    scale_y_continuous(limits = c(600, 2400), 
                       breaks =seq(800,2400, by = 200)) +
    labs(x="Naming test percentile score ",y ="RT (ms)", colour="Naming score",
        # linetype="Session",
         title = "Mean RTs across sessions and\nordinal positions by Naming test score") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
    scale_linetype(guide="none"))

filename <- "CSI_online_aphasia_spoken_plot_PWA_AAT.pdf"
ggsave(plot_rt_PWA_AAT, filename = 
         here::here("results", "figures", filename),
       width = 15, height = 10, units = "cm", 
       dpi = 300, device = cairo_pdf)


plots2 <- cowplot::plot_grid(plot_rt_PWA_AAT, plots,
          nrow = 2, ncol=c(1,3),  rel_widths = c(0.81,0.81,1), 
          rel_height = c(4,1),
          margin(1.5,1.5,1.5,1.5),
          labels = c("A", ""),label_size = 34,
                    label_fontfamily = "Helvetica", label_y = 1.01,
          label_x=-0.03)
filename <- "CSI_online_aphasia_spoken_plot_PWA_AAT_summary_plot.pdf"
ggsave(plots2, filename = 
         here::here("results", "figures", filename),
       width = 25, height = 20, units = "cm", 
       dpi = 300, device = cairo_pdf)

```


#### Errors

Add into converging model 

```{r}
cor.test(df_errors_PWA$TokenTest_c, df_errors_PWA$LHoverall_c)
cor.test(df_errors_PWA$AAT_c, df_errors_PWA$LHoverall_c)
cor.test(df_errors_PWA$AAT_c, df_errors_PWA$TokenTest_c)
cor.test(df_errors_PWA$AAT_spontansprache, df_errors_PWA$TokenTest_c)
# m1_glmm_PWA_all <- glmer(error_class ~
#                           PosOr.cont*session*TokenTest_c*AAT_c*LHoverall_c + 
#                     (PosOr.cont |subject) +
#                     (1|category) ,
#                   data =df_errors_PWA, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# m1_glmm_PWA_all <- afex::lmer_alt(error_class ~
#                           PosOr.cont*session*(TokenTest_c*AAT_c*
#                                                 AAT_spontansprache_c*
#                                                 LHoverall_c) + 
#                     (PosOr.cont |subject) +
#                     (1|category) ,
#                   data =df_errors_PWA, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

m1_glmm_PWA_all <- afex::lmer_alt(error_class ~
                          PosOr.cont*session*(TokenTest_c+AAT_c+
                                                AAT_spontansprache_c+
                                                LHoverall_c) + 
                    (PosOr.cont |subject) +
                    (1|category) ,
                  data =df_errors_PWA, family = "binomial",
                  control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))

# m1_glmm_PWA_all <- afex::lmer_alt(error_class ~
#                           PosOr.cont*session*(TokenTest_c*AAT_c*
#                                                 LHoverall_c) +
#                     (PosOr.cont |subject) +
#                     (1|category) ,
#                   data =df_errors_PWA, family = "binomial",
#                   control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))

didLmerConverge(m1_glmm_PWA_all)
## Warnings can be ignored

summary(m1_glmm_PWA_all)
anova(m1_glmm_PWA_all)

saveRDS(m1_glmm_PWA_all,  file = here::here("results", "tables", "CSI_online_aphasia_PWA_lmm_error_TokenTest_Naming_Lesionsize.RDS"))
tab_model(m1_glmm_PWA_tt,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = 
            "GLMM of errors Predicted by Ordinal Position and Session",
          dv.labels = "Errors",
          #string.pred = "",
          string.stat = "z-Value",
          file = here::here(
            "results", "tables",
            "CSI_online_aphasia_PWA_control_glmm_error_TokenTest_Naming_Lesionsize.html"))
```

###### Plot errors and Tests

```{r }
(means_final<- df_errors_PWA %>% 
   filter(category != "Filler") %>% 
   Rmisc::summarySEwithin(.,"error_class",idvar = "category",
                          withinvars = c("session", "PosOr"), 
                          betweenvars = c("subject", "AAT", "TokenTest",
                                          "AAT_spontansprache"),
                          na.rm = T))

override.linetype<-c("dashed")
(plot_error_repetition_PWA_session1_Naming <- 
    means_final %>% filter(session=="1") %>% 
    ggplot(., aes(x=PosOr, y=error_class, group=subject, color = AAT)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=AAT, color=AAT),
                 fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("dashed"))+
    scale_colour_manual(values=c("#feedec", "#fdcac6", "#fca7a0",
                                          "#fb8479", "#fa6153",
                                          "#f93e2d", "#f81b07",
                                          "#d21706", "#ac1305", 
                                          "#860f04", "#5f0b03",
                                          "#390602", "#130201"))+
    geom_errorbar(
      aes(ymin=error_class-se, ymax=error_class+se, group = AAT),
                  width =.1) +
    apatheme+
    scale_y_continuous(limits = c(0, 0.5), 
                        breaks =seq(0,0.5, by = 0.1)) +
    labs(x="Ordinal Position ",y ="Errors", colour="Session",
         linetype="Session",
         title = "Session 1") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))

(plot_error_repetition_PWA_session2_Naming <- means_final %>%
    filter(session=="2") %>% 
    ggplot(., aes(x=PosOr, y=error_class, group=subject, color = AAT)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=AAT, color=AAT),
                 fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("dashed"))+
    scale_colour_manual(values=c("#feedec", "#fdcac6", "#fca7a0",
                                          "#fb8479", "#fa6153",
                                          "#f93e2d", "#f81b07",
                                          "#d21706", "#ac1305", 
                                          "#860f04", "#5f0b03",
                                          "#390602", "#130201"))+
    geom_errorbar(aes(ymin=error_class-se, ymax=error_class+se, 
                      group = AAT), width =.1) +
    apatheme+
    scale_y_continuous(limits = c(0, 0.5), 
                        breaks =seq(0,0.5, by = 0.1)) +
    labs(x="Ordinal Position ",y ="Errors", 
         colour="Session", linetype="Session",
         title = "Session 2") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))


(plot_error_repetition_PWA_session3_Naming <- means_final %>%
    filter(session=="3") %>% 
    ggplot(., aes(x=PosOr, y=error_class, group=subject, color = AAT)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=AAT, color=AAT),
                 fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("dashed"))+
    scale_colour_manual(values=c("#feedec", "#fdcac6", "#fca7a0",
                                          "#fb8479", "#fa6153",
                                          "#f93e2d", "#f81b07",
                                          "#d21706", "#ac1305", 
                                          "#860f04", "#5f0b03",
                                          "#390602", "#130201"))+
    geom_errorbar(aes(ymin=error_class-se, ymax=error_class+se, 
                      group = AAT), width =.1) +
    apatheme+
    scale_y_continuous(limits = c(0, 0.5), 
                        breaks =seq(0,0.5, by = 0.1)) +
    labs(x="Ordinal Position ",y ="Errors", colour="Naming\npercentile",
        # linetype="Session",
         title = "Session 3") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="right")+
    scale_linetype(guide="none"))


(plot_error_repetition_PWA_session1_Token <- 
    means_final %>% filter(session=="1") %>% 
    ggplot(., aes(x=PosOr, y=error_class, group=subject, color = TokenTest)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=TokenTest, color=TokenTest),
                 fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("dashed"))+
    scale_colour_manual(values=c("#f2ecfd", "#d7c5f9", "#bd9ef5",
                                          "#a378f1", "#8851ee",
                                          "#6e2aea", "#5915d4",
                                          "#4911ae", "#380e87", 
                                          "#280a61", "#18063a",
                                          "#080213"))+
    geom_errorbar(aes(ymin=error_class-se, ymax=error_class+se, group = TokenTest),
                  width =.1) +
    apatheme+
    scale_y_continuous(limits = c(0, 0.5), 
                        breaks =seq(0,0.5, by = 0.1)) +
    labs(x="Ordinal Position ",y ="Errors", colour="Session",
         linetype="Session",
         title = "Session 1") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))

(plot_error_repetition_PWA_session2_Token <- means_final %>%
    filter(session=="2") %>% 
    ggplot(., aes(x=PosOr, y=error_class, group=subject, color = TokenTest)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=TokenTest, color=TokenTest),
                 fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("dashed"))+
    scale_colour_manual(values=c("#f2ecfd", "#d7c5f9", "#bd9ef5",
                                          "#a378f1", "#8851ee",
                                          "#6e2aea", "#5915d4",
                                          "#4911ae", "#380e87", 
                                          "#280a61", "#18063a",
                                          "#080213"))+
    geom_errorbar(aes(ymin=error_class-se, ymax=error_class+se, 
                      group = TokenTest), width =.1) +
    apatheme+
    scale_y_continuous(limits = c(0, 0.5), 
                        breaks =seq(0,0.5, by = 0.1)) +
    labs(x="Ordinal Position ",y ="Errors", 
         colour="Session", linetype="Session",
         title = "Session 2") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))


(plot_error_repetition_PWA_session3_Token <- means_final %>%
    filter(session=="3") %>% 
    ggplot(., aes(x=PosOr, y=error_class, group=subject, color = TokenTest)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=TokenTest, color=TokenTest),
                 fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("dashed"))+
    scale_colour_manual(values=c("#f2ecfd", "#d7c5f9", "#bd9ef5",
                                          "#a378f1", "#8851ee",
                                          "#6e2aea", "#5915d4",
                                          "#4911ae", "#380e87", 
                                          "#280a61", "#18063a",
                                          "#080213"))+
    geom_errorbar(aes(ymin=error_class-se, ymax=error_class+se, 
                      group = TokenTest), width =.1) +
    apatheme+
    scale_y_continuous(limits = c(0, 0.5), 
                        breaks =seq(0,0.5, by = 0.1)) +
    labs(x="Ordinal Position ",y ="Errors", colour="Token test\npercentile",
        # linetype="Session",
         title = "Session 3") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="right")+
    scale_linetype(guide="none"))

(plot_error_repetition_PWA_session1_Speech <- 
    means_final %>% filter(session=="1") %>% 
    ggplot(., aes(x=PosOr, y=error_class, group=subject, 
                  color = AAT_spontansprache)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=AAT_spontansprache,
                     color=AAT_spontansprache),
                 fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("dashed"))+
    scale_colour_manual(values=c("#76ff76", "#008900"))+
    geom_errorbar(aes(ymin=error_class-se, ymax=error_class+se, 
                      group = AAT_spontansprache),
                  width =.1) +
    apatheme+
    scale_y_continuous(limits = c(0, 0.5), 
                        breaks =seq(0,0.5, by = 0.1)) +
    labs(x="Ordinal Position ",y ="Errors", colour="Session",
         linetype="Session",
         title = "Session 1") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))

(plot_error_repetition_PWA_session2_Speech <- means_final %>%
    filter(session=="2") %>% 
    ggplot(., aes(x=PosOr, y=error_class, group=subject, color = AAT_spontansprache)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=AAT_spontansprache, color=AAT_spontansprache),
                 fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("dashed"))+
    scale_colour_manual(values=c("#76ff76", "#008900"))+
    geom_errorbar(aes(ymin=error_class-se, ymax=error_class+se, 
                      group = AAT_spontansprache), width =.1) +
    apatheme+
    scale_y_continuous(limits = c(0, 0.5), 
                        breaks =seq(0,0.5, by = 0.1)) +
    labs(x="Ordinal Position ",y ="Errors", 
         colour="Session", linetype="Session",
         title = "Session 2") +
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))


(plot_error_repetition_PWA_session3_Speech <- means_final %>%
    filter(session=="3") %>% 
    ggplot(., aes(x=PosOr, y=error_class, group=subject, color = AAT_spontansprache)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=AAT_spontansprache, color=AAT_spontansprache),
                 fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("dashed"))+
    scale_colour_manual(values=c("#76ff76", "#008900"))+
    geom_errorbar(aes(ymin=error_class-se, ymax=error_class+se, 
                      group = AAT_spontansprache), width =.1) +
    apatheme+
     scale_y_continuous(limits = c(0, 0.5), 
                        breaks =seq(0,0.5, by = 0.1)) +
    labs(x="Ordinal Position ",y ="Errors", 
         colour="Spontaneous\nspeech\nscore",
        # linetype="Session",
         title = "Session 3") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="right")+
    scale_linetype(guide="none"))


plots <- cowplot::plot_grid(plot_error_repetition_PWA_session1_Naming,
                            plot_error_repetition_PWA_session2_Naming,
                            plot_error_repetition_PWA_session3_Naming,
                            plot_error_repetition_PWA_session1_Token,
                            plot_error_repetition_PWA_session2_Token,
                            plot_error_repetition_PWA_session3_Token,
                            plot_error_repetition_PWA_session1_Speech,
                            plot_error_repetition_PWA_session2_Speech,
                           plot_error_repetition_PWA_session3_Speech,
          nrow = 3, ncol=3,  
          rel_widths = c(0.81,0.81,1,0.81,0.81,1,0.81,0.81,1),
          margin(1,1,1,1),
          labels = c("A", "", "", "B", "", "","C", "", ""),
          label_size = 34,
                    label_fontfamily = "Helvetica", label_y = 1.01,
          label_x=-0.03)
filename <- "CSI_online_aphasia_spoken_plot_PWA_Error_Test_scores.pdf"
ggsave(plots, filename = 
         here::here("results", "figures", filename),
       width = 25, height = 39, units = "cm", 
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))
# 
# # Naming percenile scores: median split of means final 
# median(as.numeric(as.character(means_final$AAT)))
# means_final %>% 
#   mutate(med_split=case_when(as.numeric(as.character(AAT)) > 
#   median(as.numeric(as.character(means_final$AAT))) ~ "high",
#   as.numeric(as.character(AAT)) < 
#     median(as.numeric(as.character(means_final$AAT))) ~ "low",
#   as.numeric(as.character(AAT)) == median(as.numeric(as.character(
#     means_final$AAT))) ~ 
#     "median"),
#   mean_split=case_when(as.numeric(as.character(AAT)) > 
#                          mean(as.numeric(as.character(means_final$AAT))) ~
#                          "high",
#   as.numeric(as.character(AAT)) < mean(as.numeric(as.character(
#     means_final$AAT))) ~ "low",
#   as.numeric(as.character(AAT)) == mean(as.numeric(as.character(
#     means_final$AAT))) ~ "median")) -> means_final
# 
# means_final %>% group_by(session, med_split, PosOr) %>%
#            summarise(mean=mean(error_class), sd = sd(error_class))
# means_final %>% group_by(session, mean_split, PosOr)  %>%
#   summarise(mean=mean(error_class), sd = sd(error_class))
# 
# 
# # Token Test percenile scores: median split of means final 
# median(as.numeric(as.character(means_final$TokenTest)))
# means_final %>% mutate(med_split=case_when(
#   as.numeric(as.character(TokenTest)) > 
#     median(as.numeric(as.character(means_final$TokenTest))) ~ "high",
#   as.numeric(as.character(TokenTest)) < 
#     median(as.numeric(as.character(means_final$TokenTest))) ~ "low",
#   as.numeric(as.character(TokenTest)) == 
#     median(as.numeric(as.character( means_final$TokenTest))) ~ "median"),
#   mean_split=case_when(
#     as.numeric(as.character(TokenTest)) >
#       mean(as.numeric(as.character(means_final$TokenTest))) ~ "high",
#     as.numeric(as.character(TokenTest)) < 
#       mean(as.numeric(as.character( means_final$TokenTest))) ~ "low",
#     as.numeric(as.character(TokenTest)) == 
#       mean(as.numeric(as.character(means_final$TokenTest))) ~ "median")) -> 
#   means_final
# 
# means_final %>% group_by(session, med_split, PosOr) %>%
#            summarise(mean=mean(error_class), sd = sd(error_class))
# means_final %>% group_by(session, mean_split, PosOr)  %>%
#   summarise(mean=mean(error_class),sd = sd(error_class))
# 
# # Spontaneous speech scores: median split of means final 
# median(as.numeric(as.character(means_final$AAT_spontansprache)))
# means_final %>% 
#   mutate(med_split=case_when(
#     as.numeric(as.character(AAT_spontansprache)) > 
#       median(as.numeric(as.character(
#         means_final$AAT_spontansprache))) ~ "high",
#     as.numeric(as.character(AAT_spontansprache)) <
#       median(as.numeric(as.character(
#         means_final$AAT_spontansprache))) ~ "low",
#     as.numeric(as.character(AAT_spontansprache)) == 
#       median(as.numeric(as.character(
#         means_final$AAT_spontansprache))) ~ "median"),
#     mean_split=case_when(
#       as.numeric(as.character(AAT_spontansprache)) > 
#         mean(as.numeric(as.character(
#           means_final$AAT_spontansprache))) ~ "high"
#       as.numeric(as.character(AAT_spontansprache)) <
#         mean(as.numeric(as.character(
#           means_final$AAT_spontansprache))) ~ "low",
#       as.numeric(as.character(AAT_spontansprache)) ==
#         mean(as.numeric(as.character(
#           means_final$AAT_spontansprache))) ~ "median")) -> means_final
# 
# means_final %>% group_by(med_split, PosOr) %>%
#            summarise(mean=mean(error_class), sd = sd(error_class))
# means_final %>% group_by(mean_split, PosOr)  %>%
#   summarise(mean=mean(error_class), sd = sd(error_class))
# 
# #### Nested models 
# # 
# # summary(afex::lmer_alt(error_class ~
# #                           session/(PosOr.cont*(TokenTest_c+AAT_c+
# #                                                 AAT_spontansprache_c+
# #                                                 LHoverall_c)) + 
# #                     (PosOr.cont |subject) +
# #                     (1|category) ,
# #                   data =df_errors_PWA, family = "binomial",
# #                   control=glmerControl(optimizer = "bobyqa",
# #                                  optCtrl = list(maxfun = 2e5))))

```

# --------------------------------------------
## Additional (pre-planned) analyses
### Preregistered analyses with GLMM
We deviated from our preregistered analyses because SEs seemed suspicously small.  

*Check fit of normal vs gamma distribution in histograms, q-q-plots and using objective criteria:*  
1) Fit normal and gamma distributions to the reaction time data

```{r load_fitdistrplus}
library(fitdistrplus)
```

```{r fit.normal}
fit.normal<- fitdist(df_RTs$VOT, distr = "norm", method = "mle")
summary(fit.normal)
#plot(fit.normal)

fit.normal_PWA<- fitdist(df_RTs_PWA$VOT, distr = "norm", method = "mle")
summary(fit.normal_PWA)
#plot(fit.normal_PWA)
```

```{r fit.gamma}
fit.gamma <- fitdist(df_RTs$VOT, distr = "gamma", method = "mle")
summary(fit.gamma)
#plot(fit.gamma)

fit.gamma_PWA <- fitdist(df_RTs_PWA$VOT, distr = "gamma", method = "mle")
summary(fit.gamma_PWA)
#plot(fit.gamma_PWA)
```

```{r fit.invgamma}
# library(actuar)
# fit.invgamma <- fitdist(df_RTs$VOT, distr = "invgamma",  method = "mle")
# summary(fit.invgauss)
# #plot(fit.invgauss)
# 
# fit.invgamma_PWA <- fitdist(df_RTs_PWA$VOT, distr = "invgamma", method = "mle")
# summary(fit.invgamma_PWA)
# #plot(fit.invgauss_PWA)
```


```{r fit.invgauss}
library(actuar)
fit.invgauss <- fitdist(
  df_RTs$VOT, distr = "invgauss", start = list(mean = 5, shape = 1),
  method = "mle")
summary(fit.invgauss)
#plot(fit.invgauss)

fit.invgauss_PWA <- fitdist(df_RTs_PWA$VOT, distr = "invgauss", 
                            start = list(mean = 5, shape = 1), 
                            method = "mle")
summary(fit.invgauss_PWA)
#plot(fit.invgauss_PWA)

MASS::boxcox(df_RTs_PWA$VOT~df_RTs_PWA$PosOr_cont*df_RTs_PWA$session)
MASS::boxcox(df_RTs$VOT~df_RTs$PosOr_cont*df_RTs$session*df_RTs$group)
fit.transf <- fitdist(log(df_RTs$VOT), distr = "norm",method = "mle")
fit.transf_PWA <- fitdist(log(df_RTs_PWA$VOT), 
                          distr = "norm",method = "mle")
```


2) Compare the fit of the two distributions  
Visually compare fit of both distributions in histogram

```{r density-comparison}
denscomp(list(fit.gamma, fit.invgauss))
denscomp(list(fit.transf))

denscomp(list(fit.gamma_PWA, fit.invgauss_PWA))
   denscomp(list(fit.transf_PWA))
```

Visually compare fit of both distributions in Q-Q-plots

```{r q-q-comparison}
qqcomp(list(fit.gamma, fit.invgauss))
qqcomp(list(fit.transf))
qqcomp(list(fit.gamma_PWA))#, fit.invgauss_PWA))
qqcomp(list(fit.transf_PWA))
```

Compare information criteria

```{r fit_criteria-comparison}
gofstat(list(fit.gamma, fit.invgauss, fit.normal),
        fitnames = c("Gamma", "Inverse Gaussian", "Normal"))

gofstat(list(fit.gamma_PWA, fit.invgauss_PWA, fit.normal_PWA),
        fitnames = c("Gamma", "Inverse Gaussian", "Normal" ))
```

**Conclusion:** .
Overall, (inverse) gamma fits the data better than a normal model with uncontrolled data and an inverse Gaussian distribution for both the entire data set and the PWA group only. The inverse Gamma is not yet implemented in glmer. Therefore we will use the Gamma distribution.

##### PWA only - Ordinal position x session 

```{r GLMM_cont}
# m1 <- glmer(VOT ~ PosOr.cont*session +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session|category),
#              data = df_RTs_PWA,
#             family =Gamma(link ="identity"),
#             control=glmerControl(optimizer = "bobyqa"))
```

Model fails to converge --> reduce

```{r}
# 1) Increase optimizer iterations
# m1 <- glmer(VOT ~ PosOr.cont*session +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session|category),
#              data = df_RTs_PWA,
#             family =Gamma(link ="identity"),
#             control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# 2) Set correlation parameters to zero
m1 <- afex::lmer_alt(VOT ~ PosOr.cont*session + 
               (PosOr.cont*session||subject) +
              (PosOr.cont*session||category),
             data = df_RTs_PWA, 
            family =Gamma(link ="identity"), 
            control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m1)
## The warnings can be safely ignored

# inspect model
summary(m1)
anova(m1)

# save model output
saveRDS(m1, file = here::here("results", "tables",
                          "CSI_online_aphasia_PWA_glmm_cont.RDS"))
tab_model(m1,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Gamma distribution) of VOTs Predicted by Ordinal Position and Session, PWA only",
          dv.labels = "Vocal Onset Time",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here(
            "results", "tables", "CSI_online_aphasia_PWA_glmm_cont.html"))
```

##### Analyses with Ordinal position x Session x Group

Make sure contrasts are correctly defined

```{r}
contrasts(df_RTs$session)
levels(df_RTs$session)

## Define contrast of group
contrasts(df_RTs$group)
levels(df_RTs$group)
```

Compute model

```{r}
# m2 <- glmer(VOT ~ PosOr.cont*session*group +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session*group|category),
#              data = df_RTs,
#             family =Gamma(link ="identity"),
#             control=glmerControl(optimizer = "bobyqa"))
```

Model fails to converge --> reduce

```{r}
# 1) Increase optimizer iterations
# m2 <- glmer(VOT ~ PosOr.cont*session*group +
#                (PosOr.cont*session|subject) +
#               (PosOr.cont*session*group|category),
#              data = df_RTs,
#             family =Gamma(link ="identity"),
#             control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# 2) Set correlation parameters to zero
m2 <- afex::lmer_alt(VOT ~ PosOr.cont*session*group + 
               (PosOr.cont*session||subject) +
              (PosOr.cont*session*group||category),
             data = df_RTs, 
            family =Gamma(link ="identity"), 
            control=glmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
didLmerConverge(m2)
## The warnings can be safely ignored

# inspect model
summary(m2)
anova(m2)

# save model output
saveRDS(m2, file = here::here("results", "tables",
                          "CSI_online_aphasia_SessionxGroup_glmm_cont.RDS"))
tab_model(m2,transform = NULL,
          show.re.var = F, show.stat = T,show.r2 = F,show.icc = F,
          title = "GLMM (Gamma distribution) of VOTs Predicted by Ordinal Position, Session and Group",
          dv.labels = "Vocal Onset Time",
          #string.pred = "",
          string.stat = "t-Value",
          file = here::here(
            "results", "tables",
            "CSI_online_aphasia_SessionxGroup_glmm_cont.html"))
```

#### Control analyses without PWA 1 and 17
The procedure deviated slightly in two participants.PWA1 had the same array in sessions 1 and 2 and was tested a day too late in session 2, PWA17 was tested a day too late in session 3. Here, we conduct control analyses without these two participants to test whether the data are affected. 

###### RTs
Plotting 

```{r}
(means_final<- df_RTs %>% 
   filter(category != "Filler") %>% 
   filter(subject != 101 & subject != 117) %>% 
   Rmisc::summarySEwithin(.,"VOT",idvar = "subject",
                          withinvars = c("session", "PosOr"), 
                          betweenvars = "group", na.rm = T))
override.linetype<-c("solid", "dashed", "dotted")
(plot_rt_repetition_PWA <- means_final %>% filter(group=="PWA") %>% 
    ggplot(., aes(x=PosOr, y=VOT, group=session, color = session)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=session),
                 fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("solid", "dashed", "dotted"))+
    scale_color_manual(values=c("#0072B2", "#E69F00", "#000000"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, group = session), 
                  width =.1) +
    apatheme+
    scale_y_continuous(limits = c(1120, 1450), 
                       breaks =seq(1150,1450, by = 50)) +
    labs(x="Ordinal Position ",y ="RT (ms)", colour="Session",
         linetype="Session",
         title = "Patients with Aphasia") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))

(plot_rt_repetition_control <- means_final %>% 
    filter(group=="control") %>% 
    ggplot(., aes(x=PosOr, y=VOT, group=session, color = session)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=session),fun=mean,  geom="line", size = 0.5) +
    scale_linetype_manual(values=c("solid", "dashed", "dotted"))+
    scale_color_manual(values=c("#0072B2", "#E69F00", "#000000"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, group = session), 
                  width =.1) +
    apatheme+
    scale_y_continuous(limits = c(1120, 1450), 
                       breaks =seq(1150,1450, by = 50)) +
    labs(x="Ordinal Position ",y ="RT (ms)", colour="Session",
         linetype="Session",
         title = "Control Group") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"))+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))

plots <- cowplot::plot_grid(plot_rt_repetition_PWA,
                            plot_rt_repetition_control,
          nrow = 1, ncol=2,  rel_widths = c(0.81,1), 
          margin(1,1,1,1),
          labels = c("A", "B"),label_size = 34,
          label_y = 1.01,
          label_x=-0.03)
filename <- 
  "CSI_online_aphasia_spoken_plot_rt_by_repetition_without_101-117.pdf"
ggsave(plots, filename =
         here::here("results", "figures", filename),
       width = 25, height = 13, units = "cm",
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))
```

Statistical analyses


```{r}
df_RTs_red <- df_RTs %>% filter(subject != "101" & subject != "117") %>%
  droplevels()
df_RTs_red$PosOr.cont <- scale(as.numeric(as.character(df_RTs_red$PosOr)),
                                        center = T, scale = F)
# m2_f <- afex::lmer_alt(lVOT ~ PosOr.cont*session*group + 
#                (PosOr.cont*session||subject) +
#               (PosOr.cont*session*group||category),
#              data = df_RTs_red, 
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# m2_f <- afex::lmer_alt(lVOT ~ PosOr.cont*session*group +
#                (PosOr.cont*session||subject) +
#               (PosOr.cont+session*group-session||category),
#              data = df_RTs_red,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
m2_f <- afex::lmer_alt(lVOT ~ PosOr.cont*session*group +
               (PosOr.cont+session||subject) +
              (PosOr.cont+group||category),
             data = df_RTs_red,
            control=lmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
# m2_f <- lmer(lVOT ~ PosOr.cont*session*group +
#                (PosOr.cont+session|subject) +
#               (PosOr.cont+group|category),
#              data = df_RTs_red,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
summary(m2_f)
didLmerConverge(m2_f)
```


###### Error rates

```{r}
df_errors_red <- df_errors %>% 
  filter(subject != "101" & subject != "117") %>%
  filter(group=="PWA") %>% 
  droplevels()
df_errors_red$PosOr.cont <-
  scale(as.numeric(as.character(df_errors_red$PosOr)),
        center = T, scale = F)
# m2_f <- afex::lmer_alt(error_class ~ PosOr.cont*session +
#                (PosOr.cont*session||subject) +
#               (PosOr.cont*session||category),
#              data = df_errors_red,
#              family="binomial",
#             control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# m2_f <- afex::lmer_alt(error_class ~ PosOr.cont*session*group +
#                (PosOr.cont||subject) +
#               (PosOr.cont+group||category),
#              data = df_errors_red,
#              family="binomial",
#             control=glmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# m2_f <- afex::lmer_alt(lVOT ~ PosOr.cont*session*group +
#                (PosOr.cont*session||subject) +
#               (PosOr.cont+session*group-session||category),
#              data = df_RTs_red,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
m2_f <- afex::lmer_alt(lVOT ~ PosOr.cont*session*group +
               (PosOr.cont+session||subject) +
              (PosOr.cont+group||category),
             data = df_RTs_red,
            control=lmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
# m2_f <- lmer(lVOT ~ PosOr.cont*session*group +
#                (PosOr.cont+session|subject) +
#               (PosOr.cont+group|category),
#              data = df_RTs_red,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
summary(m2_f)
didLmerConverge(m2_f)
```

#### Comparison to verbal CSI with young participants

######  Load data
Load data from both the verbal online CSI experiment (Stark et al., 2022)

```{r load_verbal_data}
load(here::here("data", "verbal_CSI_young_starketal2022",
                "CSI_online_verbal_df_full.RData"))
df_young <- df_full
```

######  Combine both data frames into one
1) Subset relevant columns and give identical names

```{r subset_and_rename_columns}
df_young <- df_young %>% 
  dplyr::select(VP, Item, subcat, VOT, correct, Pos) %>%
  dplyr::rename(subject = VP, item = Item, 
                category = subcat, PosOr=Pos) %>%
  mutate(group="young") %>% 
  mutate(session="young group")

x <- df_RTs %>% 
  dplyr::select(subject, group, session, item, category, VOT, PosOr)
```

2) Give subjects from both experiments different names

```{r adapt_subject_names}
df_young <- df_young %>% mutate(subject = subject + 300)
```

3) Put columns into correct format 

```{r factorize}
df_young <- df_young %>% 
  mutate(subject = as.factor(subject)) %>%
  mutate(item = as.character(item)) %>%
  mutate(category = as.factor(category)) %>% 
  mutate(VOT = as.numeric(VOT)) %>%
  mutate(PosOr = as.factor(PosOr)) %>%
  filter(!is.na(correct) & correct != 0) %>% 
  dplyr::select(-correct) %>%
  droplevels()
```

4) Bind both data frames into one

```{r combine_df}
df_combi <- bind_rows(x, df_young)
```

5) Give identical category names in both experiments

```{r category_names}
df_combi <- df_combi %>% dplyr::mutate(category = case_when(
  category == "Buero" ~ "Büro",
  category == "Gebaeude" ~ "Gebäude",
  category == "Gemuese" ~ "Gemüse",
  category ==  "Koerperteile" ~ "Körperteile",
  category == "Kueche" ~ "Küche",
  category == "Suessigkeiten" ~ "Süssigkeiten",
  category == "Trinkgefaesse" ~ "Trinkgefässe",
  category == "Voegel" ~ "Vögel",
  TRUE ~ as.character(category))) %>%
  mutate(category == as.factor(category)) %>% droplevels()
table(df_combi$category)
```

5) Drop filler trials

```{r drop_filler}
 df_combi <- df_combi %>% filter(category != "Filler" & 
                      category != "Filler1" & category != "Filler2") %>%
  droplevels()
```

6) Export combined data frame for post-hoc power plot

```{r export_df}
write.csv(df_combi, here::here("data", "CSI_online_young_PWA_old_combined.csv"))
```

###### Descriptives

```{r}
(descriptives <- df_combi %>% 
   Rmisc::summarySEwithin(.,"VOT",idvar = "subject",
                          withinvars = c("PosOr", "session"),
                          betweenvars = "group",
                          na.rm = T))
```

###### Plotting

Plot RTs by Session and ordinal position for both experiments

````{r}
override.linetype<-c("solid", "dashed", "dotted", "longdash")
(plot_rt_repetition_PWA <- descriptives %>% 
    filter(group=="PWA" | group=="young") %>% 
    ggplot(., aes(x=PosOr, y=VOT, group=session, color = session)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=session),fun=mean,  
                 geom="line", size = 0.5) +
    scale_linetype_manual(values=c("solid", "dashed", 
                                   "dotted", "longdash"))+
    scale_color_manual(values=c("#0072B2", "#E69F00", "#000000", "gray"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, group = session), 
                  width =.1) +
    apatheme  +
    scale_y_continuous(limits = c(1040, 1450), 
                       breaks =seq(1050,1450, by = 50)) + 
    labs(x="Ordinal Position ",y ="RT (ms)", colour="Session",
         linetype="Session",
         title = "PWA vs Young Group") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"),
    legend.position="none")+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))

(plot_rt_repetition_control <- descriptives %>% 
    filter(group=="control" | group=="young") %>% 
    ggplot(., aes(x=PosOr, y=VOT, group=session, color = session)) +
    geom_point(size = 2)+
    stat_summary(aes(linetype=session),fun=mean,  
                 geom="line", size = 0.5) +
    scale_linetype_manual(values=c("solid", "dashed", "dotted", "longdash"))+
    scale_color_manual(values=c("#0072B2", "#E69F00", "#000000", "gray"))+
    geom_errorbar(aes(ymin=VOT-se, ymax=VOT+se, group = session), 
                  width =.1) +
    apatheme+
    scale_y_continuous(limits = c(1040, 1450), 
                       breaks =seq(1050,1450, by = 50)) +
    labs(x="Ordinal Position ",y ="RT (ms)", colour="Session",
         linetype="Session",
         title = "Control vs Young Group") + 
    theme(
    axis.title.y = element_text(margin = margin(0,10,0,0)),
    axis.title.x = element_text(margin = margin(10,0,0,0)),
    legend.key.width = unit(1, "cm"))+
   guides(color=guide_legend(
     override.aes=list(linetype=override.linetype)))+
    scale_linetype(guide="none"))

plots <- cowplot::plot_grid(
  plot_rt_repetition_PWA,plot_rt_repetition_control,
          nrow = 1, ncol=2,  rel_widths = c(0.7,1), #rel_height = c(1,1),
          margin(1,1,1,1),
          labels = c("A", "B"),label_size = 34,
                    label_fontfamily = "Helvetica", label_y = 1.01,
  label_x=-0.03)
filename <- "CSI_online_aphasia_spoken_comparison-to-young.pdf"
ggsave(plots, filename = 
         here::here("results", "figures", filename),
       width = 25, height = 13, units = "cm", 
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))

````

# ---------------------------------------------
## Appendix

### List of stimuli

```{r}
df %>% arrange(category) %>% 
  group_by(category, item, correct, AR) %>% count()

```

### Response times and error rates by participant and category
#### RTs by subject
Line graph for each participant: 

```{r, warning=FALSE}
modeloutput <- coef(m2)$subject
means_final_subject <- df_RTs %>%
   summarySEwithin(.,"VOT",withinvars = c("subject","PosOr", "session"),
                   betweenvars="group")
means_final<- df_RTs %>%
   Rmisc::summarySEwithin(.,"VOT",idvar = "subject",
                          withinvars = c("PosOr"),
                          na.rm = T)

for(i in 1:nrow(means_final_subject)) {
  means_final_subject$grandmean[i] <- 
    means_final$VOT[means_final$PosOr == means_final_subject$PosOr[i]] -
    means_final$VOT[means_final$PosOr== 1]
  means_final_subject$normalizedRT[i] <- 
    means_final_subject$VOT[i] -
    means_final_subject$VOT[means_final_subject$subject ==
                              means_final_subject$subject[i] &
                              means_final_subject$PosOr == 1 & 
                                    means_final_subject$session == 1]
  # prepare for ordering
  means_final_subject$effect[i] <- 
    round(modeloutput$PosOr.cont[means_final_subject$subject[i]] + 
    modeloutput$re1.PosOr.cont[means_final_subject$subject[i]] +
    modeloutput$re2.PosOr.cont[means_final_subject$subject[i]],2)
}

means_final_subject <- means_final_subject[
  order(desc(means_final_subject$group),
        desc(means_final_subject$effect)),] 
means_final_subject$effect <- 
  as.factor(round(means_final_subject$effect, 2))
means_final_subject$effect <- 
  factor(means_final_subject$effect,
         levels=rev(levels(means_final_subject$effect )))


# add participant number
means_final_subject <- means_final_subject %>% 
  mutate(subject_en = case_when(
    group == "PWA" ~ paste0("PWA ",
                            substr(as.character(
                              means_final_subject$subject), 2,3),
                            "\n(",effect,")",sep=''),
    group == "control" ~ paste0("Control ",
                            substr(as.character(means_final_subject$subject), 2,3),
                            "\n(",effect,")",sep='')))  %>%
  mutate(subject_en = case_when(subject_en=="PWA 04\n(29.1)" ~
                                    "PWA 04\n(29.10)",
                                  subject_en=="PWA 16\n(24.3)" ~
                                    "PWA 16\n(24.30)",
                                  subject_en=="Participant 12\n(38.3)" ~
                                    "Participant 12\n(38.30)",
                                    subject_en=="Control 12\n(17.5)" ~
                                      "Control 12\n(17.50)",
                                  TRUE~subject_en)) %>%
  mutate(subject_en=factor(subject_en,levels=c(
     "PWA 03\n(42.36)","PWA 05\n(37.11)","PWA 20\n(33.71)",
     "PWA 13\n(32.42)","PWA 07\n(29.28)","PWA 08\n(29.13)",
     "PWA 04\n(29.10)","PWA 12\n(27.84)","PWA 16\n(24.30)",
     "PWA 18\n(23.59)","PWA 06\n(23.31)", "PWA 09\n(19.86)",
     "PWA 14\n(18.04)","PWA 11\n(16.91)","PWA 17\n(16.18)",
     "PWA 10\n(12.79)","PWA 19\n(10.94)","PWA 02\n(4.11)",
     "PWA 01\n(0.72)","PWA 15\n(0.02)","Control 09\n(44.58)",
     "Control 17\n(41.22)","Control 10\n(34.06)","Control 20\n(29.22)",
     "Control 02\n(26.54)","Control 07\n(26.11)","Control 01\n(23.97)",
     "Control 05\n(22.77)","Control 03\n(22.53)","Control 15\n(21.83)",
     "Control 19\n(21.75)", "Control 13\n(21.66)","Control 14\n(20.13)",
     "Control 04\n(19.86)","Control 08\n(17.97)","Control 12\n(17.50)",
     "Control 11\n(13.73)","Control 06\n(12.86)","Control 16\n(12.39)",
     "Control 18\n(9.51)" )))

# Plotting
(plot_rt_subject <- means_final_subject %>%
    ggplot(., aes(x=PosOr,y=normalizedRT, 
                  color=session, group=session, na.rm=T)) +
    geom_point(size =1, color = 'black') +
    geom_line(aes(x=PosOr,y=normalizedRT, color=session, linetype="c"),
              size = 0.5) +
    geom_line(aes(x=PosOr,y=grandmean, color="b", linetype="d"),
              group = 1,size = 0.8)+
    geom_errorbar(aes(ymin=normalizedRT-se, ymax=normalizedRT+se), 
                  width =.1) +
    scale_color_manual(name="Session",
                       values=c(
                         "#0072B2", "#E69F00", "#000000", "dark gray"),
                       labels=c(
                         "1", "2", "3", 
                      "Grand Mean (across subjects, sessions, groups)")) +
    scale_linetype_manual(name="",values=c("c"="solid","d"="dashed"),
                          labels=c("Participant mean",
                                   "Grand Mean"))+
    apatheme+
    labs(x="Ordinal Position",y ="Normalized RTs (ms)") +
    facet_wrap(means_final_subject$subject_en, scales='free', ncol=8)+
    scale_y_continuous(limits = c(-800, 800),
                       breaks = c(-600,-400,-200,0,200,400,600)) +
    scale_x_discrete(breaks=c(1,2,3,4,5))+
    theme(legend.position = "bottom"))

filename <- "CSI_online_aphasia_effect_by_participant.pdf"
ggsave(plot_rt_subject, filename =
         here::here("results", "figures", filename),
       width = 34, height = 26, units = "cm",
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))
```

#### RTs by category
Line graph for each category: 

```{r, warning=FALSE}
modeloutput <- coef(m2)$category
means_final_category <- df_RTs %>%
   summarySEwithin(.,"VOT",withinvars = 
                     c("category","PosOr", "session"))
means_final<- df_RTs %>%
   Rmisc::summarySEwithin(.,"VOT",idvar = "category",
                          withinvars = c("PosOr"),
                          na.rm = T)

for(i in 1:nrow(means_final_category)) {
  means_final_category$grandmean[i] <- 
    means_final$VOT[means_final$PosOr == means_final_category$PosOr[i]] -
    means_final$VOT[means_final$PosOr== 1]
  means_final_category$normalizedRT[i] <- 
    means_final_category$VOT[i] -
    means_final_category$VOT[means_final_category$category == means_final_category$category[i] & means_final_category$PosOr == 1 & 
                                    means_final_category$session == 1]
  # prepare for ordering
  means_final_category$effect[i] <- 
    modeloutput$PosOr.cont[means_final_category$category[i]] + 
    modeloutput$re2.PosOr.cont[means_final_category$category[i]]
}

means_final_category <- means_final_category[
  order(desc(means_final_category$effect)),] 
means_final_category$effect <-
  as.factor(round(means_final_category$effect, 2))
means_final_category$effect <- 
  factor(means_final_category$effect,
         levels=rev(levels(means_final_category$effect )))
means_final_category$category <- factor(
  means_final_category$category, levels=c(
       "Insekten",     "Sitzen",       "Kochen",       "Jacken",
       "Obst",         "Trinkgefässe", "Wasser",       "Heimwerker",   
       "Küche",        "Fische",       "Aufbewahrung",
       "Büro", "Bauernhof", "Raubtiere", "Huftiere", "Gemüse",
       "Körperteile", "Vögel", "Instrumente", "Blumen",
       "Gebäude", "Schmuck", "Strasse", "Süssigkeiten"))

# order category levels by effect size
means_final_category$category <- factor(
  means_final_category$category, levels=c(
    "Gebäude","Schmuck","Raubtiere","Sitzen","Jacken",
    "Blumen","Huftiere","Wasser","Trinkgefässe","Küche",
    "Insekten","Büro","Bauernhof","Strasse","Kochen",
    "Gemüse","Körperteile","Fische","Heimwerker","Aufbewahrung",
    "Obst","Vögel","Instrumente","Süssigkeiten"))
# give categories English names and combine with effect size
means_final_category <- means_final_category %>% 
  mutate(category_en = case_when(
    category == "Aufbewahrung" ~ paste0(
      "Storage\n\n(", effect, ")", sep=''), 
    category == "Bauernhof" ~ paste0(
      "Farming\ntools\n(", effect, ")", sep=''), 
    category == "Blumen" ~ paste0(
      "Flowers\n\n(", effect, ")", sep=''),
    category == "Büro" ~ paste0(
      "Office\ntools\n(", effect, ")", sep=''),
    category == "Fische" ~ paste0(
      "Fish\n\n(", effect, ")", sep=''),
    category == "Gebäude" ~ paste0(
      "Buildings\n\n(", effect, ")", sep=''),
    category == "Gemüse" ~ paste0(
      "Vegetables\n\n(", effect, ")", sep=''),
    category == "Heimwerker" ~ paste0(
      "Carpenter.s\ntools\n(", effect, ")", sep=''),
    category == "Huftiere" ~ paste0(
      "Hoofed\nanimals\n(", effect, ")", sep=''),
    category == "Insekten" ~ paste0(
      "Insects\n\n(", effect, ")", sep=''),
    category == "Instrumente" ~ paste0(
      "Instruments\n\n(", effect, ")", sep=''),
    category == "Jacken" ~ paste0(
      "Jackets\n\n(", effect, ")", sep=''),
    category == "Kochen" ~ paste0(
      "Cooking\nequipment\n(", effect, ")", sep=''),
    category == "Körperteile" ~ paste0(
      "Body parts\n\n(", effect, ")", sep=''),
    category == "Küche" ~ paste0(
      "Kitchen\nfurniture\n(", effect, ")", sep=''),
    category == "Obst" ~ paste0(
      "Fruits\n\n(", effect, ")", sep=''),
    category == "Raubtiere" ~ paste0(
      "Predators\n\n(", effect, ")", sep=''),
    category == "Schmuck" ~ paste0(
      "Jewelry\n\n(", effect, ")", sep=''),
    category == "Sitzen" ~ paste0(
      "Seating\nfurniture\n(", effect, ")", sep=''),
    category == "Strasse" ~ paste0(
      "Street\nvehicles\n(", effect, ")", sep=''),
    category == "Süssigkeiten" ~ paste0(
      "Sweets\n\n(", effect, ")", sep=''),
    category == "Trinkgefässe" ~ paste0(
      "Drinking\nvessels\n(", effect, ")", sep=''),
    category == "Vögel" ~ paste0(
      "Birds\n\n(", effect, ")", sep=''),
    category == "Wasser" ~ paste0(
      "Water\nvehicles\n(", effect, ")", sep='')))  %>%
  mutate(category_en = case_when(category_en=="Insects\n\n(35.4)" ~
                                    "Insects\n\n(35.40)",
                                  category_en=="Jackets\n\n(27.9)"  ~
                                    "Jackets\n\n(27.90)" ,
                                  TRUE~category_en)) %>%
  mutate(category_en=factor(category_en,levels=c(
     "Insects\n\n(35.40)", "Seating\nfurniture\n(33.45)", 
     "Cooking\nequipment\n(28.45)", "Jackets\n\n(27.90)",
     "Fruits\n\n(27.77)", "Drinking\nvessels\n(26.47)",  
     "Water\nvehicles\n(26.44)","Carpenter.s\ntools\n(26.18)",
     "Kitchen\nfurniture\n(25.76)", "Fish\n\n(23.97)",
     "Storage\n\n(23.56)","Office\ntools\n(23.13)",
     "Farming\ntools\n(22.55)","Predators\n\n(21.51)",
     "Hoofed\nanimals\n(21.18)","Vegetables\n\n(20.74)" ,
     "Body parts\n\n(19.93)","Birds\n\n(19.33)",
     "Instruments\n\n(18.27)","Flowers\n\n(15.53)",
     "Buildings\n\n(13.56)","Jewelry\n\n(12.87)",
     "Street\nvehicles\n(12.76)","Sweets\n\n(11.11)")))

# Plotting
(plot_rt_category <- means_final_category %>%
    ggplot(., aes(x=PosOr,y=normalizedRT, color=session, 
                  group=session, na.rm=T)) +
    geom_point(size =1) +
    geom_line(aes(x=PosOr,y=normalizedRT, color=session, linetype="c"),
              size = 0.5) +
    geom_line(aes(x=PosOr,y=grandmean, color="b", linetype="d"),
              group = 1,size = 0.8)+
    geom_errorbar(aes(ymin=normalizedRT-se, ymax=normalizedRT+se), 
                  width =.1) +
    scale_color_manual(name="Session",
                       values=c("#0072B2", "#E69F00", "#000000", 
                                         "dark gray"),
                       labels=c("1", "2", "3", "Grand Mean")) +
    scale_linetype_manual(name="",values=c("c"="solid","d"="dashed"),
                          labels=c("Category mean (across groups)",
                                   "Grand Mean"))+
    apatheme+
    labs(x="Ordinal Position",y ="Normalized RTs (ms)") +
    facet_wrap(means_final_category$category_en, scales='free', ncol=8)+
    scale_y_continuous(limits = c(-800, 800),
                       breaks = c(-600,-400,-200,0,200,400,600)) +
    scale_x_discrete(breaks=c(1,2,3,4,5))+
    theme(legend.position = "bottom"))

filename <- "CSI_online_aphasia_effect_by_category.pdf"
ggsave(plot_rt_category, filename =
         here::here("results", "figures", filename),
       width = 26, height = 20,units = "cm",
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))
```

Combine both

```{r}
plots <- cowplot::plot_grid(plot_rt_subject,plot_rt_category,
          nrow = 2, ncol=1,  #rel_widths = c(1,1), 
          rel_heights = c(1,0.6),
          margin(1,1,1,1),
          labels = c("A", "B"),label_size = 34,
                    label_fontfamily = "Helvetica", label_y = 1.01,
          label_x=0)
filename <- "CSI_online_aphasia_spoken_RTs-by-category-and-subject.pdf"
ggsave(plots, filename = 
         here::here("results", "figures", filename),
       width = 30, height = 50, units = "cm", 
       dpi = 300, device = cairo_pdf)
```


#### Errors by subject
Line graph for each participant: 

```{r, warning=FALSE}
m2_error <- readRDS(here::here(
  "results", "tables",
  "CSI_online_aphasia_SessionxGroup_glmm_errors.RDS"))
modeloutput <- coef(m2_error)$subject
means_final_subject <- df_errors %>%
   summarySEwithin(
     .,"error_class",withinvars = c("subject","PosOr", "session"),
                   betweenvars="group")
means_final<- df_errors %>%
   Rmisc::summarySEwithin(.,"error_class",idvar = "subject",
                          withinvars = c("PosOr"),
                          na.rm = T)

for(i in 1:nrow(means_final_subject)) {
  means_final_subject$grandmean[i] <-
    means_final$error_class[means_final$PosOr ==
                              means_final_subject$PosOr[i]] -
    means_final$error_class[means_final$PosOr== 1]
  means_final_subject$normalizedRT[i] <-
    means_final_subject$error_class[i] -
    means_final_subject$error_class[means_final_subject$subject ==
                                      means_final_subject$subject[i] &
                                      means_final_subject$PosOr == 1 & 
                                    means_final_subject$session == 1]
  # prepare for ordering
  means_final_subject$effect[i] <- 
    modeloutput$PosOr.cont[means_final_subject$subject[i]] + 
    modeloutput$re1.PosOr.cont[means_final_subject$subject[i]]
}

means_final_subject <- means_final_subject[order(desc(means_final_subject$group), desc(means_final_subject$effect)),] 
means_final_subject$effect <- 
  as.factor(round(means_final_subject$effect, 2))
means_final_subject$effect <- 
  factor(means_final_subject$effect,
         levels=rev(levels(means_final_subject$effect )))


# add participant number
means_final_subject <- means_final_subject %>% 
  mutate(effect=round(as.numeric(as.character(effect)),2)) %>%
  mutate(subject_en = case_when(
    group == "PWA" & as.numeric(as.character(effect)) == 0.10~ 
      paste0("PWA ",
                            substr(as.character(means_final_subject$subject), 2,3),
                            "\n(",effect,"0)",sep=''),
    group == "control" & as.numeric(as.character(effect)) == 0.10~
      paste0("Control ",
             substr(as.character(means_final_subject$subject), 2,3),
                            "\n(",effect,"0)",sep=''),
     group == "PWA" & as.numeric(as.character(effect)) >= 0.01~
      paste0("PWA ",
             substr(as.character(means_final_subject$subject), 2,3),
                            "\n(",effect,")",sep=''),
    group == "control"& as.numeric(as.character(effect)) >= 0.01 ~
      paste0("Control ",
                            substr(as.character(means_final_subject$subject), 2,3),
                            "\n(",effect,")",sep=''),
    group == "PWA" & as.numeric(as.character(effect)) < 0.01~ 
      paste0("PWA ",
             substr(as.character(means_final_subject$subject), 2,3),
                            "\n(< .01)",sep=''),
    group == "control"& as.numeric(as.character(effect)) < 0.01 ~
      paste0("Control ",
             substr(as.character(means_final_subject$subject), 2,3),
                            "\n(<.01)",sep='')))  %>%
  mutate(subject_en=factor(subject_en))
  # mutate(subject_en=factor(subject_en,levels=c(
  #     "PWA 12\n(0.24)","PWA 07\n(0.16)","PWA 05\n(0.16)","PWA 08\n(0.16)",  
  #     "PWA 10\n(0.13)","PWA 18\n(0.12)","PWA 04\n(0.12)","PWA 19\n(0.12)",
  #     "PWA 03\n(0.10)","PWA 06\n(0.07)","PWA 15\n(0.06)","PWA 20\n(0.05)",
  #     "PWA 16\n(0.05)","PWA 14\n(0.03)","PWA 13\n(0.03)","PWA 02\n(< .01)",
  #     "PWA 17\n(< .01)","PWA 09\n(< .01)","PWA 01\n(< .01)","PWA 11\n(< .01)",
  #     "Control 02\n(0.13)","Control 05\n(0.13)","Control 07\n(0.11)",
  #     "Control 15\n(0.10)","Control 10\n(0.10)","Control 16\n(0.09)",
  #     "Control 01\n(0.09)","Control 04\n(0.08)","Control 20\n(0.08)",
  #     "Control 09\n(0.07)","Control 19\n(0.07)","Control 12\n(0.07)",
  #     "Control 06\n(0.07)","Control 14\n(0.06)","Control 08\n(0.05)",
  #     "Control 13\n(0.04)","Control 11\n(0.03)","Control 17\n(0.03)",
  #     "Control 03\n(0.02)","Control 18\n(0.01)")))

# Plotting
(plot_error_subject <- means_final_subject %>%
    ggplot(., aes(x=PosOr,y=normalizedRT, color=session, 
                  group=session, na.rm=T)) +
    geom_point(size =1, color = 'black') +
    geom_line(aes(x=PosOr,y=normalizedRT, color=session, linetype="c"),
              size = 0.5) +
    geom_line(aes(x=PosOr,y=grandmean, color="b", linetype="d"),
              group = 1,size = 0.8)+
    geom_errorbar(aes(ymin=normalizedRT-se, ymax=normalizedRT+se), width =.1) +
    scale_color_manual(name="Session",
                       values=c("#0072B2", "#E69F00", "#000000", 
                                         "dark gray"),
                       labels=c("1", "2", "3", 
                      "Grand Mean (across subjects, sessions, groups)")) +
    scale_linetype_manual(name="",values=c("c"="solid","d"="dashed"),
                          labels=c("Participant mean",
                                   "Grand Mean"))+
    apatheme+
    labs(x="Ordinal Position",y ="Error Rate") +
    facet_wrap(means_final_subject$subject_en, scales='free', ncol=8)+
    scale_y_continuous(limits = c(-0.5, 0.5),
                       breaks = c(-0.4,-0.2,0,0.2,0.4)) +
    scale_x_discrete(breaks=c(1,2,3,4,5))+
    theme(legend.position = "bottom"))

filename <- "CSI_online_aphasia_errors_by_participant.pdf"
ggsave(plot_error_subject, filename =
         here::here("results", "figures", filename),
       width = 34, height = 26, units = "cm",
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))
```


#### Errors by categry
Line graph for each participant: 

```{r, warning=FALSE}
m2_error <- readRDS(here::here(
  "results", "tables",
  "CSI_online_aphasia_SessionxGroup_glmm_errors.RDS"))
modeloutput <- coef(m2_error)$category
means_final_category <- df_errors %>%
   summarySEwithin(.,"error_class",
                   withinvars = c("category","PosOr", "session"))
means_final<- df_errors %>%
   Rmisc::summarySEwithin(.,"error_class",idvar = "category",
                          withinvars = c("PosOr"),#, "session"),
                          #betweenvars="group",
                          na.rm = T)

for(i in 1:nrow(means_final_category)) {
  means_final_category$grandmean[i] <-
    means_final$error_class[means_final$PosOr ==
                              means_final_category$PosOr[i]] -
    means_final$error_class[means_final$PosOr== 1]
  means_final_category$normalized_error[i] <-
    means_final_category$error_class[i] -
    means_final_category$error_class[
      means_final_category$category == means_final_category$category[i] &
                                       means_final_category$PosOr == 1 & 
                                    means_final_category$session == 1]
  # prepare for ordering
  means_final_category$effect[i] <- 
    modeloutput$PosOr.cont[means_final_category$category[i]] + 
    modeloutput$re1.PosOr.cont+
    modeloutput$re2.group2.1[means_final_category$category[i]]
}

means_final_category <-
  means_final_category[order(desc(means_final_category$effect)),] 
means_final_category$effect <-
  as.factor(round(means_final_category$effect, 2))
means_final_category$effect <- 
  factor(means_final_category$effect,
         levels=rev(levels(means_final_category$effect )))

means_final_category$category <- factor(
  means_final_category$category, levels=c(
       "Insekten",     "Sitzen",       "Kochen",       "Jacken",
       "Obst",         "Trinkgefässe", "Wasser",       "Heimwerker",   
       "Küche",        "Fische",       "Aufbewahrung",
       "Büro", "Bauernhof", "Raubtiere", "Huftiere", "Gemüse",
       "Körperteile", "Vögel", "Instrumente", "Blumen",
       "Gebäude", "Schmuck", "Strasse", "Süssigkeiten"))

# give categories English names and combine with effect size
means_final_category <- means_final_category %>% 
  mutate(category_en =
         case_when(
  category == "Aufbewahrung" ~ "Storage",
  category == "Bauernhof" ~"Farming\ntools",
  category == "Blumen" ~ "Flowers",
  category == "Büro" ~"Office\ntools",
  category == "Fische" ~ "Fish",
  category == "Gebäude" ~ "Buildings",
  category == "Gemüse" ~"Vegetables",
  category == "Heimwerker" ~ "Carpenter.s\ntools",
  category == "Huftiere" ~ "Hoofed\nanimals",
  category == "Insekten" ~ "Insects",
  category == "Instrumente" ~  "Instruments",
  category == "Jacken" ~ "Jackets",
  category == "Kochen" ~ "Cooking\nequipment",
  category == "Körperteile" ~ "Body part",
  category == "Küche" ~ "Kitchen\nfurniture",
  category == "Obst" ~ "Fruits",
  category == "Raubtiere" ~"Predators",
  category == "Schmuck" ~ "Jewelry",
  category == "Sitzen" ~"Seating\nfurniture",
  category == "Strasse" ~"Street\nvehicles",
  category == "Süssigkeiten" ~ "Sweets",
  category == "Trinkgefässe" ~  "Drinking\nvessels",
  category == "Vögel" ~  "Birds",
  category == "Wasser" ~ "Water\nvehicles")) %>% 
  # mutate(category_en = case_when(
  #   as.numeric(as.character(effect)) == 0.10~ paste0(category_en, " ",
  #                           "\n(",effect,"0)",sep=''),
  #    as.numeric(as.character(effect)) >= 0.01~ paste0(category_en, " ",
  #                           "\n(",effect,")",sep=''),
  #   as.numeric(as.character(effect)) < 0.01~ paste0(category_en, " ",
  #                           "\n(< .01)",sep=''),
  #   TRUE ~ paste0(category_en, " ",
  #                           "\n(",effect,")",sep='')))  %>%
  mutate(category_en=factor(category_en))

# Plotting
(plot_error_category <- means_final_category %>%
    ggplot(., aes(x=PosOr,y=normalized_error, color=session, group=session, na.rm=T)) +
    geom_point(size =1, color = 'black') +
    geom_line(aes(x=PosOr,y=normalized_error, color=session,
                  linetype="c"),
              size = 0.5) +
    geom_line(aes(x=PosOr,y=grandmean, color="b", linetype="d"),
              group = 1,size = 0.8)+
    geom_errorbar(aes(ymin=normalized_error-se, ymax=normalized_error+se),
                  width =.1) +
    scale_color_manual(name="Session",
                       values=c("#0072B2", "#E69F00", "#000000",
                                         "dark gray"),
                       labels=c("1", "2", "3", 
                    "Grand Mean (across categories, sessions, groups)")) +
    scale_linetype_manual(name="",values=c("c"="solid","d"="dashed"),
                          labels=c("Participant mean",
                                   "Grand Mean"))+
    apatheme+
    labs(x="Ordinal Position",y ="Error Rate") +
     facet_wrap(means_final_category$category_en, scales='free', ncol=8)+
    scale_y_continuous(limits = c(-0.5, 0.5),
                       breaks = c(-0.4,-0.2,0,0.2,0.4)) +
    scale_x_discrete(breaks=c(1,2,3,4,5))+
    theme(legend.position = "bottom"))


filename <- "CSI_online_aphasia_errors_by_category.pdf"
ggsave(plot_error_category, filename =
         here::here("results", "figures", filename),
       width = 26, height = 20, units = "cm",
       dpi = 300, device = cairo_pdf)
#embedFonts(file = here::here("results", "figures", filename))
```


Combine both

```{r}
plots <- cowplot::plot_grid(plot_error_subject,plot_error_category,
          nrow = 2, ncol=1, 
          rel_heights = c(1,0.6),
          margin(1,1,1,1),
          labels = c("A", "B"),label_size = 34,
                    label_fontfamily = "Helvetica", label_y = 1.01,
          label_x=0)
filename <- "CSI_online_aphasia_spoken_errors-by-category-and-subject.pdf"
ggsave(plots, filename = 
         here::here("results", "figures", filename),
       width = 30, height = 50, units = "cm", 
       dpi = 300, device = cairo_pdf)
```


### Exploratory nested model with group and ordinal position nested into session
Take the same random structure as in the main model

```{r}
# m2_lmm_n <- lmer(lVOT ~ group/session/PosOr.cont +
#                (PosOr.cont+session|subject) +
#               (PosOr.cont+group|category),
#              data = df_RTs,
#             control=lmerControl(optimizer = "bobyqa",
#                                  optCtrl = list(maxfun = 2e5)))
# summary(m2_lmm_n)

m2_lmm_n <- lmer(lVOT ~ session/(group*PosOr.cont) +
               (PosOr.cont+session|subject) +
              (PosOr.cont+group|category),
             data = df_RTs,
            control=lmerControl(optimizer = "bobyqa",
                                 optCtrl = list(maxfun = 2e5)))
summary(m2_lmm_n)
```

# -------------------------
# Session info

```{r}
sessionInfo()
```

# -------------------------
# Exploratory analyses
We conducted several exploratory analyses to assess the stability of our effects, especially because we deviated from the pre-planned GLMMs for RT analyses

<!-- ### Intercept-only models -->
<!-- #### RTs -->
<!-- *Center predictor variable and contrast coding*  -->

<!-- ```{r} -->
<!-- # PWA + control -->
<!-- df_RTs$PosOr.cont <- scale(as.numeric(as.character(df_RTs$PosOr)), -->
<!--                                         center = T, scale = F) -->
<!-- # PWA -->
<!-- df_RTs_PWA <- df_RTs %>% filter(group=="PWA") %>% droplevels() -->
<!-- df_RTs_PWA$PosOr.cont <- scale(as.numeric(as.character(df_RTs_PWA$PosOr)), -->
<!--                                         center = T, scale = F) -->

<!-- # define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE) -->
<!-- c<-contr.treatment(3) -->
<!-- my.coding<-matrix(rep(1/3, 6), ncol=2) -->
<!-- my.simple<-c-my.coding -->
<!-- my.simple -->
<!-- contrasts(df_RTs$session)<-my.simple -->
<!-- levels(df_RTs$session) -->
<!-- contrasts(df_RTs_PWA$session)<-my.simple -->
<!-- levels(df_RTs_PWA$session) -->

<!-- ## Define contrast of group -->
<!-- contrasts(df_RTs$group) <- MASS::contr.sdif(2) -->
<!-- levels(df_RTs$group) -->
<!-- levels(df_RTs_PWA$group) -->
<!-- ``` -->


<!-- *Exclude unrealistically short reaction times < 200 ms* -->

<!-- ```{r} -->
<!-- sum(df_RTs$VOT < 200) -->
<!-- df_RTs <- df_RTs %>% filter(VOT >=200) -->

<!-- sum(df_RTs_PWA$VOT < 200) -->
<!-- df_RTs_PWA <- df_RTs_PWA %>% filter(VOT >=200) -->
<!-- ``` -->


<!-- ##### Main 1: PWA only - Ordinal position x session  -->

<!-- ```{r} -->
<!-- m1_intercept <- glmer(VOT ~ PosOr.cont*session + -->
<!--                (1|subject) + -->
<!--               (1|category), -->
<!--              data = df_RTs_PWA, -->
<!--             family =Gamma(link ="identity"), -->
<!--             control=glmerControl(optimizer = "bobyqa")) -->
<!-- didLmerConverge(m1_intercept) -->
<!-- ## The warnings can be safely ignored -->

<!-- # inspect model -->
<!-- summary(m1_intercept) -->
<!-- anova(m1_intercept) -->

<!-- # save model output -->
<!-- saveRDS(m1_intercept, file = here::here("results", "tables", -->
<!--                           "CSI_online_aphasia_PWA_glmm_intercept_only.RDS")) -->
<!-- tab_model(m1_intercept,transform = NULL, -->
<!--           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F, -->
<!--           title = "GLMM (Gamma distribution) of VOTs Predicted by Ordinal Position and Session, PWA only\nIntercept-Only-Modell", -->
<!--           pred.labels = c("(Intercept)", "Ordinal Position",  -->
<!--                           "Session 2 vs 1", -->
<!--                           "Session 3 vs 1", "Ord.Pos. x Session2-1", -->
<!--                           "Ord.Pos. x Session3-1"), -->
<!--           dv.labels = "Vocal Onset Time", -->
<!--           #string.pred = "", -->
<!--           string.stat = "t-Value", -->
<!--           file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_intercept_only.html")) -->
<!-- ``` -->


<!-- ##### Main 2: Ordinal position x session x group -->

<!-- ```{r} -->
<!-- m2_intercept <- glmer(VOT ~  PosOr.cont *group * session  + -->
<!--                (1|subject) + -->
<!--               (1|category), -->
<!--              data = df_RTs, -->
<!--             family =Gamma(link ="identity"), -->
<!--             control=glmerControl(optimizer = "bobyqa")) -->
<!-- didLmerConverge(m2_intercept) -->
<!-- ## The warnings can be safely ignored -->

<!-- # inspect model -->
<!-- summary(m2_intercept) -->
<!-- anova(m2_intercept) -->

<!-- # save model output -->
<!-- saveRDS(m2_intercept, file = here::here("results", "tables", -->
<!--                           "CSI_online_aphasia_glmm_intercept_only.RDS")) -->
<!-- tab_model(m2_intercept,transform = NULL, -->
<!--           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F, -->
<!--           title = "GLMM (Gamma distribution) of VOTs Predicted by Ordinal Position, Group, and Session\nIntercept-Only-Modell", -->
<!--           dv.labels = "Vocal Onset Time", -->
<!--           #string.pred = "", -->
<!--           string.stat = "t-Value", -->
<!--           file = here::here( -->
<!--             "results", "tables", -->
<!--             "CSI_online_aphasia_glmm_intercept_only.html")) -->
<!-- ``` -->


<!-- ### Errors -->
<!-- *Center predictor variable* -->

<!-- ```{r} -->
<!-- df_errors_PWA <- df_errors %>% filter(group=="PWA") %>% droplevels() -->
<!-- df_errors_PWA$PosOr.cont <- -->
<!--   c(scale(as.numeric(as.character(df_errors_PWA$PosOr)), -->
<!--         center = T, scale = F)) -->

<!-- df_errors$PosOr.cont <- -->
<!--   c(scale(as.numeric(as.character(df_errors$PosOr)), -->
<!--         center = T, scale = F)) -->
<!-- ``` -->

<!-- *Contrast coding* -->

<!-- ```{r} -->
<!-- # define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE) -->
<!-- c<-contr.treatment(3) -->
<!-- my.coding<-matrix(rep(1/3, 6), ncol=2) -->
<!-- my.simple<-c-my.coding -->
<!-- my.simple -->
<!-- contrasts(df_errors$session)<-my.simple -->
<!-- levels(df_errors$session) -->
<!-- contrasts(df_errors_PWA$session)<-my.simple -->
<!-- levels(df_RTs_PWA$session) -->

<!-- ## Define contrast of group -->
<!-- contrasts(df_errors$group) <- MASS::contr.sdif(2) -->
<!-- levels(df_errors$group) -->
<!-- levels(df_errors_PWA$group) -->
<!-- ``` -->

<!-- #### Main 1: PWA only -->

<!-- ```{r } -->
<!-- m1_error_intercept <- glmer(error_class ~ PosOr.cont*session + -->
<!--                     (1|subject) + -->
<!--                     (1|category) , -->
<!--                   data =df_errors_PWA, family = "binomial", -->
<!--                   control=glmerControl(optimizer = "bobyqa")) -->
<!-- didLmerConverge(m1_error_intercept) -->
<!-- summary(m1_error_intercept) -->

<!-- # save model output -->
<!-- saveRDS(m1_error_intercept, file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_errors_intercept_only.RDS")) -->
<!-- tab_model(m1_error_intercept,transform = NULL, -->
<!--           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F, -->
<!--           title = "GLMM (Binomial distribution) of Errors Predicted by Ordinal Position and Session,  -->
<!--           PWA only\n Intercept-Only-Modell", -->
<!--           dv.labels = "Error Rate", -->
<!--           #string.pred = "", -->
<!--           string.stat = "z-Value", -->
<!--           file = here::here( -->
<!--             "results", "tables", -->
<!--             "CSI_online_aphasia_PWA_glmm_errors_intercept_only.html")) -->
<!-- ``` -->

<!-- ### Polynomial contrasts in VOT of people with aphasia (Session 1) -->
<!-- #### RTs, PWA; session 1 -->
<!-- Ordinal position effect is only a trend in session 1. Does another than a linear trend describe the data better?  -->

<!-- ```{r} -->
<!-- x <- df_RTs_PWA %>% filter(session == "1") -->
<!-- x$PosOr <- as.factor(x$PosOr) -->
<!-- levels(x$PosOr) -->
<!-- contrasts(x$PosOr) <- contr.poly(5) -->
<!-- contrasts(x$PosOr) -->

<!-- # m1_poly <- glmer(VOT ~ PosOr +  -->
<!-- #                (PosOr|subject) + -->
<!-- #               (PosOr|category), -->
<!-- #              data = x,  -->
<!-- #             family =Gamma(link ="identity"),  -->
<!-- #             control=glmerControl(optimizer = "bobyqa", -->
<!-- #                                  optCtrl = list(maxfun = 2e5))) -->
<!-- # m1_poly <- afex::lmer_alt(VOT ~ PosOr +  -->
<!-- #                (PosOr||subject) + -->
<!-- #               (PosOr||category), -->
<!-- #              data = x,  -->
<!-- #             family =Gamma(link ="identity"),  -->
<!-- #             control=glmerControl(optimizer = "bobyqa", -->
<!-- #                                  optCtrl = list(maxfun = 2e5))) -->
<!-- # didLmerConverge(m1_poly) -->
<!-- # rePCA(m1_poly) -->
<!-- # summary(m1_poly) -->
<!-- # m1_poly <- afex::lmer_alt(VOT ~ PosOr +  -->
<!-- #                (1|subject) + -->
<!-- #               (PosOr||category), -->
<!-- #              data = x,  -->
<!-- #             family =Gamma(link ="identity"),  -->
<!-- #             control=glmerControl(optimizer = "bobyqa", -->
<!-- #                                  optCtrl = list(maxfun = 2e5))) -->
<!-- m1_poly <- glmer(VOT ~ PosOr +  -->
<!--                (1|subject) + -->
<!--               (1|category), -->
<!--              data = x,  -->
<!--             family =Gamma(link ="identity"),  -->
<!--             control=glmerControl(optimizer = "bobyqa", -->
<!--                                  optCtrl = list(maxfun = 2e5))) -->
<!-- summary(m1_poly) -->

<!-- saveRDS(m1_poly, file = here::here("results", "tables", -->
<!--                           "CSI_online_aphasia_PWA_session1_glmm_poly_contrast.RDS")) -->
<!-- tab_model(m1_poly,transform = NULL, -->
<!--           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F, -->
<!--           title =  -->
<!--             "GLMM (Gamma distribution) of VOTs Predicted by Ordinal Position (polynomial contrasts)in Session 1, PWA only", -->
<!--           dv.labels = "Vocal Onset Time", -->
<!--           #string.pred = "", -->
<!--           string.stat = "t-Value", -->
<!--           file = here::here( -->
<!--             "results", "tables", -->
<!--             "CSI_online_aphasia_PWA_session1_glmm_poly_contrast.html")) -->
<!-- ``` -->

<!-- ### Sliding-difference contrasts -->
<!-- #### RTs -->
<!-- *Center predictor variable and contrast coding*  -->

<!-- ```{r} -->
<!-- # PWA + control -->
<!-- df_RTs$PosOr.cont <- scale(as.numeric(as.character(df_RTs$PosOr)), -->
<!--                                         center = T, scale = F) -->
<!-- # PWA -->
<!-- df_RTs_PWA <- df_RTs %>% filter(group=="PWA") %>% droplevels() -->
<!-- df_RTs_PWA$PosOr.cont <- scale(as.numeric(as.character(df_RTs_PWA$PosOr)), -->
<!--                                         center = T, scale = F) -->

<!-- # define contrasts of session: sliding difference contrasts -->
<!-- contrasts(df_RTs$session) <- MASS::contr.sdif(3) -->
<!-- levels(df_RTs$session) -->
<!-- contrasts(df_RTs_PWA$session) <- MASS::contr.sdif(3) -->
<!-- levels(df_RTs_PWA$session) -->

<!-- ## Define contrast of group -->
<!-- contrasts(df_RTs$group) <- MASS::contr.sdif(2) -->
<!-- levels(df_RTs$group) -->
<!-- levels(df_RTs_PWA$group) -->
<!-- ``` -->


<!-- *Exclude unrealistically short reaction times < 200 ms* -->

<!-- ```{r} -->
<!-- sum(df_RTs$VOT < 200) -->
<!-- df_RTs <- df_RTs %>% filter(VOT >=200) -->

<!-- sum(df_RTs_PWA$VOT < 200) -->
<!-- df_RTs_PWA <- df_RTs_PWA %>% filter(VOT >=200) -->
<!-- ``` -->


<!-- ##### Main 1: PWA only - Ordinal position x session  -->

<!-- ```{r} -->
<!-- # m1_sdif <- glmer(VOT ~ PosOr.cont*session + -->
<!-- #                (PosOr.cont*session|subject) + -->
<!-- #               (PosOr.cont*session|category), -->
<!-- #              data = df_RTs_PWA, -->
<!-- #             family =Gamma(link ="identity"), -->
<!-- #             control=glmerControl(optimizer = "bobyqa")) -->
<!-- m1_sdif <- afex::lmer_alt(VOT ~ PosOr.cont*session + -->
<!--                (PosOr.cont*session||subject) + -->
<!--               (PosOr.cont*session||category), -->
<!--              data = df_RTs_PWA, -->
<!--             family =Gamma(link ="identity"), -->
<!--             control=glmerControl(optimizer = "bobyqa")) -->
<!-- didLmerConverge(m1_sdif) -->
<!-- ## The warnings can be safely ignored -->

<!-- # inspect model -->
<!-- summary(m1_sdif) -->

<!-- # save model output -->
<!-- saveRDS(m1_sdif, file = here::here("results", "tables", -->
<!--                           "CSI_online_aphasia_PWA_glmm_sliding_difference_contrast.RDS")) -->
<!-- tab_model(m1_sdif,transform = NULL, -->
<!--           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F, -->
<!--           title = "GLMM (Gamma distribution) of VOTs Predicted by Ordinal Position and Session, PWA only (Sliding-difference_contrast)", -->
<!--           dv.labels = "Vocal Onset Time", -->
<!--           #string.pred = "", -->
<!--           string.stat = "t-Value", -->
<!--           file = here::here( -->
<!--             "results", "tables", -->
<!--             "CSI_online_aphasia_PWA_glmm_sliding_difference_contrast.html")) -->
<!-- ``` -->


<!-- ##### Main 2: Ordinal position x session x group -->

<!-- ```{r} -->
<!-- # m2_sdif <- afex::lmer_alt(VOT ~ PosOr.cont*session*group + -->
<!-- #                (PosOr.cont*session||subject) + -->
<!-- #               (PosOr.cont*session*group||category), -->
<!-- #              data = df_RTs, -->
<!-- #             family =Gamma(link ="identity"), -->
<!-- #             control=glmerControl(optimizer = "bobyqa")) -->
<!-- m2_sdif <- afex::lmer_alt(VOT ~ PosOr.cont*session*group + -->
<!--                (PosOr.cont*session||subject) + -->
<!--               (PosOr.cont*session*group||category), -->
<!--              data = df_RTs, -->
<!--             family =Gamma(link ="identity"), -->
<!--             control=glmerControl(optimizer = "bobyqa")) -->

<!-- didLmerConverge(m2_sdif) -->
<!-- didLmerConverge(m2_sdif) -->
<!-- ## The warnings can be safely ignored -->

<!-- # inspect model -->
<!-- summary(m2_sdif) -->
<!-- anova(m2_sdif) -->

<!-- # save model output -->
<!-- saveRDS(m2_sdif, file = here::here("results", "tables", -->
<!--                           "CSI_online_aphasia_glmm_sliding_difference_contrast.RDS")) -->
<!-- tab_model(m2_sdif,transform = NULL, -->
<!--           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F, -->
<!--           title = "GLMM (Gamma distribution) of VOTs Predicted by Ordinal Position, Group, and Session (Sliding difference contrasts)", -->
<!--           dv.labels = "Vocal Onset Time", -->
<!--           #string.pred = "", -->
<!--           string.stat = "t-Value", -->
<!--           file = here::here( -->
<!--             "results", "tables", -->
<!--             "CSI_online_aphasia_glmm_sliding_difference_contrast.html")) -->
<!-- ``` -->

<!-- ### Errors: RTs as covariate (PWA only) -->
<!-- Exclude null responses -->

<!-- ```{r} -->
<!-- table(df_errors_PWA$error) -->
<!-- df_errors_PWA_control <- df_errors_PWA %>%  -->
<!--   filter((error != 4 & error != 99) | is.na(error)) %>%  -->
<!--   filter(VOT > 200) %>% droplevels() -->
<!-- ``` -->

<!-- *Center predictor variable* -->

<!-- ```{r} -->
<!-- df_errors_PWA_control$PosOr.cont <- -->
<!--   c(scale(as.numeric(as.character(df_errors_PWA_control$PosOr)), -->
<!--         center = T, scale = F)) -->

<!-- df_errors_PWA_control$PosOr.cont <- -->
<!--   c(scale(as.numeric(as.character(df_errors_PWA_control$PosOr)), -->
<!--         center = T, scale = F)) -->

<!-- range(df_errors_PWA_control$VOT)/1000 -->
<!-- df_errors_PWA_control$VOT_c <- -->
<!--   c(scale(as.numeric(as.character(df_errors_PWA_control$VOT))/1000, -->
<!--         center = T, scale = F)) -->
<!-- ``` -->

<!-- *Contrast coding* -->

<!-- ```{r} -->
<!-- # define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE) -->
<!-- c<-contr.treatment(3) -->
<!-- my.coding<-matrix(rep(1/3, 6), ncol=2) -->
<!-- my.simple<-c-my.coding -->
<!-- my.simple -->
<!-- contrasts(df_errors_PWA_control$session)<-my.simple -->
<!-- ``` -->

<!-- *GLMM* -->

<!-- ```{r } -->
<!-- # m1_error_VOT <- glmer(error_class ~ PosOr.cont*session*VOT_c + -->
<!-- #                     (PosOr.cont*session|subject) + -->
<!-- #                     (PosOr.cont*session|category) , -->
<!-- #                   data =df_errors_PWA_control, family = "binomial", -->
<!-- # #                   control=glmerControl(optimizer = "bobyqa")) -->
<!-- # m1_error_VOT <- afex::lmer_alt(error_class ~ PosOr.cont*session*VOT_c + -->
<!-- #                     (PosOr.cont*session||subject) + -->
<!-- #                     (PosOr.cont*session||category) , -->
<!-- #                   data =df_errors_PWA_control, family = "binomial", -->
<!-- #                   control=glmerControl(optimizer = "bobyqa")) -->
<!-- # m1_error_VOT <- afex::lmer_alt(error_class ~ PosOr.cont*session*VOT_c + -->
<!-- #                     (PosOr.cont+session||subject) + -->
<!-- #                     (PosOr.cont+session||category) , -->
<!-- #                   data =df_errors_PWA_control, family = "binomial", -->
<!-- #                   control=glmerControl(optimizer = "bobyqa")) -->
<!-- m1_error_VOT <- afex::lmer_alt(error_class ~ PosOr.cont*session*VOT_c + -->
<!--                     (PosOr.cont+session||subject) + -->
<!--                     (PosOr.cont||category) , -->
<!--                   data =df_errors_PWA_control, family = "binomial", -->
<!--                   control=glmerControl(optimizer = "bobyqa")) -->
<!-- #rePCA(m1_error_VOT) -->
<!-- didLmerConverge(m1_error_VOT) -->
<!-- summary(m1_error_VOT) -->

<!-- # save model output -->
<!-- saveRDS(m1_error_VOT, file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_errors_VOT_covariate.RDS")) -->
<!-- tab_model(m1_error_VOT,transform = NULL, -->
<!--           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F, -->
<!--           title = "GLMM (Binomial distribution) of Errors Predicted by Ordinal Position and Session and VOT,  -->
<!--           PWA only", -->
<!--           dv.labels = "Error Rate", -->
<!--           #string.pred = "", -->
<!--           string.stat = "z-Value", -->
<!--           file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_errors_VOT_covariate.html")) -->
<!-- ``` -->

<!-- #### Word errors only -->
<!-- Exclude null responses, other, and phonematic errors -->

<!-- ```{r} -->
<!-- table(df_errors_PWA$error) -->
<!-- df_errors_PWA_control <- df_errors_PWA %>%  -->
<!--   filter((error != 4 & error != 1 & error != 9 & error != 99) | is.na(error)) %>%  -->
<!--   filter(VOT > 200) %>% droplevels() -->
<!-- table(df_errors_PWA_control$error) -->
<!-- ``` -->

<!-- *Center predictor variable* -->

<!-- ```{r} -->
<!-- df_errors_PWA_control$PosOr.cont <- -->
<!--   c(scale(as.numeric(as.character(df_errors_PWA_control$PosOr)), -->
<!--         center = T, scale = F)) -->

<!-- df_errors_PWA_control$PosOr.cont <- -->
<!--   c(scale(as.numeric(as.character(df_errors_PWA_control$PosOr)), -->
<!--         center = T, scale = F)) -->

<!-- range(df_errors_PWA_control$VOT)/1000 -->
<!-- df_errors_PWA_control$VOT_c <- -->
<!--   c(scale(as.numeric(as.character(df_errors_PWA_control$VOT))/1000, -->
<!--         center = T, scale = F)) -->
<!-- ``` -->

<!-- *Contrast coding* -->

<!-- ```{r} -->
<!-- # define contrasts of session: compare 1 to 2 and 1 to 3, intercept is the grand mean => simple coding (https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE) -->
<!-- c<-contr.treatment(3) -->
<!-- my.coding<-matrix(rep(1/3, 6), ncol=2) -->
<!-- my.simple<-c-my.coding -->
<!-- my.simple -->
<!-- contrasts(df_errors_PWA_control$session)<-my.simple -->
<!-- ``` -->

<!-- *GLMM* -->


<!-- ```{r } -->
<!-- # m1_worderror <- glmer(error_class ~ PosOr.cont*session + -->
<!-- #                     (PosOr.cont*session|subject) + -->
<!-- #                     (PosOr.cont*session|category) , -->
<!-- #                   data =df_errors_PWA_control, family = "binomial", -->
<!-- #                    control=glmerControl(optimizer = "bobyqa")) -->
<!-- # m1_worderror <- afex::lmer_alt(error_class ~ PosOr.cont*session + -->
<!-- #                     (PosOr.cont*session||subject) + -->
<!-- #                     (PosOr.cont*session||category) , -->
<!-- #                   data =df_errors_PWA_control, family = "binomial", -->
<!-- #                   control=glmerControl(optimizer = "bobyqa")) -->
<!-- # m1_worderror <- afex::lmer_alt(error_class ~ PosOr.cont*session + -->
<!-- #                     (PosOr.cont+session||subject) + -->
<!-- #                     (PosOr.cont+session||category) , -->
<!-- #                   data =df_errors_PWA_control, family = "binomial", -->
<!-- #                   control=glmerControl(optimizer = "bobyqa")) -->
<!-- m1_worderror <- afex::lmer_alt(error_class ~ PosOr.cont*session + -->
<!--                     (PosOr.cont+session||subject) + -->
<!--                     (PosOr.cont||category) , -->
<!--                   data =df_errors_PWA_control, family = "binomial", -->
<!--                   control=glmerControl(optimizer = "bobyqa")) -->
<!-- #rePCA(m1_worderror) -->
<!-- didLmerConverge(m1_worderror) -->
<!-- summary(m1_worderror) -->

<!-- # save model output -->
<!-- saveRDS(m1_worderror,  -->
<!--         file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_worderrors.RDS")) -->
<!-- tab_model(m1_worderror,transform = NULL, -->
<!--           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F, -->
<!--           title = "GLMM (Binomial distribution) of WORD Errors Predicted by Ordinal Position and Session,  -->
<!--           PWA only", -->
<!--           # pred.labels = c("(Intercept)", "Ordinal Position", "Session 2 vs 1",  -->
<!--           #                 "Session 3 vs 1", "Ord.Pos. x Session2-1", -->
<!--           #                 "Ord.Pos. x Session3-1"), -->
<!--           dv.labels = "Error Rate", -->
<!--           #string.pred = "", -->
<!--           string.stat = "z-Value", -->
<!--           file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_worderrors.html")) -->
<!-- ``` -->





<!-- ```{r } -->
<!-- # m1_worderror_VOT <- glmer(error_class ~ PosOr.cont*session*VOT_c + -->
<!-- #                     (PosOr.cont*session|subject) + -->
<!-- #                     (PosOr.cont*session|category) , -->
<!-- #                   data =df_errors_PWA_control, family = "binomial", -->
<!-- # #                   control=glmerControl(optimizer = "bobyqa")) -->
<!-- # m1_worderror_VOT <- afex::lmer_alt(error_class ~ PosOr.cont*session*VOT_c + -->
<!-- #                     (PosOr.cont*session||subject) + -->
<!-- #                     (PosOr.cont*session||category) , -->
<!-- #                   data =df_errors_PWA_control, family = "binomial", -->
<!-- #                   control=glmerControl(optimizer = "bobyqa")) -->
<!-- # m1_worderror_VOT <- afex::lmer_alt(error_class ~ PosOr.cont*session*VOT_c + -->
<!-- #                     (PosOr.cont+session||subject) + -->
<!-- #                     (PosOr.cont+session||category) , -->
<!-- #                   data =df_errors_PWA_control, family = "binomial", -->
<!-- #                   control=glmerControl(optimizer = "bobyqa")) -->
<!-- m1_worderror_VOT <- afex::lmer_alt(error_class ~ PosOr.cont*session*VOT_c + -->
<!--                     (PosOr.cont+session||subject) + -->
<!--                     (1|category) , -->
<!--                   data =df_errors_PWA_control, family = "binomial", -->
<!--                   control=glmerControl(optimizer = "bobyqa")) -->

<!-- #rePCA(m1_worderror_VOT) -->
<!-- didLmerConverge(m1_worderror_VOT) -->
<!-- summary(m1_worderror_VOT) -->

<!-- # save model output -->
<!-- saveRDS(m1_worderror_VOT, file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_worderrors_VOT_covariate.RDS")) -->
<!-- tab_model(m1_worderror_VOT,transform = NULL, -->
<!--           show.re.var = F, show.stat = T,show.r2 = F,show.icc = F, -->
<!--           title = "GLMM (Binomial distribution) of WORD Errors Predicted by Ordinal Position, Session and VOT,  -->
<!--           PWA only", -->
<!--           # pred.labels = c("(Intercept)", "Ordinal Position", "Session 2 vs 1",  -->
<!--           #                 "Session 3 vs 1", "Ord.Pos. x Session2-1", -->
<!--           #                 "Ord.Pos. x Session3-1"), -->
<!--           dv.labels = "Error Rate", -->
<!--           #string.pred = "", -->
<!--           string.stat = "z-Value", -->
<!--           file = here::here("results", "tables", "CSI_online_aphasia_PWA_glmm_worderrors_VOT_covariate.html")) -->
<!-- ``` -->


<!-- ### RTs: Add Array to model -->
<!-- Center array  -->

<!-- ```{r} -->
<!-- df_RTs$array <- as.factor(df_RTs$array) -->
<!-- contrasts(df_RTs$array) <- contr.sdif(30) -->
<!-- ``` -->

<!-- Add array to fixed structure of intercept only model  -->
<!-- (otherwise it takes veeery long to converge) -->

<!-- ```{r} -->
<!-- # m2_array <- afex::lmer_alt(VOT ~ PosOr.cont*session*group*array +  -->
<!-- #                (1|subject) + -->
<!-- #               (1|category), -->
<!-- #              data = df_RTs,  -->
<!-- #             family =Gamma(link ="identity"),  -->
<!-- #             control=glmerControl(optimizer = "bobyqa", -->
<!-- #                                  optCtrl = list(maxfun = 2e5))) -->
<!-- # didLmerConverge(m2_array) -->
<!-- # ## The warnings can be safely ignored -->
<!-- #  -->
<!-- # # inspect model -->
<!-- # summary(m2_array) -->
<!-- # anova(m2_array) -->
<!-- #  -->
<!-- # # save model output -->
<!-- # saveRDS(m2_array, file = here::here("results", "tables", -->
<!-- #                           "CSI_online_aphasia_SessionxGroupxArray.RDS")) -->
<!-- ``` -->

<!-- Model still fails to converge, but there seems to be some influence of array.    -->
<!-- What if we add array to the random structure only?  -->

<!-- ```{r} -->
<!-- # m2_array_rand <- afex::lmer_alt(VOT ~ PosOr.cont*session*group +  -->
<!-- #                (PosOr.cont*session*array||subject) + -->
<!-- #               (PosOr.cont*session*group*array||category), -->
<!-- #              data = df_RTs,  -->
<!-- #             family =Gamma(link ="identity"),  -->
<!-- #             control=glmerControl(optimizer = "bobyqa", -->
<!-- #                                  optCtrl = list(maxfun = 2e5))) -->
<!-- # summary(m2_array_rand) -->
<!-- # # save model output -->
<!-- # saveRDS(m2_array_rand, file = here::here("results", "tables", -->
<!-- #                           "CSI_online_aphasia_SessionxGroupxArray_random_structure.RDS")) -->
<!-- ``` -->


<!-- ### Do Bayesian estimation using brms to get an idea if the strength and reliability of the effects -->
<!-- Compare GLMM, inverse Gaussian, and LMM model with transformed and untransformed RTs.  -->


<!-- ```{r} -->
<!-- m2 <- readRDS(m2, file = here::here("results", "tables", -->
<!--                           "CSI_online_aphasia_SessionxGroup_glmm_cont.RDS")) -->
<!-- # m2 <- afex::lmer_alt(VOT ~ PosOr.cont*session*group +  -->
<!-- #                (PosOr.cont*session||subject) + -->
<!-- #               (PosOr.cont*session*group||category), -->
<!-- #              data = df_RTs,  -->
<!-- #             family =Gamma(link ="identity"),  -->
<!-- #             control=glmerControl(optimizer = "bobyqa", -->
<!-- #                                  optCtrl = list(maxfun = 2e5))) -->
<!-- # didLmerConverge(m2) -->


<!-- m2_lmm <- readRDS(m2_lmm,  file = here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_control_lmm_VOT.RDS")) -->
<!-- # m2_lmm <- lmer(lVOT ~ PosOr.cont*session*group + -->
<!-- #                (PosOr.cont+session|subject) + -->
<!-- #               (PosOr.cont+group|category), -->
<!-- #              data = df_RTs, -->
<!-- #             control=lmerControl(optimizer = "bobyqa", -->
<!-- #                                  optCtrl = list(maxfun = 2e5))) -->


<!-- # m2_lmm_raw <- lmer(VOT ~ PosOr.cont*session*group + -->
<!-- #                (PosOr.cont+session|subject) + -->
<!-- #               (PosOr.cont+group|category), -->
<!-- #              data = df_RTs, -->
<!-- #             control=lmerControl(optimizer = "bobyqa", -->
<!-- #                                  optCtrl = list(maxfun = 2e5))) -->
<!-- # saveRDS(m2_lmm_raw,  file = here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_control_lmm_VOT_raw.RDS")) -->
<!-- m2_lmm_raw <- readRDS(file = here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_control_lmm_VOT_raw.RDS")) -->


<!-- # m2_gamma_inverse <- afex::lmer_alt(VOT ~ PosOr.cont*session*group + -->
<!-- #                (PosOr.cont*session||subject) + -->
<!-- #               (PosOr.cont*session*group||category), -->
<!-- #              data = df_RTs, -->
<!-- #             family =Gamma(link = "inverse"), -->
<!-- #             control=glmerControl(optimizer = "bobyqa", -->
<!-- #                                  optCtrl = list(maxfun = 2e5))) -->
<!-- # saveRDS(m2_gamma_inverse,  file = here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_control_glmm_VOT_gamma_inverseLink.RDS")) -->
<!-- m2_gamma_inverse <- readRDS(file = here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_control_glmm_VOT_gamma_inverseLink.RDS")) -->

<!-- # m2_invGauss <- afex::lmer_alt(VOT ~ PosOr.cont*session*group + -->
<!-- #                (PosOr.cont*session||subject) + -->
<!-- #               (PosOr.cont*session*group||category), -->
<!-- #              data = df_RTs, -->
<!-- #             family =inverse.gaussian(link = "identity"), -->
<!-- #             control=glmerControl(optimizer = "bobyqa", -->
<!-- #                                  optCtrl = list(maxfun = 2e5))) -->
<!-- # didLmerConverge(m2_invGauss) -->
<!-- saveRDS(m2_invGauss,  file = here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_control_glmm_VOT_invGauss_identity.RDS")) -->
<!-- m2_gamma_inverse <- readRDS(file = here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_control_glmm_VOT_invGauss_identity.RDS")) -->

<!-- ## Get raw fit overview -->
<!-- print('LMM with boxcox-transformed RTs') -->
<!-- fit.gauss <- fitdistrplus::fitdist( -->
<!--   df_RTs$lVOT, distr = "norm", -->
<!--   method = "mle") -->
<!-- summary(fit.gauss) -->
<!-- #plot(fit.gamma) -->
<!-- print('Gamma distribution, identity link') -->
<!-- fit.gamma_identity <- fitdistrplus::fitdist( -->
<!--   df_RTs$VOT, distr = "gamma", -->
<!--   method = "mle") -->
<!-- summary(fit.gamma_identity) -->
<!-- print('LMM with raw RTs') -->
<!-- fit.gauss_raw <- fitdistrplus::fitdist( -->
<!--   df_RTs$VOT, distr = "norm", -->
<!--   method = "mle") -->
<!-- summary(fit.gauss_raw) -->
<!-- #plot(fit.gamma) -->
<!-- print('GLMM Gamma distribution with inverse Link') -->
<!-- fit.gamma_inverse <- fitdistrplus::fitdist( -->
<!--   df_RTs$VOT, distr = "invgamma", -->
<!--   method = "mle") -->
<!-- summary(fit.gamma_inverse) -->
<!-- print('invGauss distribution, identity link') -->
<!-- library(actuar) -->
<!-- # fit.invgauss_identity <- fitdistrplus::fitdist( -->
<!-- #   df_RTs$VOT, distr = "invgauss", -->
<!-- #   method = "mle", shaphe=1, dispersion=1, start=100) -->
<!-- # summary(fit.invgauss_identity) -->

<!-- plot(fit.gauss) -->
<!-- plot(fit.gamma_identity) -->
<!-- plot(fit.gauss_raw) -->
<!-- plot(fit.gamma_inverse) -->

<!-- ## Get Result Overview -->
<!-- print('MODEL SUMMARIES') -->
<!-- print('LMM with boxcox-transformed RTs') -->
<!-- summary(m2_lmm) -->
<!-- print('Gamma distribution, identity link') -->
<!-- summary(m2) -->
<!-- print('LMM with raw RTs') -->
<!-- summary(m2_lmm_raw) -->
<!-- print('Gamma distribution, inverse link') -->
<!-- summary(m2_gamma_inverse) -->
<!-- print('Inverse Gaussian distribution,  -->
<!--       identity link') -->
<!-- summary(m2_invGauss) -->



<!-- ## Check model -->
<!-- performance::check_model(m2_lmm)  -->
<!-- ggResidpanel::resid_panel(m2_lmm, smoother = TRUE, qqbands = TRUE, type = "pearson") -->
<!-- performance::check_model(m2)  -->
<!-- ggResidpanel::resid_panel(m2, smoother = TRUE, qqbands = TRUE, type = "pearson") -->
<!-- performance::check_model(m2_lmm_raw)  -->
<!-- ggResidpanel::resid_panel(m2_lmm_raw, smoother = TRUE, qqbands = TRUE, type = "pearson") -->
<!-- performance::check_model(m2_invGauss)  -->
<!-- ggResidpanel::resid_panel(m2_invGauss, smoother = TRUE, qqbands = TRUE, type = "pearson") -->
<!-- ``` -->

<!-- Compare to Bayesian analyses using brms  -->

<!-- ```{r} -->

<!-- ## Prior predictive checks -->
<!-- library(extraDistr) ## needed for half-normal distribution ## number of simulations -->
<!-- nsim<-1000 -->
<!-- ## number of observations generated each time: -->
<!-- nobs<-100  -->
<!-- y<-matrix(rep(NA,nsim*nobs),ncol = nobs) -->
<!-- mu<-rnorm(nsim,mean=0,sd=2000) -->
<!-- ## truncated normal, cut off at 0: sigma<-rtnorm(nsim,mean=0,sd=500,a=0) -->
<!-- for(i in 1:nsim){ -->
<!--   y[i,]<-rnorm(nobs,mean=mu[i],sd=sigma[i]) } -->


<!-- y<-matrix(rep(NA,nsim*nobs),ncol = nobs) mu<-rtnorm(nsim,mean=0,sd=2000,a=0) -->
<!-- for(i in 1:nsim){ y[i,]<-rnorm(nobs,mean=mu[i],sd=sigma[i]) } -->

<!-- priorpred<-"data { -->
<!--   int N; -->
<!-- } -->
<!-- parameters { -->
<!-- real<lower=0> mu; -->
<!-- real<lower=0> sigma; -->
<!-- } -->
<!-- model { -->
<!--     mu ~ normal(0,2000); -->
<!--     sigma ~ normal(0,500); -->
<!-- } -->
<!-- generated quantities { -->
<!--   vector[N] y_sim; -->
<!--   for(i in 1:N) { -->
<!--     y_sim[i] = normal_rng(mu,sigma); -->
<!--   }}" -->

<!-- #devtools::install_github("paul-buerkner/brms") -->
<!-- library(rstan) -->
<!-- options(mc.cores = parallel::detectCores()) library(brms) -->

<!-- ## generate 100 data-points -->
<!-- dat<-list(N=100) -->
<!-- ## fit model: -->
<!-- m1priorpred<-stan(model_code=priorpred, data=dat, -->
<!-- chains = 4, -->
<!--                   warmup = 1000, -->
<!--                 iter = 2000) -->

<!-- ## extract and plot one of the data-sets: -->
<!-- y_sim<-extract(m1priorpred,pars="y_sim")  -->
<!-- str(y_sim) -->

<!-- hist(y_sim$y_sim[1,], -->
<!-- main="Prior predictive distribution", xlab="y_sim",freq=FALSE) -->

<!-- m1<-"data { -->
<!--   int N; -->
<!--   real y[N]; // data -->
<!-- } -->
<!-- parameters { -->
<!-- real<lower=0> mu; -->
<!-- real<lower=0> sigma; -->
<!-- } -->
<!-- model { -->
<!-- mu ~ normal(0,2000); -->
<!-- sigma ~ normal(0,500); -->
<!-- y ~ normal(mu,sigma); -->
<!-- } -->
<!-- generated quantities { -->
<!--   vector[N] y_sim; -->
<!--   for(i in 1:N) { -->
<!--     y_sim[i] = normal_rng(mu,sigma); -->
<!--   }} -->
<!-- " -->


<!-- set.seed(123) -->
<!-- N <- 500 -->
<!-- true_mu <- 400 -->
<!-- true_sigma <- 125 -->
<!-- y <- rnorm(N, true_mu, true_sigma) -->
<!-- y <- round(y) -->
<!-- fake_data <- data.frame(y=y) dat<-list(y=y,N=N) -->


<!-- ## fit model: -->
<!-- m1rstan<-stan(model_code=m1, data=dat, -->
<!--                   chains = 4, -->
<!--                 iter = 2000) -->
<!-- ## extract posteriors: -->
<!-- posteriors<-extract(m1rstan,pars=c("mu","sigma")) -->

<!-- priors <- c(set_prior("normal(0, 2000)", class = "Intercept"), -->
<!-- set_prior("normal(0, 500)", class = "sigma")) -->

<!-- m1brms<-brm(y~1,noreading_data,prior = priors, iter = 2000, -->
<!-- warmup = 1000, -->
<!-- chains = 4, -->
<!-- family = gaussian(), -->
<!-- control = list(adapt_delta = 0.99)) -->

<!-- m1_fakebrms<-brm(y~1,fake_data,prior = priors, -->
<!-- iter = 2000, chains = 4,family = gaussian(), control = list(adapt_delta = 0.99)) -->

<!-- mu_post<-posterior_samples(m1brms, pars=c("b_Intercept"))$b_Intercep -->
<!-- mean(mu_post>170) -->
<!-- posterior_interval(m1brms,pars=c("b_Intercept")) -->

<!-- round(quantile(mu_post,prob=c(0.135,0.865))) -->

<!-- priors <- c(set_prior("uniform(0, 5000)", class = "Intercept"), -->
<!-- set_prior("normal(0, 500)", class = "sigma")) -->

<!-- m2<-brm(y~1,noreading_data,prior = priors, -->
<!-- iter = 2000, chains = 4,family = gaussian(), control = list(adapt_delta = 0.99)) -->



<!-- contrasts(df_RTs$group) -->
<!-- contrasts(df_RTs$session) -->
<!-- table(df_RTs$PosOr.cont) -->

<!-- # fit1 <- brm(bf( -->
<!-- #   symptom_post ~ group, sigma ~ group), -->
<!-- #   data = dat1, family = gamma(), link="identity") -->

<!-- priors <- c( -->
<!--   set_prior("normal(0, 10)", class = "Intercept"), -->
<!--   set_prior("normal(0, 1)", class = "b", -->
<!--             coef = "PosOr.cont"),  -->
<!--   set_prior("normal(0, 1)", class = "sd"), -->
<!--   # set_prior("normal(0, 1)", class = "b", -->
<!--   #           coef = "session"),  -->
<!--   # set_prior("normal(0, 1)", class = "sd", -->
<!--   #           coef = "session"), -->
<!--   # set_prior("normal(0, 1)", class = "b", -->
<!--   #           coef = "group"),  -->
<!--   # set_prior("normal(0, 1)", class = "sd", -->
<!--   #           coef = "group"), -->
<!--   set_prior("normal(0, 1)", -->
<!--             class = "sigma"),  -->
<!--   set_prior("lkj(2)",class = "cor")) -->

<!-- # m_brm_lVOT<-brm(lVOT ~ PosOr.cont*session*group + -->
<!-- #                (PosOr.cont+session|subject) + -->
<!-- #                (PosOr.cont+group|category), -->
<!-- #           df_RTs, -->
<!-- #           family=gaussian(), -->
<!-- #           prior=priors) -->
<!-- # saveRDS(m_brm_lVOT, file = here::here("results", "tables", "CSI_online_aphasia_SessionxGroup_control_brm_lVOT_norm.RDS")) -->

<!-- m_brm_lVOT <- readRDS( -->
<!--   file = here::here("results", "tables", -->
<!--               "CSI_online_aphasia_SessionxGroup_control_brm_lVOT_norm.RDS")) -->
<!-- summary(m_brm_lVOT) -->


<!-- ### checks -->
<!-- pp_check(m_brm_lVOT, nsamples = 100)+  -->
<!--   theme(text = element_text(size=16), -->
<!--         legend.text=element_text(size=16)) -->


<!--  library(bayesplot) -->
<!-- postgg<-posterior_samples(m_brm_lVOT) -->
<!-- # extract variances:  -->
<!-- alpha<-postgg$b_Intercept  -->
<!-- beta_PosOr<-postgg$b_PosOr.cont -->
<!-- beta_session2<-postgg$b_session2 -->
<!-- beta_session3<-postgg$b_session3 -->
<!-- beta_group2M1<-postgg$b_group2M1 -->
<!-- beta_PosOr.contXsession2<- -->
<!--   postgg$`b_PosOr.cont:session2` -->
<!-- beta_PosOr.contXsession3 <- -->
<!--   postgg$`b_PosOr.cont:session3` -->
<!-- beta_PosOr.contXgroup2M1 <- -->
<!--   postgg$`b_PosOr.cont:group2M1` -->
<!-- beta_session2Xgroup2M1 <-  -->
<!--   postgg$`b_session2:group2M1` -->
<!-- beta_session3Xgroup2M1 <-  -->
<!--   postgg$`b_session3:group2M1` -->
<!-- beta_PosOr.contXsession2Xgroup2M1 <-  -->
<!--   postgg$`b_PosOr.cont:session2:group2M1` -->
<!-- beta_PosOr.contXsession3Xgroup2M1 <-  -->
<!--   postgg$`b_PosOr.cont:session3:group2M1` -->
<!-- cor_category__Intercept__PosOr.cont<- -->
<!--   posterior_samples( -->
<!--     m_brm_lVOT," -->
<!--     cor_category__Intercept__PosOr.cont") -->
<!-- cor_category__Intercept__group2M1<- -->
<!--   posterior_samples( -->
<!--     m_brm_lVOT," -->
<!--     cor_category__PosOr.cont__group2M1") -->
<!-- cor_category__Intercept__PosOr.cont__group2M1<- -->
<!--   posterior_samples( -->
<!--     m_brm_lVOT," -->
<!--     cor_category__PosOr.cont__group2M1") -->
<!-- cor_subject__Intercept__PosOr.cont<- -->
<!--   posterior_samples( -->
<!--     m_brm_lVOT," -->
<!--     cor_subject__Intercept__PosOr.cont") -->
<!-- cor_subject__Intercept__session2<- -->
<!--   posterior_samples( -->
<!--     m_brm_lVOT," -->
<!--     cor_subject__Intercept__session2") -->
<!-- cor_subject__Intercept__session3<- -->
<!--   posterior_samples( -->
<!--     m_brm_lVOT," -->
<!--     cor_subject__Intercept__session2") -->
<!-- cor_subject__PosOr.cont__session2<- -->
<!--   posterior_samples( -->
<!--     m_brm_lVOT," -->
<!--     cor_subject__PosOr.cont__session2") -->
<!-- cor_subject__PosOr.cont__session3<- -->
<!--   posterior_samples( -->
<!--     m_brm_lVOT," -->
<!--     cor_subject__PosOr.cont__session3") -->
<!-- cor_subject__session2__session3<- -->
<!--   posterior_samples( -->
<!--     m_brm_lVOT," -->
<!--     cor_subject__session2__session3") -->

<!-- cor<-posterior_samples(m_brm_lVOT,"^cor") -->
<!-- sd<-posterior_samples(m_brm_lVOT,"^sd") -->
<!-- sigma<-posterior_samples(m_brm_lVOT,"sigma") -->

<!-- ``` -->

<!-- ##### Additional exploratory analyses with lesion sizes in different brain areas -->

<!-- ```{r} -->
<!-- summarySE(data=df_RTs_PWA, -->
<!--                 measurevar="VOT", -->
<!--                 groupvars=c("subject", "SoSci_ID", "ID",  -->
<!--                             "LHoverall", "ATL", "IFG", "MTG_ITG", -->
<!--                             "SMG_AG", "Precentral", -->
<!--                             "session","PosOr") -->
<!--               ) -> summary -->
<!-- # Mean RTs 1-2-3 -->
<!-- summarySE(data=df_RTs_PWA, -->
<!--                 measurevar="VOT", -->
<!--                 groupvars=c("subject","SoSci_ID", "ID",  -->
<!--                             "LHoverall", "ATL", "IFG", "MTG_ITG", -->
<!--                             "SMG_AG", "Precentral", -->
<!--                             "session") -->
<!--               ) -> summary2 -->
<!--     ## Calculate difference between session 1 and 2 -->
<!-- for(i in 1:length(unique(summary2$subject))){ -->
<!--   summary2$session_2M1[summary2$subject==unique(summary2$subject)[i]] <-  -->
<!--     summary2$VOT[summary2$session==2& -->
<!--                    summary2$subject==unique(summary2$subject)[i]] -  -->
<!--     summary2$VOT[summary2$session==1& -->
<!--                    summary2$subject==unique(summary2$subject)[i]] -->
<!-- } -->
<!--     ## add to the overall summary -->
<!-- for(i in 1:length(unique(summary2$subject))){ -->
<!--   summary$session_2minus1[ -->
<!--     summary$subject == unique(summary2$subject)[i]] <-  -->
<!--     summary2$session_2M1[summary2$subject ==  -->
<!--                            unique(summary2$subject)[i]][1] -->

<!-- } -->
<!--   # Ordinal position effect, across sessions -->
<!-- summarySE(data=df_RTs_PWA, -->
<!--                 measurevar="VOT", -->
<!--                 groupvars=c("subject","SoSci_ID", "ID",  -->
<!--                             "LHoverall", "ATL", "IFG", "MTG_ITG", -->
<!--                             "SMG_AG", "Precentral", -->
<!--                             "PosOr") -->
<!--               ) -> summary3 -->
<!--       ## Calculate mean ordinal position effect -->
<!-- for(i in 1:length(unique(summary3$subject))){ -->
<!--   summary3$mean_csi[summary3$subject==unique(summary3$subject)[i]] <- -->
<!--     (summary3$VOT[summary3$subject==unique(summary3$subject)[i] & -->
<!--                   summary3$PosOr==5] - -->
<!--     summary3$VOT[summary3$subject==unique(summary3$subject)[i] & -->
<!--                   summary3$PosOr==1]) -->
<!-- } -->
<!--       ##  Add to overall summary -->
<!-- for(i in 1:length(unique(summary3$subject))){ -->
<!--   summary$mean_csi[ -->
<!--     summary$subject == unique(summary3$subject)[i]] <-  -->
<!--     summary3$mean_csi[summary3$subject ==  -->
<!--                            unique(summary3$subject)[i]][1] -->

<!-- } -->

<!-- ### Save as word and csv file -->
<!-- library(flextable) -->
<!-- huxt_word <- huxtable::huxtable(summary) -->
<!-- huxt_word <- huxtable::set_number_format(huxt_word, round(2)) -->
<!-- huxtable::quick_docx(huxt_word,  -->
<!--                      file = here::here("results", "tables", -->
<!--                                        "CSI_online_aphasia_mean_PosOr_Session_for_MRT.docx"),  -->
<!--                                        open = FALSE) -->
<!-- write.csv(summary, here::here("results", "tables", -->
<!--                                    "CSI_online_aphasia_mean_PosOr_Session_for_MRT.csv")) -->

<!-- # -------------------------------------------------------------- -->

<!-- # Mean CSI-effect per person and session, according to LMM -->
<!-- m1_lmm_PWA <- lmer(VOTlog ~ PosOr.cont*session + -->
<!--                (PosOr.cont+session|subject) + -->
<!--               (1|category), -->
<!--              data = df_RTs_PWA, -->
<!--             control=lmerControl(optimizer = "bobyqa", -->
<!--                                  optCtrl = list(maxfun = 2e5))) -->
<!-- modeloutput <- coef(m1_lmm_PWA)$subject -->

<!-- ## Add MRT data to model output -->
<!-- modeloutput$subject <- as.numeric(as.character(row.names(modeloutput))) -->
<!-- for(i in 1:nrow(modeloutput)){ -->
<!--   modeloutput$SoSci_ID[i] <- df_RTs_PWA$SoSci_ID[ -->
<!--     df_RTs_PWA$subject == modeloutput$subject[i]][1] -->
<!--   modeloutput$ID[i] <- df_RTs_PWA$ID[ -->
<!--     df_RTs_PWA$subject == modeloutput$subject[i]][1] -->
<!--   modeloutput$LHoverall[i] <- df_RTs_PWA$LHoverall[ -->
<!--     df_RTs_PWA$subject == modeloutput$subject[i]][1] -->
<!--   modeloutput$ATL[i] <- df_RTs_PWA$ATL[ -->
<!--     df_RTs_PWA$subject == modeloutput$subject[i]][1] -->
<!--   modeloutput$IFG[i] <- df_RTs_PWA$IFG[ -->
<!--     df_RTs_PWA$subject == modeloutput$subject[i]][1] -->
<!--   modeloutput$MTG_ITG[i] <- df_RTs_PWA$MTG_ITG[ -->
<!--     df_RTs_PWA$subject == modeloutput$subject[i]][1] -->
<!--   modeloutput$SMG_AG[i] <- df_RTs_PWA$SMG_AG[ -->
<!--     df_RTs_PWA$subject == modeloutput$subject[i]][1] -->
<!--   modeloutput$Precentral[i] <- df_RTs_PWA$Precentral[ -->
<!--     df_RTs_PWA$subject == modeloutput$subject[i]][1] -->
<!-- } -->
<!--  # Export as word and csv-file -->
<!-- huxt_word <- huxtable::huxtable(modeloutput) -->
<!-- huxt_word <- huxtable::set_number_format(huxt_word, round(2)) -->
<!-- huxtable::quick_docx(huxt_word,  -->
<!--                      file = here::here( -->
<!--                        "results", "tables", -->
<!--                        "CSI_online_aphasia_mean_PosOr_Session_LMM_for_MRT.docx"),  -->
<!--                                        open = FALSE) -->
<!-- write.csv(modeloutput, here::here("results", "tables", -->
<!--                                   "CSI_online_aphasia_mean_PosOr_Session_LMM_for_MRT.csv")) -->
<!-- ``` -->

<!-- ##### Correlation matrix -->
<!-- ###### Session effect, based on raw means -->

<!-- ```{r} -->
<!-- unique_session2M1 <- summary2 %>%  -->
<!--   dplyr::select(c("subject", "session_2M1",  -->
<!--            "LHoverall", "ATL", "IFG", "MTG_ITG", -->
<!--            "SMG_AG", "Precentral")) %>% unique() %>%  -->
<!--   dplyr::select(-subject) -->

<!-- map <- cor(unique_session2M1) -->

<!-- ## Using corrplot -->
<!-- corrplot::corrplot(map, method='number', type='upper') -->

<!-- ## Using PerformanceAnalytics (caution: Calculates all correlations and corrects for them) -->
<!-- PerformanceAnalytics::chart.Correlation(unique_session2M1,  -->
<!--                                         histogram=TRUE, pch=19, -->
<!--                                         method="pearson") -->

<!-- ## Correlation test -->
<!-- cor.test(unique_session2M1$session_2M1, unique_session2M1$MTG_ITG) -->
<!-- ``` -->

<!-- ###### Session effect, based on LMM estimates -->

<!-- ```{r} -->
<!-- unique_session2M1 <- modeloutput %>%  -->
<!--   dplyr::select(c("subject", "session2",  -->
<!--            "LHoverall", "ATL", "IFG", "MTG_ITG", -->
<!--            "SMG_AG", "Precentral")) %>% unique() %>%  -->
<!--   dplyr::select(-subject) -->

<!-- map <- cor(unique_session2M1) -->

<!-- ## Using corrplot -->
<!-- corrplot::corrplot(map, method='number', type='upper') -->

<!-- ## Using PerformanceAnalytics (caution: Calculates all correlations and corrects for them) -->
<!-- PerformanceAnalytics::chart.Correlation(unique_session2M1,  -->
<!--                                         histogram=TRUE, pch=19, -->
<!--                                         method="pearson") -->

<!-- ## Correlation test -->
<!-- cor.test(unique_session2M1$session2, unique_session2M1$IFG) -->
<!-- cor.test(unique_session2M1$session2, unique_session2M1$MTG_ITG) -->
<!-- ``` -->

<!-- ###### Ordinal position effect, based on raw means -->

<!-- ```{r} -->
<!-- unique_mean_csi <- summary3 %>%  -->
<!--   dplyr::select(c("subject", "mean_csi",  -->
<!--            "LHoverall", "ATL", "IFG", "MTG_ITG", -->
<!--            "SMG_AG", "Precentral")) %>% unique() %>%  -->
<!--   dplyr::select(-subject) -->

<!-- map <- cor(unique_mean_csi) -->

<!-- ## Using corrplot -->
<!-- corrplot::corrplot(map, method='number', type='upper') -->

<!-- ## Using PerformanceAnalytics (caution: Calculates all correlations and corrects for them) -->
<!-- PerformanceAnalytics::chart.Correlation(unique_mean_csi,  -->
<!--                                         histogram=TRUE, pch=19, -->
<!--                                         method="pearson") -->

<!-- ## Correlation test -->
<!-- cor.test(unique_mean_csi$mean_csi, unique_mean_csi$MTG_ITG, -->
<!--          method="pearson") -->
<!-- cor.test(unique_mean_csi$mean_csi, unique_mean_csi$Precentral,  -->
<!--          method="pearson") -->
<!-- cor.test(unique_mean_csi$mean_csi, unique_mean_csi$ATL,  -->
<!--          method="pearson") -->
<!-- ``` -->


<!-- ###### Ordinal position effect, based on raw means -->

<!-- ```{r} -->
<!-- unique_mean_csi <- modeloutput %>%  -->
<!--   dplyr::select(c("subject", "PosOr.cont",  -->
<!--            "LHoverall", "ATL", "IFG", "MTG_ITG", -->
<!--            "SMG_AG", "Precentral")) %>% unique() %>%  -->
<!--   dplyr::select(-subject) -->

<!-- map <- cor(unique_mean_csi) -->

<!-- ## Using corrplot -->
<!-- corrplot::corrplot(map, method='number', type='upper') -->

<!-- ## Using PerformanceAnalytics (caution: Calculates all correlations and corrects for them) -->
<!-- PerformanceAnalytics::chart.Correlation(unique_mean_csi,  -->
<!--                                         histogram=TRUE, pch=19, -->
<!--                                         method="pearson") -->

<!-- ## Correlation test -->
<!-- cor.test(unique_mean_csi$PosOr.cont, unique_mean_csi$MTG_ITG, -->
<!--          method="pearson") -->
<!-- cor.test(unique_mean_csi$PosOr.cont, unique_mean_csi$Precentral,  -->
<!--          method="pearson") -->
<!-- ``` -->

<!-- Analysen:  -->
<!-- - LH gesamt = Gesamtgröße der Lesion: We expect no correlation -->
<!-- - MTG =  memory  -> We might expect correlations -->
<!-- - IFG = executive control  -> We might expect correlations -->
<!-- - ATL = supra-modal semantic -> We might expect correlations -->
<!-- - Precentral = Premotor area -> We don't expect correlations -->

<!-- Are there correlations between lesion and (a) interference effect (mean interference effect/person) and (b) overall RT improvement between session 1 and 2?  -->
<!-- -> correlation matrix -->

<!-- If there are no correlations: Do we need to continue analysing at all?  -->
<!-- Add correlations successively depending on R-value -->

<!-- We have good hypotheses regarding (a) LH gesamt, (b) MTG, (c) IFG, and (d) ATL  -->

