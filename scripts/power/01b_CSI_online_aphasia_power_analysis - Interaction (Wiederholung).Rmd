---
title: "Power Analysis for CSI online typing with patients with aphasia - Interaction effect: Session x Ordinal position (wh estimates)"
author: "Kirsten Stark"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# load packages

```{r message=FALSE}
library(tidyr)
library(dplyr)
library(devtools)
library(MASS)
library(lme4)
library(lmerTest)
library(simr)
library(pbkrtest)
library(testthat)
library(ggplot2)

rm(list = ls())

today <- Sys.Date()
today <- format(today, format="%d%m%y")


```


# Load data from Lorenz, Doering, van Scherpenberg, Pino, Abdel Rahman, & Obrig (2021)

In this lab-based study, people with Aphasia did a CSI task with 3 repetitions in two subsequent weeks. Both testing sessions had different items. Additionally, participants also did a CSI task with compounds (not relevant here).  
The data loaded here are already cleaned for errors and participants.

```{r load data Lorenz_et_al}
# Set number of iterations 
n_it = 1000
# load data
df <- read.csv2(here::here("data", "power-analysis",
                "Doeringetal_PWA_naming_simple_nouns_data_for_modelling.csv"))

# subset the relevant columns
df <- df %>% 
  filter(error==1) %>% 
    # repet_trig = repetition (151,152,153 is 1,2,3), 
    # wh = testing session 1 and 2, 
    # cat_nr = 18 categories (Ã  5 members each)
  dplyr::select(c(subject, Ordinal_position, RT, 
                  repet_trig, wh, item_id, cat_nr)) %>%
  droplevels() %>% 
  dplyr::rename(repet = repet_trig, 
                OrdPos = Ordinal_position) %>% 
  # factorize colums
  mutate(subject = as.factor(subject),
         repet = as.factor(repet), 
         wh = as.factor(wh), 
         item_id = as.factor(item_id),
         cat_nr = as.factor(cat_nr))
```

The data structure is somewhat different from the planned experiment. Our experiment will have no repetition, but three testing sessions with the same items. Does the variance differ between the repetitions within a session and the two testing sessions? 

```{r}
df %>% group_by(wh, repet, OrdPos) %>% 
  summarize(sd = sd(RT, na.rm = T))

df %>% group_by(wh)%>% summarize(sd = sd(RT, na.rm = T))
df %>% group_by(repet)%>% summarize(sd = sd(RT, na.rm = T))
df %>% group_by(wh, repet)%>%summarize(sd = sd(RT, na.rm = T))
df %>% group_by(OrdPos)%>%summarize(sd = sd(RT,na.rm=T))
```

Overall, the variances are not too different (but still). The variance in the second session seems to be somewhat higher and the variances seem to increase with ordinal position.


# Comparison 1: Power analysis for the interaction of Ordinal position and Session

Subset the data to the first repetition of the first and second session. 

```{r}
df_Ord <- df %>% filter(repet == 151) %>% droplevels()
```


## 1) Set up models based on the structure of the online CSI experiment
Unfortunately, simr does not work properly with GLMMs. Therefore, for the power analysis, we will set up an LMM with transformed RTs  
a) center OrdPos (continuous predictor)

```{r}
# center continuous predictor
df_Ord %>% mutate(OrdPos_num = case_when(OrdPos == "OP1" ~1,
                                         OrdPos == "OP2" ~2,
                                         OrdPos == "OP3" ~3,
                                         OrdPos == "OP4" ~4,
                                         OrdPos == "OP5" ~5)) %>%
                  mutate(OrdPos.c=
                    scale(as.numeric(as.character(OrdPos_num)), 
                     center = TRUE, scale = FALSE)) %>% 
        mutate(wh=as.factor(wh))-> df_Ord
```

b) Check distribution of RTs

```{r RT distributions}
# Boxcox plot suggests inverse transformation: 
boxcox(df_Ord$RT ~ df_Ord$OrdPos*df_Ord$wh)

# # check distribution of RTs (by eyeballing)
# # 1) density plot of RTs
# qplot(data=df_Ord, RT, geom="density", na.rm=TRUE)+ theme_bw() 
# # 2) plot data against real normal distribution -> is it way off?
# qqnorm(df_Ord$RT); qqline(df_Ord$RT)
# 
# # check distribution of logRTs (by eyeballing)
# df_Ord$lRT <- log(df_Ord$RT)
# # 1) density plot of logRTs
# qplot(data=df_Ord, lRT, geom="density", na.rm=TRUE)+ theme_bw() 
# # 2) plot data against real normal distribution -> is it way off?
# qqnorm(df_Ord$lRT); qqline(df_Ord$lRT)
# ### data kind of normally distributed. Log RTs fit better
# 
# # check distribution of 1/RT (by eyeballing)
# df_Ord$iRT <- 1/df_Ord$RT
# # 1) density plot of logRTs
# qplot(data=df_Ord, iRT, geom="density", na.rm=TRUE)+ theme_bw() 
# # 2) plot data against real normal distribution -> is it way off?
# qqnorm(df_Ord$iRT); qqline(df_Ord$iRT)
# ### data kind of normally distributed. Inverse RTs fit well
```

Check the goodness of fit of an inverse transformation (with RT divided by 1000: 1/(x/1000) = 1000/x): 

```{r fit.normal}
library(fitdistrplus)
# fit.normal<- fitdist(df_Ord$RT, distr = "norm", method = "mle")
# summary(fit.normal)
# plot(fit.normal)
df_Ord$iRT <-1000/df_Ord$RT
# plot this transformation distribution
plot(df_Ord$RT, df_Ord$iRT)
# check fit
fit.normal_inv<- fitdist(df_Ord$iRT, distr = "norm", method = "mle")
summary(fit.normal_inv)
plot(fit.normal_inv)
```

An inverse transformation fits the data well. We will thus use this kind of transformation


c) Set up the models  
*Model 1: Linear model with continuous predictor "Ordinal position", treatment contrasted predictor "repetition" and inversely transformed RT data*

```{r LMM1 online}
# compute sliding difference contrast: Intercept is grand mean, second level is compared to first level
contrasts(df_Ord$wh) <- contr.sdif(2)
# maximal model has singular fit - stepwise reduction
#lmm1 <- lmer(iRT ~ OrdPos.c*wh + 
#               (OrdPos.c*wh|subject) +(OrdPos.c*wh|cat_nr) ,
#            data = df_Ord, REML = FALSE,
#            control=lmerControl(optimizer = "bobyqa"))
lmm1 <- lmer(iRT ~ OrdPos.c*wh + 
               (wh|subject) +(wh|cat_nr) ,
            data = df_Ord, REML = FALSE,
            control=lmerControl(optimizer = "bobyqa",
                                optCtrl=list(maxfun=2e5)))


# lmm1 <- afex::lmer_alt(iRT ~ OrdPos.c*wh + 
#                (wh||subject) +(OrdPos.c*wh||cat_nr) ,
#             data = df_Ord, REML = FALSE,
#             control=lmerControl(optimizer = "bobyqa",
#                                 optCtrl=list(maxfun=2e5)))
# isSingular(lmm1)
# summary(lmm1)
```

## A) Power analysis for the Ordinal position effect in this more complex model

### 2a) Extend dataset
Other than Lorenz et al, we have 24 categories (we use the same stimuli as in Stark, van Scherpenberg et al., 2021). So we extend along categories.  
Additionally, we also extend along participants: 25 participants 
(20 + 25%)

```{r}
lmm24 <- extend(lmm1, along="cat_nr", n=24)
m2data <- getData(lmm24) 
## ok, data were indeed extended to n categories ;-)
str(m2data)
str(df_Ord)

lmm24_20 <- extend(lmm24, along="subject", n=20)
 m2data <- getData(lmm24_20) 

lmm24_25 <- extend(lmm24, along="subject", n=25)
 m2data <- getData(lmm24_25) 
# ## ok, data were indeed extended to n subjects ;-)
str(m2data)
# str(df_Ord)
```

### 3a) Specify effect sizes: Use the ordinal position effect from Lorenz et al 2021

*Model 1: Linear model with continuous predictor "Ordinal position" and inversely transformed RT data* 
Ordinal position effect: ~77 ms


```{r LMM_eff_Lorenz}
# use this as the fixed effect of interest
fixef(lmm24_20)
fixef(lmm24_25)
```


### 4a) Run the power analysis for ordinal position based on effect size from Lorenz et al (2021)

```{r}
set.seed(99)
```

*Model 1: Linear model with continuous predictor "Ordinal position" and the factor "repetition" (sliding diff. contrast) and inversely transformed RT data (sample size: 16)* 

```{r power_eff_OrdPos_16, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM_OrdPos_16 <- powerCurve(lmm24_20,along = "subject", 
                                 test=fixed("OrdPos.c","t"),
                          breaks = c(16), nsim = n_it) 
lastResult()$warnings
lastResult()$errors
```

```{r}
PowerLMM_OrdPos_16
```


*Model 2: Linear model with continuous predictor "Ordinal position" and the factor "repetition" (sliding diff. contrast) and inversely transformed RT data (sample size: 16)* 

```{r power_eff_OrdPos_20, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM_OrdPos_20 <- powerSim(lmm24_20, test=fixed("OrdPos.c","t"), nsim = n_it) # increase to nsim > 1000 for real test
lastResult()$warnings
lastResult()$errors
```

```{r}
PowerLMM_OrdPos_20
```

*Model 3: Linear model with continuous predictor "Ordinal position" and the factor "repetition" (sliding diff. contrast) and inversely transformed RT data (sample size: 25)* 

```{r power_eff_OrdPos_25, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM_OrdPos_25 <- powerSim(lmm24_25, test=fixed("OrdPos.c","t"), nsim = n_it) # increase to nsim > 1000 for real test
lastResult()$warnings
lastResult()$errors
```

```{r}
PowerLMM_OrdPos_25
```

### Do the same with the effect size from Stark et al (2021)

#### 3a) Specify effect sizes: Use the ordinal position effect from Stark et al 2021

*Model 1: Linear model with continuous predictor "Ordinal position" and inversely transformed RT data* 
Ordinal position effect: ~31


```{r LMM_eff_Stark}
# take the grand mean 
gm <- mean(df_Ord$RT)
fixeff_Stark <- (1000/(gm+(31/2))) - (1000/(gm-(31/2)))
# use this as the fixed effect of interest
lmm20_Stark <- lmm24_20
fixef(lmm20_Stark)["OrdPos.c"] <- fixeff_Stark
lmm25_Stark <- lmm24_25
fixef(lmm25_Stark)["OrdPos.c"] <- fixeff_Stark
```


#### 4a) Run the power analysis for ordinal position based on effect size from Stark et al (2021)

```{r}
set.seed(99)
```


*Model 1: Linear model with continuous predictor "Ordinal position" and the factor "repetition" (sliding diff. contrast) and inversely transformed RT data (sample size: 16)* 

```{r power_eff_OrdPos_16_Stark, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM_OrdPos_16_Stark <- powerCurve(lmm24_20,along = "subject",
                                       test=fixed("OrdPos.c","t"),
                          breaks = c(16), nsim = n_it) 
lastResult()$warnings
lastResult()$errors
```

```{r}
PowerLMM_OrdPos_16_Stark
```

*Model 2: Linear model with continuous predictor "Ordinal position" and the factor "repetition" (sliding diff. contrast) and inversely transformed RT data (sample size: 20)*

```{r power_eff_OrdPos_20_Stark, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM_OrdPos_20_Stark <- powerSim(lmm20_Stark, test=fixed("OrdPos.c","t"), nsim = n_it) # increase to nsim > 1000 for real test
lastResult()$warnings
lastResult()$errors
```

```{r}
PowerLMM_OrdPos_20_Stark
```

*Model 3: Linear model with continuous predictor "Ordinal position" and the factor "repetition" (sliding diff. contrast) and inversely transformed RT data (sample size: 25)* 

```{r power_eff_OrdPos_25_Stark, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM_OrdPos_25_Stark <- powerSim(lmm25_Stark, test=fixed("OrdPos.c","t"), nsim = n_it) # increase to nsim > 1000 for real test
lastResult()$warnings
lastResult()$errors
```

```{r}
PowerLMM_OrdPos_25_Stark
```



# --------------------------------------------
## B) Power analysis for the Interaction effect Ordinal position x Session

### 2b) Extend data set
We will use the sample size as for the effect of main interest (ordinal position)

### 3b)+ 4b) Specify effect sizes and run different power analyses
To specify the effect sizes, we always take the grand mean and take +- 1/2 the inversly transformed difference we want to implement. 
We keep the two main effects unchanged. 

#### 35 ms interaction effect, 20 VP

```{r}
gm <- mean(df_Ord$RT)
eff_35ms <- (1000/(gm+(35/2))) - (1000/(gm-(35/2)))
fixef(lmm24_20)["OrdPos.c:wh2-1"]<- eff_35ms
```

*Model B1: Linear model with interaction effect "Ordinal position x Session" of 35 ms* 

```{r PowerSim_Interaction35_20, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM1_Interaction35_20 <- powerSim(lmm24_20, test=fixed("OrdPos.c:wh2-1","t"), nsim = n_it) # increase to nsim > 1000 for real test
lastResult()$warnings
lastResult()$errors
``` 

```{r}
PowerLMM1_Interaction35_20
```


#### 35 ms interaction effect, 25 VP

```{r}
gm <- mean(df_Ord$RT)
eff_35ms <- (1000/(gm+(35/2))) - (1000/(gm-(35/2)))
fixef(lmm24_25)["OrdPos.c:wh2-1"]<- eff_35ms
```

*Model B1: Linear model with interaction effect "Ordinal position x Session" of 35 ms* 

```{r PowerSim_Interaction35, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM1_Interaction35 <- powerSim(lmm24_25, test=fixed("OrdPos.c:wh2-1","t"), nsim = n_it) # increase to nsim > 1000 for real test
lastResult()$warnings
lastResult()$errors
``` 

```{r}
PowerLMM1_Interaction35
```


#### 40 ms interaction effect, 20 VP

```{r}
gm <- mean(df_Ord$RT)
eff_40ms <- (1000/(gm+(40/2))) - (1000/(gm-(40/2)))
fixef(lmm24_20)["OrdPos.c:wh2-1"]<- eff_40ms
```

*Model B2: Linear model with interaction effect "Ordinal position x Session" of 40 ms* 

```{r PowerSim_Interaction40_20, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM1_Interaction40_20 <- powerSim(lmm24_20, test=fixed("OrdPos.c:wh2-1","t"), nsim = n_it) # increase to nsim > 1000 for real test
lastResult()$warnings
lastResult()$errors
``` 

```{r}
PowerLMM1_Interaction40_20
```


#### 40 ms interaction effect, 25 VPs

```{r}
gm <- mean(df_Ord$RT)
eff_40ms <- (1000/(gm+(40/2))) - (1000/(gm-(40/2)))
fixef(lmm24_25)["OrdPos.c:wh2-1"]<- eff_40ms
```

*Model B2: Linear model with interaction effect "Ordinal position x Session" of 40 ms* 

```{r PowerSim_Interaction40, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM1_Interaction40 <- powerSim(lmm24_25, test=fixed("OrdPos.c:wh2-1","t"), nsim = n_it) # increase to nsim > 1000 for real test
lastResult()$warnings
lastResult()$errors
``` 

```{r}
PowerLMM1_Interaction40
```


#### 45 ms interaction effect, 20 VP

```{r}
gm <- mean(df_Ord$RT)
eff_45ms <- (1000/(gm+(45/2))) - (1000/(gm-(45/2)))
fixef(lmm24_20)["OrdPos.c:wh2-1"]<- eff_45ms
```

*Model B3: Linear model with interaction effect "Ordinal position x Session" of 45 ms* 

```{r PowerSim_Interaction45_20, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM1_Interaction45_20 <- powerSim(lmm24_20, test=fixed("OrdPos.c:wh2-1","t"), nsim = n_it) # increase to nsim > 1000 for real test
lastResult()$warnings
lastResult()$errors
``` 

```{r}
PowerLMM1_Interaction45_20
```

#### 45 ms interaction effect, 25 VP

```{r}
gm <- mean(df_Ord$RT)
eff_45ms <- (1000/(gm+(45/2))) - (1000/(gm-(45/2)))
fixef(lmm24_25)["OrdPos.c:wh2-1"]<- eff_45ms
```

*Model B3: Linear model with interaction effect "Ordinal position x Session" of 45 ms* 

```{r PowerSim_Interaction45, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM1_Interaction45 <- powerSim(lmm24_25, test=fixed("OrdPos.c:wh2-1","t"), nsim = n_it) # increase to nsim > 1000 for real test
lastResult()$warnings
lastResult()$errors
``` 

```{r}
PowerLMM1_Interaction45
```


#### 50 ms interaction effect, 20 VP

```{r}
gm <- mean(df_Ord$RT)
eff_50ms <- (1000/(gm+(50/2))) - (1000/(gm-(50/2)))
fixef(lmm24_20)["OrdPos.c:wh2-1"]<- eff_50ms
```

*Model B4: Linear model with interaction effect "Ordinal position x Session" of 50 ms* 

```{r PowerSim_Interaction50_20, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM1_Interaction50_20 <- powerSim(lmm24_20, test=fixed("OrdPos.c:wh2-1","t"), nsim = n_it) # increase to nsim > 1000 for real test
lastResult()$warnings
lastResult()$errors
``` 

```{r}
PowerLMM1_Interaction50_20
```


#### 50 ms interaction effect, 25 VP

```{r}
gm <- mean(df_Ord$RT)
eff_50ms <- (1000/(gm+(50/2))) - (1000/(gm-(50/2)))
fixef(lmm24_25)["OrdPos.c:wh2-1"]<- eff_50ms
```

*Model B4: Linear model with interaction effect "Ordinal position x Session" of 50 ms* 

```{r PowerSim_Interaction50, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM1_Interaction50 <- powerSim(lmm24_25, test=fixed("OrdPos.c:wh2-1","t"), nsim = n_it) # increase to nsim > 1000 for real test
lastResult()$warnings
lastResult()$errors
``` 

```{r}
PowerLMM1_Interaction50
```


#### 55 ms interaction effect, 20 VP

```{r}
gm <- mean(df_Ord$RT)
eff_55ms <- (1000/(gm+(55/2))) - (1000/(gm-(55/2)))
fixef(lmm24_20)["OrdPos.c:wh2-1"]<- eff_55ms
```

*Model B5: Linear model with interaction effect "Ordinal position x Session" of 55 ms* 

```{r PowerSim_Interaction55_20, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM1_Interaction55_20 <- powerSim(lmm24_20, test=fixed("OrdPos.c:wh2-1","t"), nsim = n_it) # increase to nsim > 1000 for real test
lastResult()$warnings
lastResult()$errors
``` 

```{r}
PowerLMM1_Interaction55_20
```

#### 55 ms interaction effect, 25 VP

```{r}
gm <- mean(df_Ord$RT)
eff_55ms <- (1000/(gm+(55/2))) - (1000/(gm-(55/2)))
fixef(lmm24_25)["OrdPos.c:wh2-1"]<- eff_55ms
```

*Model B5: Linear model with interaction effect "Ordinal position x Session" of 55 ms* 

```{r PowerSim_Interaction55, message=FALSE, warning=FALSE, cache=TRUE, results="hide"}
PowerLMM1_Interaction55 <- powerSim(lmm24_25, test=fixed("OrdPos.c:wh2-1","t"), nsim = n_it) # increase to nsim > 1000 for real test
lastResult()$warnings
lastResult()$errors
``` 

```{r}
PowerLMM1_Interaction55
```


# --------------------------------------------
### C) Calculate effect size for interaction effect 
Use the method by Westfall, Judd, and Kenny (2014), as reviewed in Brysbaert & Stevens (2018)  
Westfall d = (difference between the means)/sqrt(variances of all random effects)  
We use the experimental variances and the simulated effect sizes

```{r}
x <- summary(lmm1)
randomvars <- 0.031756+0.001310+0.011178+0.002588+0.082964
(d_35 <- eff_35ms /sqrt(randomvars))
(d_40 <- eff_40ms /sqrt(randomvars))
(d_45 <- eff_45ms /sqrt(randomvars))
(d_50 <- eff_50ms /sqrt(randomvars))
(d_55 <- eff_55ms /sqrt(randomvars))

```

